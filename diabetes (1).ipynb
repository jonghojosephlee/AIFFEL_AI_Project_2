{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d4a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes=load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab1b512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0232978f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=diabetes.data, columns = diabetes.feature_names)\n",
    "df['target'] = diabetes.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cad51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y data 지정\n",
    "X = df[['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']].values\n",
    "y = df['target'].values\n",
    "# removed sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc654e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 9)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a756f29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1 : age\n",
      "feature 2 : sex\n",
      "feature 3 : bmi\n",
      "feature 4 : bp\n",
      "feature 5 : s1\n",
      "feature 6 : s2\n",
      "feature 7 : s3\n",
      "feature 8 : s4\n",
      "feature 9 : s5\n",
      "feature 10 : s6\n"
     ]
    }
   ],
   "source": [
    "for i,feature_name in enumerate(diabetes.feature_names):\n",
    "  print(f'feature {i+1} : {feature_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b704170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 9) (287,)\n",
      "(155, 9) (155,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=40)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e734cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(9)\n",
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f8c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9494297 , 0.12517451, 0.87680904, 0.40722202, 0.38842664,\n",
       "       0.25354477, 0.40357642, 0.11875251, 0.04851771])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0198c02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048920507122495516"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f79cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델설정\n",
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(9):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e503fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수\n",
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff9b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2210f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    # N은 데이터 포인트의 개수\n",
    "    N = len(y)\n",
    "    \n",
    "    # y_pred 준비\n",
    "    y_pred = model(X, W, b)\n",
    "    \n",
    "    # 공식에 맞게 gradient 계산\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "        \n",
    "    # b의 gradient 계산\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac7ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW: [-1.36930005 -4.29157763 -3.22715716 -1.54615051 -1.26859321  2.89009417\n",
      " -3.14762329 -4.13962721 -2.79681976]\n",
      "db: -304.16912731154684\n"
     ]
    }
   ],
   "source": [
    "dW, db = gradient(X, W, b, y)\n",
    "print(\"dW:\", dW)\n",
    "print(\"db:\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962cded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a797c799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 20602.4922\n",
      "Iteration 20 : Loss 15680.9427\n",
      "Iteration 30 : Loss 12392.8239\n",
      "Iteration 40 : Loss 10195.1916\n",
      "Iteration 50 : Loss 8725.5763\n",
      "Iteration 60 : Loss 7741.9932\n",
      "Iteration 70 : Loss 7082.8928\n",
      "Iteration 80 : Loss 6640.4250\n",
      "Iteration 90 : Loss 6342.5886\n",
      "Iteration 100 : Loss 6141.3158\n",
      "Iteration 110 : Loss 6004.5164\n",
      "Iteration 120 : Loss 5910.7670\n",
      "Iteration 130 : Loss 5845.7652\n",
      "Iteration 140 : Loss 5799.9628\n",
      "Iteration 150 : Loss 5766.9853\n",
      "Iteration 160 : Loss 5742.5771\n",
      "Iteration 170 : Loss 5723.8972\n",
      "Iteration 180 : Loss 5709.0488\n",
      "Iteration 190 : Loss 5696.7656\n",
      "Iteration 200 : Loss 5686.2023\n",
      "Iteration 210 : Loss 5676.7944\n",
      "Iteration 220 : Loss 5668.1651\n",
      "Iteration 230 : Loss 5660.0628\n",
      "Iteration 240 : Loss 5652.3195\n",
      "Iteration 250 : Loss 5644.8231\n",
      "Iteration 260 : Loss 5637.4987\n",
      "Iteration 270 : Loss 5630.2961\n",
      "Iteration 280 : Loss 5623.1821\n",
      "Iteration 290 : Loss 5616.1342\n",
      "Iteration 300 : Loss 5609.1375\n",
      "Iteration 310 : Loss 5602.1820\n",
      "Iteration 320 : Loss 5595.2610\n",
      "Iteration 330 : Loss 5588.3700\n",
      "Iteration 340 : Loss 5581.5061\n",
      "Iteration 350 : Loss 5574.6670\n",
      "Iteration 360 : Loss 5567.8516\n",
      "Iteration 370 : Loss 5561.0588\n",
      "Iteration 380 : Loss 5554.2879\n",
      "Iteration 390 : Loss 5547.5385\n",
      "Iteration 400 : Loss 5540.8103\n",
      "Iteration 410 : Loss 5534.1030\n",
      "Iteration 420 : Loss 5527.4164\n",
      "Iteration 430 : Loss 5520.7505\n",
      "Iteration 440 : Loss 5514.1050\n",
      "Iteration 450 : Loss 5507.4799\n",
      "Iteration 460 : Loss 5500.8750\n",
      "Iteration 470 : Loss 5494.2904\n",
      "Iteration 480 : Loss 5487.7258\n",
      "Iteration 490 : Loss 5481.1813\n",
      "Iteration 500 : Loss 5474.6568\n",
      "Iteration 510 : Loss 5468.1521\n",
      "Iteration 520 : Loss 5461.6673\n",
      "Iteration 530 : Loss 5455.2023\n",
      "Iteration 540 : Loss 5448.7569\n",
      "Iteration 550 : Loss 5442.3312\n",
      "Iteration 560 : Loss 5435.9250\n",
      "Iteration 570 : Loss 5429.5384\n",
      "Iteration 580 : Loss 5423.1711\n",
      "Iteration 590 : Loss 5416.8232\n",
      "Iteration 600 : Loss 5410.4947\n",
      "Iteration 610 : Loss 5404.1853\n",
      "Iteration 620 : Loss 5397.8951\n",
      "Iteration 630 : Loss 5391.6241\n",
      "Iteration 640 : Loss 5385.3720\n",
      "Iteration 650 : Loss 5379.1390\n",
      "Iteration 660 : Loss 5372.9248\n",
      "Iteration 670 : Loss 5366.7295\n",
      "Iteration 680 : Loss 5360.5530\n",
      "Iteration 690 : Loss 5354.3953\n",
      "Iteration 700 : Loss 5348.2561\n",
      "Iteration 710 : Loss 5342.1356\n",
      "Iteration 720 : Loss 5336.0336\n",
      "Iteration 730 : Loss 5329.9501\n",
      "Iteration 740 : Loss 5323.8850\n",
      "Iteration 750 : Loss 5317.8383\n",
      "Iteration 760 : Loss 5311.8098\n",
      "Iteration 770 : Loss 5305.7996\n",
      "Iteration 780 : Loss 5299.8075\n",
      "Iteration 790 : Loss 5293.8336\n",
      "Iteration 800 : Loss 5287.8776\n",
      "Iteration 810 : Loss 5281.9397\n",
      "Iteration 820 : Loss 5276.0197\n",
      "Iteration 830 : Loss 5270.1176\n",
      "Iteration 840 : Loss 5264.2332\n",
      "Iteration 850 : Loss 5258.3667\n",
      "Iteration 860 : Loss 5252.5178\n",
      "Iteration 870 : Loss 5246.6865\n",
      "Iteration 880 : Loss 5240.8728\n",
      "Iteration 890 : Loss 5235.0766\n",
      "Iteration 900 : Loss 5229.2978\n",
      "Iteration 910 : Loss 5223.5365\n",
      "Iteration 920 : Loss 5217.7925\n",
      "Iteration 930 : Loss 5212.0657\n",
      "Iteration 940 : Loss 5206.3562\n",
      "Iteration 950 : Loss 5200.6638\n",
      "Iteration 960 : Loss 5194.9886\n",
      "Iteration 970 : Loss 5189.3304\n",
      "Iteration 980 : Loss 5183.6891\n",
      "Iteration 990 : Loss 5178.0648\n",
      "Iteration 1000 : Loss 5172.4574\n",
      "Iteration 1010 : Loss 5166.8668\n",
      "Iteration 1020 : Loss 5161.2930\n",
      "Iteration 1030 : Loss 5155.7359\n",
      "Iteration 1040 : Loss 5150.1954\n",
      "Iteration 1050 : Loss 5144.6715\n",
      "Iteration 1060 : Loss 5139.1642\n",
      "Iteration 1070 : Loss 5133.6733\n",
      "Iteration 1080 : Loss 5128.1989\n",
      "Iteration 1090 : Loss 5122.7409\n",
      "Iteration 1100 : Loss 5117.2992\n",
      "Iteration 1110 : Loss 5111.8737\n",
      "Iteration 1120 : Loss 5106.4645\n",
      "Iteration 1130 : Loss 5101.0714\n",
      "Iteration 1140 : Loss 5095.6944\n",
      "Iteration 1150 : Loss 5090.3335\n",
      "Iteration 1160 : Loss 5084.9886\n",
      "Iteration 1170 : Loss 5079.6596\n",
      "Iteration 1180 : Loss 5074.3465\n",
      "Iteration 1190 : Loss 5069.0492\n",
      "Iteration 1200 : Loss 5063.7678\n",
      "Iteration 1210 : Loss 5058.5020\n",
      "Iteration 1220 : Loss 5053.2520\n",
      "Iteration 1230 : Loss 5048.0175\n",
      "Iteration 1240 : Loss 5042.7987\n",
      "Iteration 1250 : Loss 5037.5954\n",
      "Iteration 1260 : Loss 5032.4075\n",
      "Iteration 1270 : Loss 5027.2351\n",
      "Iteration 1280 : Loss 5022.0780\n",
      "Iteration 1290 : Loss 5016.9363\n",
      "Iteration 1300 : Loss 5011.8098\n",
      "Iteration 1310 : Loss 5006.6985\n",
      "Iteration 1320 : Loss 5001.6024\n",
      "Iteration 1330 : Loss 4996.5215\n",
      "Iteration 1340 : Loss 4991.4555\n",
      "Iteration 1350 : Loss 4986.4046\n",
      "Iteration 1360 : Loss 4981.3687\n",
      "Iteration 1370 : Loss 4976.3477\n",
      "Iteration 1380 : Loss 4971.3415\n",
      "Iteration 1390 : Loss 4966.3502\n",
      "Iteration 1400 : Loss 4961.3736\n",
      "Iteration 1410 : Loss 4956.4118\n",
      "Iteration 1420 : Loss 4951.4646\n",
      "Iteration 1430 : Loss 4946.5321\n",
      "Iteration 1440 : Loss 4941.6141\n",
      "Iteration 1450 : Loss 4936.7106\n",
      "Iteration 1460 : Loss 4931.8216\n",
      "Iteration 1470 : Loss 4926.9471\n",
      "Iteration 1480 : Loss 4922.0869\n",
      "Iteration 1490 : Loss 4917.2411\n",
      "Iteration 1500 : Loss 4912.4095\n",
      "Iteration 1510 : Loss 4907.5922\n",
      "Iteration 1520 : Loss 4902.7890\n",
      "Iteration 1530 : Loss 4898.0001\n",
      "Iteration 1540 : Loss 4893.2252\n",
      "Iteration 1550 : Loss 4888.4643\n",
      "Iteration 1560 : Loss 4883.7175\n",
      "Iteration 1570 : Loss 4878.9846\n",
      "Iteration 1580 : Loss 4874.2656\n",
      "Iteration 1590 : Loss 4869.5605\n",
      "Iteration 1600 : Loss 4864.8692\n",
      "Iteration 1610 : Loss 4860.1917\n",
      "Iteration 1620 : Loss 4855.5279\n",
      "Iteration 1630 : Loss 4850.8778\n",
      "Iteration 1640 : Loss 4846.2413\n",
      "Iteration 1650 : Loss 4841.6184\n",
      "Iteration 1660 : Loss 4837.0090\n",
      "Iteration 1670 : Loss 4832.4132\n",
      "Iteration 1680 : Loss 4827.8308\n",
      "Iteration 1690 : Loss 4823.2618\n",
      "Iteration 1700 : Loss 4818.7062\n",
      "Iteration 1710 : Loss 4814.1639\n",
      "Iteration 1720 : Loss 4809.6349\n",
      "Iteration 1730 : Loss 4805.1192\n",
      "Iteration 1740 : Loss 4800.6166\n",
      "Iteration 1750 : Loss 4796.1271\n",
      "Iteration 1760 : Loss 4791.6508\n",
      "Iteration 1770 : Loss 4787.1875\n",
      "Iteration 1780 : Loss 4782.7373\n",
      "Iteration 1790 : Loss 4778.3000\n",
      "Iteration 1800 : Loss 4773.8757\n",
      "Iteration 1810 : Loss 4769.4642\n",
      "Iteration 1820 : Loss 4765.0656\n",
      "Iteration 1830 : Loss 4760.6798\n",
      "Iteration 1840 : Loss 4756.3067\n",
      "Iteration 1850 : Loss 4751.9464\n",
      "Iteration 1860 : Loss 4747.5988\n",
      "Iteration 1870 : Loss 4743.2638\n",
      "Iteration 1880 : Loss 4738.9413\n",
      "Iteration 1890 : Loss 4734.6315\n",
      "Iteration 1900 : Loss 4730.3341\n",
      "Iteration 1910 : Loss 4726.0492\n",
      "Iteration 1920 : Loss 4721.7768\n",
      "Iteration 1930 : Loss 4717.5167\n",
      "Iteration 1940 : Loss 4713.2690\n",
      "Iteration 1950 : Loss 4709.0335\n",
      "Iteration 1960 : Loss 4704.8104\n",
      "Iteration 1970 : Loss 4700.5995\n",
      "Iteration 1980 : Loss 4696.4007\n",
      "Iteration 1990 : Loss 4692.2141\n",
      "Iteration 2000 : Loss 4688.0396\n",
      "Iteration 2010 : Loss 4683.8772\n",
      "Iteration 2020 : Loss 4679.7268\n",
      "Iteration 2030 : Loss 4675.5884\n",
      "Iteration 2040 : Loss 4671.4619\n",
      "Iteration 2050 : Loss 4667.3473\n",
      "Iteration 2060 : Loss 4663.2446\n",
      "Iteration 2070 : Loss 4659.1537\n",
      "Iteration 2080 : Loss 4655.0747\n",
      "Iteration 2090 : Loss 4651.0073\n",
      "Iteration 2100 : Loss 4646.9517\n",
      "Iteration 2110 : Loss 4642.9078\n",
      "Iteration 2120 : Loss 4638.8754\n",
      "Iteration 2130 : Loss 4634.8547\n",
      "Iteration 2140 : Loss 4630.8456\n",
      "Iteration 2150 : Loss 4626.8479\n",
      "Iteration 2160 : Loss 4622.8618\n",
      "Iteration 2170 : Loss 4618.8871\n",
      "Iteration 2180 : Loss 4614.9237\n",
      "Iteration 2190 : Loss 4610.9718\n",
      "Iteration 2200 : Loss 4607.0312\n",
      "Iteration 2210 : Loss 4603.1019\n",
      "Iteration 2220 : Loss 4599.1839\n",
      "Iteration 2230 : Loss 4595.2770\n",
      "Iteration 2240 : Loss 4591.3814\n",
      "Iteration 2250 : Loss 4587.4969\n",
      "Iteration 2260 : Loss 4583.6235\n",
      "Iteration 2270 : Loss 4579.7612\n",
      "Iteration 2280 : Loss 4575.9099\n",
      "Iteration 2290 : Loss 4572.0697\n",
      "Iteration 2300 : Loss 4568.2403\n",
      "Iteration 2310 : Loss 4564.4220\n",
      "Iteration 2320 : Loss 4560.6145\n",
      "Iteration 2330 : Loss 4556.8179\n",
      "Iteration 2340 : Loss 4553.0321\n",
      "Iteration 2350 : Loss 4549.2571\n",
      "Iteration 2360 : Loss 4545.4928\n",
      "Iteration 2370 : Loss 4541.7393\n",
      "Iteration 2380 : Loss 4537.9964\n",
      "Iteration 2390 : Loss 4534.2642\n",
      "Iteration 2400 : Loss 4530.5426\n",
      "Iteration 2410 : Loss 4526.8316\n",
      "Iteration 2420 : Loss 4523.1311\n",
      "Iteration 2430 : Loss 4519.4411\n",
      "Iteration 2440 : Loss 4515.7616\n",
      "Iteration 2450 : Loss 4512.0925\n",
      "Iteration 2460 : Loss 4508.4339\n",
      "Iteration 2470 : Loss 4504.7856\n",
      "Iteration 2480 : Loss 4501.1477\n",
      "Iteration 2490 : Loss 4497.5200\n",
      "Iteration 2500 : Loss 4493.9026\n",
      "Iteration 2510 : Loss 4490.2955\n",
      "Iteration 2520 : Loss 4486.6986\n",
      "Iteration 2530 : Loss 4483.1118\n",
      "Iteration 2540 : Loss 4479.5352\n",
      "Iteration 2550 : Loss 4475.9686\n",
      "Iteration 2560 : Loss 4472.4122\n",
      "Iteration 2570 : Loss 4468.8658\n",
      "Iteration 2580 : Loss 4465.3293\n",
      "Iteration 2590 : Loss 4461.8029\n",
      "Iteration 2600 : Loss 4458.2864\n",
      "Iteration 2610 : Loss 4454.7798\n",
      "Iteration 2620 : Loss 4451.2831\n",
      "Iteration 2630 : Loss 4447.7962\n",
      "Iteration 2640 : Loss 4444.3191\n",
      "Iteration 2650 : Loss 4440.8518\n",
      "Iteration 2660 : Loss 4437.3943\n",
      "Iteration 2670 : Loss 4433.9465\n",
      "Iteration 2680 : Loss 4430.5083\n",
      "Iteration 2690 : Loss 4427.0798\n",
      "Iteration 2700 : Loss 4423.6609\n",
      "Iteration 2710 : Loss 4420.2517\n",
      "Iteration 2720 : Loss 4416.8519\n",
      "Iteration 2730 : Loss 4413.4617\n",
      "Iteration 2740 : Loss 4410.0810\n",
      "Iteration 2750 : Loss 4406.7098\n",
      "Iteration 2760 : Loss 4403.3480\n",
      "Iteration 2770 : Loss 4399.9955\n",
      "Iteration 2780 : Loss 4396.6525\n",
      "Iteration 2790 : Loss 4393.3188\n",
      "Iteration 2800 : Loss 4389.9944\n",
      "Iteration 2810 : Loss 4386.6793\n",
      "Iteration 2820 : Loss 4383.3735\n",
      "Iteration 2830 : Loss 4380.0769\n",
      "Iteration 2840 : Loss 4376.7894\n",
      "Iteration 2850 : Loss 4373.5111\n",
      "Iteration 2860 : Loss 4370.2420\n",
      "Iteration 2870 : Loss 4366.9819\n",
      "Iteration 2880 : Loss 4363.7310\n",
      "Iteration 2890 : Loss 4360.4890\n",
      "Iteration 2900 : Loss 4357.2561\n",
      "Iteration 2910 : Loss 4354.0322\n",
      "Iteration 2920 : Loss 4350.8172\n",
      "Iteration 2930 : Loss 4347.6112\n",
      "Iteration 2940 : Loss 4344.4140\n",
      "Iteration 2950 : Loss 4341.2257\n",
      "Iteration 2960 : Loss 4338.0463\n",
      "Iteration 2970 : Loss 4334.8756\n",
      "Iteration 2980 : Loss 4331.7138\n",
      "Iteration 2990 : Loss 4328.5607\n",
      "Iteration 3000 : Loss 4325.4163\n",
      "Iteration 3010 : Loss 4322.2806\n",
      "Iteration 3020 : Loss 4319.1536\n",
      "Iteration 3030 : Loss 4316.0352\n",
      "Iteration 3040 : Loss 4312.9255\n",
      "Iteration 3050 : Loss 4309.8243\n",
      "Iteration 3060 : Loss 4306.7317\n",
      "Iteration 3070 : Loss 4303.6476\n",
      "Iteration 3080 : Loss 4300.5720\n",
      "Iteration 3090 : Loss 4297.5049\n",
      "Iteration 3100 : Loss 4294.4462\n",
      "Iteration 3110 : Loss 4291.3960\n",
      "Iteration 3120 : Loss 4288.3541\n",
      "Iteration 3130 : Loss 4285.3206\n",
      "Iteration 3140 : Loss 4282.2955\n",
      "Iteration 3150 : Loss 4279.2787\n",
      "Iteration 3160 : Loss 4276.2701\n",
      "Iteration 3170 : Loss 4273.2698\n",
      "Iteration 3180 : Loss 4270.2777\n",
      "Iteration 3190 : Loss 4267.2939\n",
      "Iteration 3200 : Loss 4264.3182\n",
      "Iteration 3210 : Loss 4261.3507\n",
      "Iteration 3220 : Loss 4258.3913\n",
      "Iteration 3230 : Loss 4255.4400\n",
      "Iteration 3240 : Loss 4252.4967\n",
      "Iteration 3250 : Loss 4249.5615\n",
      "Iteration 3260 : Loss 4246.6344\n",
      "Iteration 3270 : Loss 4243.7152\n",
      "Iteration 3280 : Loss 4240.8040\n",
      "Iteration 3290 : Loss 4237.9007\n",
      "Iteration 3300 : Loss 4235.0054\n",
      "Iteration 3310 : Loss 4232.1179\n",
      "Iteration 3320 : Loss 4229.2384\n",
      "Iteration 3330 : Loss 4226.3666\n",
      "Iteration 3340 : Loss 4223.5027\n",
      "Iteration 3350 : Loss 4220.6466\n",
      "Iteration 3360 : Loss 4217.7982\n",
      "Iteration 3370 : Loss 4214.9576\n",
      "Iteration 3380 : Loss 4212.1247\n",
      "Iteration 3390 : Loss 4209.2995\n",
      "Iteration 3400 : Loss 4206.4819\n",
      "Iteration 3410 : Loss 4203.6720\n",
      "Iteration 3420 : Loss 4200.8697\n",
      "Iteration 3430 : Loss 4198.0750\n",
      "Iteration 3440 : Loss 4195.2879\n",
      "Iteration 3450 : Loss 4192.5083\n",
      "Iteration 3460 : Loss 4189.7362\n",
      "Iteration 3470 : Loss 4186.9717\n",
      "Iteration 3480 : Loss 4184.2146\n",
      "Iteration 3490 : Loss 4181.4649\n",
      "Iteration 3500 : Loss 4178.7227\n",
      "Iteration 3510 : Loss 4175.9879\n",
      "Iteration 3520 : Loss 4173.2604\n",
      "Iteration 3530 : Loss 4170.5403\n",
      "Iteration 3540 : Loss 4167.8276\n",
      "Iteration 3550 : Loss 4165.1221\n",
      "Iteration 3560 : Loss 4162.4239\n",
      "Iteration 3570 : Loss 4159.7330\n",
      "Iteration 3580 : Loss 4157.0493\n",
      "Iteration 3590 : Loss 4154.3729\n",
      "Iteration 3600 : Loss 4151.7036\n",
      "Iteration 3610 : Loss 4149.0415\n",
      "Iteration 3620 : Loss 4146.3865\n",
      "Iteration 3630 : Loss 4143.7386\n",
      "Iteration 3640 : Loss 4141.0979\n",
      "Iteration 3650 : Loss 4138.4642\n",
      "Iteration 3660 : Loss 4135.8376\n",
      "Iteration 3670 : Loss 4133.2180\n",
      "Iteration 3680 : Loss 4130.6054\n",
      "Iteration 3690 : Loss 4127.9998\n",
      "Iteration 3700 : Loss 4125.4012\n",
      "Iteration 3710 : Loss 4122.8095\n",
      "Iteration 3720 : Loss 4120.2247\n",
      "Iteration 3730 : Loss 4117.6468\n",
      "Iteration 3740 : Loss 4115.0758\n",
      "Iteration 3750 : Loss 4112.5117\n",
      "Iteration 3760 : Loss 4109.9543\n",
      "Iteration 3770 : Loss 4107.4038\n",
      "Iteration 3780 : Loss 4104.8601\n",
      "Iteration 3790 : Loss 4102.3231\n",
      "Iteration 3800 : Loss 4099.7929\n",
      "Iteration 3810 : Loss 4097.2694\n",
      "Iteration 3820 : Loss 4094.7526\n",
      "Iteration 3830 : Loss 4092.2425\n",
      "Iteration 3840 : Loss 4089.7390\n",
      "Iteration 3850 : Loss 4087.2422\n",
      "Iteration 3860 : Loss 4084.7520\n",
      "Iteration 3870 : Loss 4082.2684\n",
      "Iteration 3880 : Loss 4079.7913\n",
      "Iteration 3890 : Loss 4077.3209\n",
      "Iteration 3900 : Loss 4074.8569\n",
      "Iteration 3910 : Loss 4072.3995\n",
      "Iteration 3920 : Loss 4069.9485\n",
      "Iteration 3930 : Loss 4067.5040\n",
      "Iteration 3940 : Loss 4065.0660\n",
      "Iteration 3950 : Loss 4062.6344\n",
      "Iteration 3960 : Loss 4060.2092\n",
      "Iteration 3970 : Loss 4057.7904\n",
      "Iteration 3980 : Loss 4055.3779\n",
      "Iteration 3990 : Loss 4052.9718\n",
      "Iteration 4000 : Loss 4050.5721\n",
      "Iteration 4010 : Loss 4048.1786\n",
      "Iteration 4020 : Loss 4045.7915\n",
      "Iteration 4030 : Loss 4043.4106\n",
      "Iteration 4040 : Loss 4041.0359\n",
      "Iteration 4050 : Loss 4038.6675\n",
      "Iteration 4060 : Loss 4036.3053\n",
      "Iteration 4070 : Loss 4033.9492\n",
      "Iteration 4080 : Loss 4031.5994\n",
      "Iteration 4090 : Loss 4029.2556\n",
      "Iteration 4100 : Loss 4026.9181\n",
      "Iteration 4110 : Loss 4024.5866\n",
      "Iteration 4120 : Loss 4022.2612\n",
      "Iteration 4130 : Loss 4019.9419\n",
      "Iteration 4140 : Loss 4017.6286\n",
      "Iteration 4150 : Loss 4015.3214\n",
      "Iteration 4160 : Loss 4013.0202\n",
      "Iteration 4170 : Loss 4010.7250\n",
      "Iteration 4180 : Loss 4008.4357\n",
      "Iteration 4190 : Loss 4006.1525\n",
      "Iteration 4200 : Loss 4003.8751\n",
      "Iteration 4210 : Loss 4001.6037\n",
      "Iteration 4220 : Loss 3999.3382\n",
      "Iteration 4230 : Loss 3997.0785\n",
      "Iteration 4240 : Loss 3994.8247\n",
      "Iteration 4250 : Loss 3992.5768\n",
      "Iteration 4260 : Loss 3990.3347\n",
      "Iteration 4270 : Loss 3988.0984\n",
      "Iteration 4280 : Loss 3985.8679\n",
      "Iteration 4290 : Loss 3983.6432\n",
      "Iteration 4300 : Loss 3981.4242\n",
      "Iteration 4310 : Loss 3979.2109\n",
      "Iteration 4320 : Loss 3977.0034\n",
      "Iteration 4330 : Loss 3974.8016\n",
      "Iteration 4340 : Loss 3972.6054\n",
      "Iteration 4350 : Loss 3970.4150\n",
      "Iteration 4360 : Loss 3968.2301\n",
      "Iteration 4370 : Loss 3966.0509\n",
      "Iteration 4380 : Loss 3963.8773\n",
      "Iteration 4390 : Loss 3961.7093\n",
      "Iteration 4400 : Loss 3959.5469\n",
      "Iteration 4410 : Loss 3957.3900\n",
      "Iteration 4420 : Loss 3955.2387\n",
      "Iteration 4430 : Loss 3953.0929\n",
      "Iteration 4440 : Loss 3950.9526\n",
      "Iteration 4450 : Loss 3948.8177\n",
      "Iteration 4460 : Loss 3946.6884\n",
      "Iteration 4470 : Loss 3944.5645\n",
      "Iteration 4480 : Loss 3942.4460\n",
      "Iteration 4490 : Loss 3940.3330\n",
      "Iteration 4500 : Loss 3938.2254\n",
      "Iteration 4510 : Loss 3936.1231\n",
      "Iteration 4520 : Loss 3934.0262\n",
      "Iteration 4530 : Loss 3931.9347\n",
      "Iteration 4540 : Loss 3929.8485\n",
      "Iteration 4550 : Loss 3927.7676\n",
      "Iteration 4560 : Loss 3925.6921\n",
      "Iteration 4570 : Loss 3923.6218\n",
      "Iteration 4580 : Loss 3921.5568\n",
      "Iteration 4590 : Loss 3919.4970\n",
      "Iteration 4600 : Loss 3917.4425\n",
      "Iteration 4610 : Loss 3915.3931\n",
      "Iteration 4620 : Loss 3913.3490\n",
      "Iteration 4630 : Loss 3911.3101\n",
      "Iteration 4640 : Loss 3909.2764\n",
      "Iteration 4650 : Loss 3907.2478\n",
      "Iteration 4660 : Loss 3905.2243\n",
      "Iteration 4670 : Loss 3903.2060\n",
      "Iteration 4680 : Loss 3901.1927\n",
      "Iteration 4690 : Loss 3899.1846\n",
      "Iteration 4700 : Loss 3897.1815\n",
      "Iteration 4710 : Loss 3895.1835\n",
      "Iteration 4720 : Loss 3893.1905\n",
      "Iteration 4730 : Loss 3891.2026\n",
      "Iteration 4740 : Loss 3889.2197\n",
      "Iteration 4750 : Loss 3887.2417\n",
      "Iteration 4760 : Loss 3885.2688\n",
      "Iteration 4770 : Loss 3883.3008\n",
      "Iteration 4780 : Loss 3881.3378\n",
      "Iteration 4790 : Loss 3879.3797\n",
      "Iteration 4800 : Loss 3877.4265\n",
      "Iteration 4810 : Loss 3875.4782\n",
      "Iteration 4820 : Loss 3873.5348\n",
      "Iteration 4830 : Loss 3871.5963\n",
      "Iteration 4840 : Loss 3869.6626\n",
      "Iteration 4850 : Loss 3867.7338\n",
      "Iteration 4860 : Loss 3865.8098\n",
      "Iteration 4870 : Loss 3863.8906\n",
      "Iteration 4880 : Loss 3861.9762\n",
      "Iteration 4890 : Loss 3860.0666\n",
      "Iteration 4900 : Loss 3858.1618\n",
      "Iteration 4910 : Loss 3856.2617\n",
      "Iteration 4920 : Loss 3854.3663\n",
      "Iteration 4930 : Loss 3852.4757\n",
      "Iteration 4940 : Loss 3850.5898\n",
      "Iteration 4950 : Loss 3848.7086\n",
      "Iteration 4960 : Loss 3846.8320\n",
      "Iteration 4970 : Loss 3844.9602\n",
      "Iteration 4980 : Loss 3843.0929\n",
      "Iteration 4990 : Loss 3841.2303\n",
      "Iteration 5000 : Loss 3839.3724\n",
      "Iteration 5010 : Loss 3837.5190\n",
      "Iteration 5020 : Loss 3835.6702\n",
      "Iteration 5030 : Loss 3833.8261\n",
      "Iteration 5040 : Loss 3831.9864\n",
      "Iteration 5050 : Loss 3830.1514\n",
      "Iteration 5060 : Loss 3828.3208\n",
      "Iteration 5070 : Loss 3826.4948\n",
      "Iteration 5080 : Loss 3824.6733\n",
      "Iteration 5090 : Loss 3822.8563\n",
      "Iteration 5100 : Loss 3821.0438\n",
      "Iteration 5110 : Loss 3819.2357\n",
      "Iteration 5120 : Loss 3817.4321\n",
      "Iteration 5130 : Loss 3815.6329\n",
      "Iteration 5140 : Loss 3813.8382\n",
      "Iteration 5150 : Loss 3812.0479\n",
      "Iteration 5160 : Loss 3810.2619\n",
      "Iteration 5170 : Loss 3808.4804\n",
      "Iteration 5180 : Loss 3806.7032\n",
      "Iteration 5190 : Loss 3804.9304\n",
      "Iteration 5200 : Loss 3803.1619\n",
      "Iteration 5210 : Loss 3801.3978\n",
      "Iteration 5220 : Loss 3799.6380\n",
      "Iteration 5230 : Loss 3797.8824\n",
      "Iteration 5240 : Loss 3796.1312\n",
      "Iteration 5250 : Loss 3794.3843\n",
      "Iteration 5260 : Loss 3792.6416\n",
      "Iteration 5270 : Loss 3790.9031\n",
      "Iteration 5280 : Loss 3789.1689\n",
      "Iteration 5290 : Loss 3787.4390\n",
      "Iteration 5300 : Loss 3785.7132\n",
      "Iteration 5310 : Loss 3783.9917\n",
      "Iteration 5320 : Loss 3782.2743\n",
      "Iteration 5330 : Loss 3780.5611\n",
      "Iteration 5340 : Loss 3778.8521\n",
      "Iteration 5350 : Loss 3777.1472\n",
      "Iteration 5360 : Loss 3775.4465\n",
      "Iteration 5370 : Loss 3773.7498\n",
      "Iteration 5380 : Loss 3772.0573\n",
      "Iteration 5390 : Loss 3770.3689\n",
      "Iteration 5400 : Loss 3768.6846\n",
      "Iteration 5410 : Loss 3767.0043\n",
      "Iteration 5420 : Loss 3765.3281\n",
      "Iteration 5430 : Loss 3763.6560\n",
      "Iteration 5440 : Loss 3761.9879\n",
      "Iteration 5450 : Loss 3760.3238\n",
      "Iteration 5460 : Loss 3758.6637\n",
      "Iteration 5470 : Loss 3757.0076\n",
      "Iteration 5480 : Loss 3755.3555\n",
      "Iteration 5490 : Loss 3753.7074\n",
      "Iteration 5500 : Loss 3752.0633\n",
      "Iteration 5510 : Loss 3750.4230\n",
      "Iteration 5520 : Loss 3748.7868\n",
      "Iteration 5530 : Loss 3747.1544\n",
      "Iteration 5540 : Loss 3745.5260\n",
      "Iteration 5550 : Loss 3743.9015\n",
      "Iteration 5560 : Loss 3742.2809\n",
      "Iteration 5570 : Loss 3740.6641\n",
      "Iteration 5580 : Loss 3739.0512\n",
      "Iteration 5590 : Loss 3737.4422\n",
      "Iteration 5600 : Loss 3735.8370\n",
      "Iteration 5610 : Loss 3734.2356\n",
      "Iteration 5620 : Loss 3732.6381\n",
      "Iteration 5630 : Loss 3731.0444\n",
      "Iteration 5640 : Loss 3729.4544\n",
      "Iteration 5650 : Loss 3727.8683\n",
      "Iteration 5660 : Loss 3726.2859\n",
      "Iteration 5670 : Loss 3724.7073\n",
      "Iteration 5680 : Loss 3723.1324\n",
      "Iteration 5690 : Loss 3721.5613\n",
      "Iteration 5700 : Loss 3719.9939\n",
      "Iteration 5710 : Loss 3718.4303\n",
      "Iteration 5720 : Loss 3716.8703\n",
      "Iteration 5730 : Loss 3715.3140\n",
      "Iteration 5740 : Loss 3713.7614\n",
      "Iteration 5750 : Loss 3712.2125\n",
      "Iteration 5760 : Loss 3710.6672\n",
      "Iteration 5770 : Loss 3709.1256\n",
      "Iteration 5780 : Loss 3707.5877\n",
      "Iteration 5790 : Loss 3706.0533\n",
      "Iteration 5800 : Loss 3704.5226\n",
      "Iteration 5810 : Loss 3702.9955\n",
      "Iteration 5820 : Loss 3701.4719\n",
      "Iteration 5830 : Loss 3699.9520\n",
      "Iteration 5840 : Loss 3698.4356\n",
      "Iteration 5850 : Loss 3696.9228\n",
      "Iteration 5860 : Loss 3695.4136\n",
      "Iteration 5870 : Loss 3693.9078\n",
      "Iteration 5880 : Loss 3692.4057\n",
      "Iteration 5890 : Loss 3690.9070\n",
      "Iteration 5900 : Loss 3689.4118\n",
      "Iteration 5910 : Loss 3687.9202\n",
      "Iteration 5920 : Loss 3686.4320\n",
      "Iteration 5930 : Loss 3684.9473\n",
      "Iteration 5940 : Loss 3683.4661\n",
      "Iteration 5950 : Loss 3681.9883\n",
      "Iteration 5960 : Loss 3680.5140\n",
      "Iteration 5970 : Loss 3679.0431\n",
      "Iteration 5980 : Loss 3677.5757\n",
      "Iteration 5990 : Loss 3676.1116\n",
      "Iteration 6000 : Loss 3674.6510\n",
      "Iteration 6010 : Loss 3673.1937\n",
      "Iteration 6020 : Loss 3671.7399\n",
      "Iteration 6030 : Loss 3670.2894\n",
      "Iteration 6040 : Loss 3668.8423\n",
      "Iteration 6050 : Loss 3667.3985\n",
      "Iteration 6060 : Loss 3665.9581\n",
      "Iteration 6070 : Loss 3664.5210\n",
      "Iteration 6080 : Loss 3663.0872\n",
      "Iteration 6090 : Loss 3661.6567\n",
      "Iteration 6100 : Loss 3660.2296\n",
      "Iteration 6110 : Loss 3658.8057\n",
      "Iteration 6120 : Loss 3657.3852\n",
      "Iteration 6130 : Loss 3655.9679\n",
      "Iteration 6140 : Loss 3654.5538\n",
      "Iteration 6150 : Loss 3653.1431\n",
      "Iteration 6160 : Loss 3651.7355\n",
      "Iteration 6170 : Loss 3650.3312\n",
      "Iteration 6180 : Loss 3648.9302\n",
      "Iteration 6190 : Loss 3647.5323\n",
      "Iteration 6200 : Loss 3646.1377\n",
      "Iteration 6210 : Loss 3644.7462\n",
      "Iteration 6220 : Loss 3643.3580\n",
      "Iteration 6230 : Loss 3641.9729\n",
      "Iteration 6240 : Loss 3640.5910\n",
      "Iteration 6250 : Loss 3639.2122\n",
      "Iteration 6260 : Loss 3637.8366\n",
      "Iteration 6270 : Loss 3636.4641\n",
      "Iteration 6280 : Loss 3635.0948\n",
      "Iteration 6290 : Loss 3633.7286\n",
      "Iteration 6300 : Loss 3632.3655\n",
      "Iteration 6310 : Loss 3631.0055\n",
      "Iteration 6320 : Loss 3629.6486\n",
      "Iteration 6330 : Loss 3628.2948\n",
      "Iteration 6340 : Loss 3626.9440\n",
      "Iteration 6350 : Loss 3625.5963\n",
      "Iteration 6360 : Loss 3624.2517\n",
      "Iteration 6370 : Loss 3622.9101\n",
      "Iteration 6380 : Loss 3621.5716\n",
      "Iteration 6390 : Loss 3620.2361\n",
      "Iteration 6400 : Loss 3618.9036\n",
      "Iteration 6410 : Loss 3617.5742\n",
      "Iteration 6420 : Loss 3616.2477\n",
      "Iteration 6430 : Loss 3614.9242\n",
      "Iteration 6440 : Loss 3613.6037\n",
      "Iteration 6450 : Loss 3612.2862\n",
      "Iteration 6460 : Loss 3610.9717\n",
      "Iteration 6470 : Loss 3609.6601\n",
      "Iteration 6480 : Loss 3608.3515\n",
      "Iteration 6490 : Loss 3607.0458\n",
      "Iteration 6500 : Loss 3605.7430\n",
      "Iteration 6510 : Loss 3604.4432\n",
      "Iteration 6520 : Loss 3603.1463\n",
      "Iteration 6530 : Loss 3601.8523\n",
      "Iteration 6540 : Loss 3600.5612\n",
      "Iteration 6550 : Loss 3599.2729\n",
      "Iteration 6560 : Loss 3597.9876\n",
      "Iteration 6570 : Loss 3596.7051\n",
      "Iteration 6580 : Loss 3595.4255\n",
      "Iteration 6590 : Loss 3594.1488\n",
      "Iteration 6600 : Loss 3592.8749\n",
      "Iteration 6610 : Loss 3591.6038\n",
      "Iteration 6620 : Loss 3590.3356\n",
      "Iteration 6630 : Loss 3589.0702\n",
      "Iteration 6640 : Loss 3587.8076\n",
      "Iteration 6650 : Loss 3586.5478\n",
      "Iteration 6660 : Loss 3585.2908\n",
      "Iteration 6670 : Loss 3584.0367\n",
      "Iteration 6680 : Loss 3582.7852\n",
      "Iteration 6690 : Loss 3581.5366\n",
      "Iteration 6700 : Loss 3580.2907\n",
      "Iteration 6710 : Loss 3579.0476\n",
      "Iteration 6720 : Loss 3577.8072\n",
      "Iteration 6730 : Loss 3576.5696\n",
      "Iteration 6740 : Loss 3575.3347\n",
      "Iteration 6750 : Loss 3574.1025\n",
      "Iteration 6760 : Loss 3572.8731\n",
      "Iteration 6770 : Loss 3571.6463\n",
      "Iteration 6780 : Loss 3570.4223\n",
      "Iteration 6790 : Loss 3569.2009\n",
      "Iteration 6800 : Loss 3567.9823\n",
      "Iteration 6810 : Loss 3566.7663\n",
      "Iteration 6820 : Loss 3565.5530\n",
      "Iteration 6830 : Loss 3564.3423\n",
      "Iteration 6840 : Loss 3563.1343\n",
      "Iteration 6850 : Loss 3561.9289\n",
      "Iteration 6860 : Loss 3560.7262\n",
      "Iteration 6870 : Loss 3559.5261\n",
      "Iteration 6880 : Loss 3558.3287\n",
      "Iteration 6890 : Loss 3557.1338\n",
      "Iteration 6900 : Loss 3555.9416\n",
      "Iteration 6910 : Loss 3554.7519\n",
      "Iteration 6920 : Loss 3553.5649\n",
      "Iteration 6930 : Loss 3552.3804\n",
      "Iteration 6940 : Loss 3551.1986\n",
      "Iteration 6950 : Loss 3550.0192\n",
      "Iteration 6960 : Loss 3548.8425\n",
      "Iteration 6970 : Loss 3547.6683\n",
      "Iteration 6980 : Loss 3546.4966\n",
      "Iteration 6990 : Loss 3545.3275\n",
      "Iteration 7000 : Loss 3544.1610\n",
      "Iteration 7010 : Loss 3542.9969\n",
      "Iteration 7020 : Loss 3541.8354\n",
      "Iteration 7030 : Loss 3540.6764\n",
      "Iteration 7040 : Loss 3539.5199\n",
      "Iteration 7050 : Loss 3538.3658\n",
      "Iteration 7060 : Loss 3537.2143\n",
      "Iteration 7070 : Loss 3536.0653\n",
      "Iteration 7080 : Loss 3534.9187\n",
      "Iteration 7090 : Loss 3533.7746\n",
      "Iteration 7100 : Loss 3532.6330\n",
      "Iteration 7110 : Loss 3531.4938\n",
      "Iteration 7120 : Loss 3530.3570\n",
      "Iteration 7130 : Loss 3529.2227\n",
      "Iteration 7140 : Loss 3528.0909\n",
      "Iteration 7150 : Loss 3526.9614\n",
      "Iteration 7160 : Loss 3525.8344\n",
      "Iteration 7170 : Loss 3524.7098\n",
      "Iteration 7180 : Loss 3523.5876\n",
      "Iteration 7190 : Loss 3522.4678\n",
      "Iteration 7200 : Loss 3521.3504\n",
      "Iteration 7210 : Loss 3520.2353\n",
      "Iteration 7220 : Loss 3519.1227\n",
      "Iteration 7230 : Loss 3518.0124\n",
      "Iteration 7240 : Loss 3516.9045\n",
      "Iteration 7250 : Loss 3515.7989\n",
      "Iteration 7260 : Loss 3514.6957\n",
      "Iteration 7270 : Loss 3513.5948\n",
      "Iteration 7280 : Loss 3512.4963\n",
      "Iteration 7290 : Loss 3511.4001\n",
      "Iteration 7300 : Loss 3510.3062\n",
      "Iteration 7310 : Loss 3509.2146\n",
      "Iteration 7320 : Loss 3508.1254\n",
      "Iteration 7330 : Loss 3507.0384\n",
      "Iteration 7340 : Loss 3505.9538\n",
      "Iteration 7350 : Loss 3504.8714\n",
      "Iteration 7360 : Loss 3503.7913\n",
      "Iteration 7370 : Loss 3502.7135\n",
      "Iteration 7380 : Loss 3501.6380\n",
      "Iteration 7390 : Loss 3500.5647\n",
      "Iteration 7400 : Loss 3499.4937\n",
      "Iteration 7410 : Loss 3498.4250\n",
      "Iteration 7420 : Loss 3497.3584\n",
      "Iteration 7430 : Loss 3496.2942\n",
      "Iteration 7440 : Loss 3495.2321\n",
      "Iteration 7450 : Loss 3494.1723\n",
      "Iteration 7460 : Loss 3493.1147\n",
      "Iteration 7470 : Loss 3492.0593\n",
      "Iteration 7480 : Loss 3491.0061\n",
      "Iteration 7490 : Loss 3489.9551\n",
      "Iteration 7500 : Loss 3488.9064\n",
      "Iteration 7510 : Loss 3487.8598\n",
      "Iteration 7520 : Loss 3486.8153\n",
      "Iteration 7530 : Loss 3485.7731\n",
      "Iteration 7540 : Loss 3484.7330\n",
      "Iteration 7550 : Loss 3483.6951\n",
      "Iteration 7560 : Loss 3482.6594\n",
      "Iteration 7570 : Loss 3481.6258\n",
      "Iteration 7580 : Loss 3480.5943\n",
      "Iteration 7590 : Loss 3479.5650\n",
      "Iteration 7600 : Loss 3478.5378\n",
      "Iteration 7610 : Loss 3477.5128\n",
      "Iteration 7620 : Loss 3476.4898\n",
      "Iteration 7630 : Loss 3475.4690\n",
      "Iteration 7640 : Loss 3474.4503\n",
      "Iteration 7650 : Loss 3473.4337\n",
      "Iteration 7660 : Loss 3472.4192\n",
      "Iteration 7670 : Loss 3471.4068\n",
      "Iteration 7680 : Loss 3470.3964\n",
      "Iteration 7690 : Loss 3469.3882\n",
      "Iteration 7700 : Loss 3468.3820\n",
      "Iteration 7710 : Loss 3467.3779\n",
      "Iteration 7720 : Loss 3466.3758\n",
      "Iteration 7730 : Loss 3465.3758\n",
      "Iteration 7740 : Loss 3464.3779\n",
      "Iteration 7750 : Loss 3463.3820\n",
      "Iteration 7760 : Loss 3462.3881\n",
      "Iteration 7770 : Loss 3461.3963\n",
      "Iteration 7780 : Loss 3460.4065\n",
      "Iteration 7790 : Loss 3459.4187\n",
      "Iteration 7800 : Loss 3458.4329\n",
      "Iteration 7810 : Loss 3457.4491\n",
      "Iteration 7820 : Loss 3456.4674\n",
      "Iteration 7830 : Loss 3455.4876\n",
      "Iteration 7840 : Loss 3454.5099\n",
      "Iteration 7850 : Loss 3453.5341\n",
      "Iteration 7860 : Loss 3452.5603\n",
      "Iteration 7870 : Loss 3451.5885\n",
      "Iteration 7880 : Loss 3450.6187\n",
      "Iteration 7890 : Loss 3449.6508\n",
      "Iteration 7900 : Loss 3448.6849\n",
      "Iteration 7910 : Loss 3447.7209\n",
      "Iteration 7920 : Loss 3446.7589\n",
      "Iteration 7930 : Loss 3445.7988\n",
      "Iteration 7940 : Loss 3444.8407\n",
      "Iteration 7950 : Loss 3443.8845\n",
      "Iteration 7960 : Loss 3442.9302\n",
      "Iteration 7970 : Loss 3441.9779\n",
      "Iteration 7980 : Loss 3441.0274\n",
      "Iteration 7990 : Loss 3440.0789\n",
      "Iteration 8000 : Loss 3439.1323\n",
      "Iteration 8010 : Loss 3438.1876\n",
      "Iteration 8020 : Loss 3437.2448\n",
      "Iteration 8030 : Loss 3436.3038\n",
      "Iteration 8040 : Loss 3435.3648\n",
      "Iteration 8050 : Loss 3434.4276\n",
      "Iteration 8060 : Loss 3433.4924\n",
      "Iteration 8070 : Loss 3432.5589\n",
      "Iteration 8080 : Loss 3431.6274\n",
      "Iteration 8090 : Loss 3430.6977\n",
      "Iteration 8100 : Loss 3429.7699\n",
      "Iteration 8110 : Loss 3428.8439\n",
      "Iteration 8120 : Loss 3427.9197\n",
      "Iteration 8130 : Loss 3426.9974\n",
      "Iteration 8140 : Loss 3426.0769\n",
      "Iteration 8150 : Loss 3425.1583\n",
      "Iteration 8160 : Loss 3424.2415\n",
      "Iteration 8170 : Loss 3423.3265\n",
      "Iteration 8180 : Loss 3422.4133\n",
      "Iteration 8190 : Loss 3421.5019\n",
      "Iteration 8200 : Loss 3420.5923\n",
      "Iteration 8210 : Loss 3419.6845\n",
      "Iteration 8220 : Loss 3418.7785\n",
      "Iteration 8230 : Loss 3417.8743\n",
      "Iteration 8240 : Loss 3416.9719\n",
      "Iteration 8250 : Loss 3416.0713\n",
      "Iteration 8260 : Loss 3415.1724\n",
      "Iteration 8270 : Loss 3414.2753\n",
      "Iteration 8280 : Loss 3413.3800\n",
      "Iteration 8290 : Loss 3412.4864\n",
      "Iteration 8300 : Loss 3411.5946\n",
      "Iteration 8310 : Loss 3410.7046\n",
      "Iteration 8320 : Loss 3409.8162\n",
      "Iteration 8330 : Loss 3408.9297\n",
      "Iteration 8340 : Loss 3408.0448\n",
      "Iteration 8350 : Loss 3407.1617\n",
      "Iteration 8360 : Loss 3406.2803\n",
      "Iteration 8370 : Loss 3405.4006\n",
      "Iteration 8380 : Loss 3404.5227\n",
      "Iteration 8390 : Loss 3403.6464\n",
      "Iteration 8400 : Loss 3402.7719\n",
      "Iteration 8410 : Loss 3401.8991\n",
      "Iteration 8420 : Loss 3401.0280\n",
      "Iteration 8430 : Loss 3400.1585\n",
      "Iteration 8440 : Loss 3399.2908\n",
      "Iteration 8450 : Loss 3398.4247\n",
      "Iteration 8460 : Loss 3397.5603\n",
      "Iteration 8470 : Loss 3396.6976\n",
      "Iteration 8480 : Loss 3395.8366\n",
      "Iteration 8490 : Loss 3394.9772\n",
      "Iteration 8500 : Loss 3394.1195\n",
      "Iteration 8510 : Loss 3393.2634\n",
      "Iteration 8520 : Loss 3392.4090\n",
      "Iteration 8530 : Loss 3391.5563\n",
      "Iteration 8540 : Loss 3390.7051\n",
      "Iteration 8550 : Loss 3389.8557\n",
      "Iteration 8560 : Loss 3389.0078\n",
      "Iteration 8570 : Loss 3388.1616\n",
      "Iteration 8580 : Loss 3387.3170\n",
      "Iteration 8590 : Loss 3386.4741\n",
      "Iteration 8600 : Loss 3385.6327\n",
      "Iteration 8610 : Loss 3384.7930\n",
      "Iteration 8620 : Loss 3383.9549\n",
      "Iteration 8630 : Loss 3383.1183\n",
      "Iteration 8640 : Loss 3382.2834\n",
      "Iteration 8650 : Loss 3381.4501\n",
      "Iteration 8660 : Loss 3380.6184\n",
      "Iteration 8670 : Loss 3379.7882\n",
      "Iteration 8680 : Loss 3378.9596\n",
      "Iteration 8690 : Loss 3378.1326\n",
      "Iteration 8700 : Loss 3377.3072\n",
      "Iteration 8710 : Loss 3376.4834\n",
      "Iteration 8720 : Loss 3375.6611\n",
      "Iteration 8730 : Loss 3374.8404\n",
      "Iteration 8740 : Loss 3374.0212\n",
      "Iteration 8750 : Loss 3373.2036\n",
      "Iteration 8760 : Loss 3372.3875\n",
      "Iteration 8770 : Loss 3371.5730\n",
      "Iteration 8780 : Loss 3370.7600\n",
      "Iteration 8790 : Loss 3369.9486\n",
      "Iteration 8800 : Loss 3369.1387\n",
      "Iteration 8810 : Loss 3368.3303\n",
      "Iteration 8820 : Loss 3367.5235\n",
      "Iteration 8830 : Loss 3366.7181\n",
      "Iteration 8840 : Loss 3365.9143\n",
      "Iteration 8850 : Loss 3365.1120\n",
      "Iteration 8860 : Loss 3364.3112\n",
      "Iteration 8870 : Loss 3363.5119\n",
      "Iteration 8880 : Loss 3362.7141\n",
      "Iteration 8890 : Loss 3361.9178\n",
      "Iteration 8900 : Loss 3361.1230\n",
      "Iteration 8910 : Loss 3360.3296\n",
      "Iteration 8920 : Loss 3359.5378\n",
      "Iteration 8930 : Loss 3358.7474\n",
      "Iteration 8940 : Loss 3357.9586\n",
      "Iteration 8950 : Loss 3357.1711\n",
      "Iteration 8960 : Loss 3356.3852\n",
      "Iteration 8970 : Loss 3355.6007\n",
      "Iteration 8980 : Loss 3354.8177\n",
      "Iteration 8990 : Loss 3354.0361\n",
      "Iteration 9000 : Loss 3353.2560\n",
      "Iteration 9010 : Loss 3352.4774\n",
      "Iteration 9020 : Loss 3351.7001\n",
      "Iteration 9030 : Loss 3350.9244\n",
      "Iteration 9040 : Loss 3350.1500\n",
      "Iteration 9050 : Loss 3349.3771\n",
      "Iteration 9060 : Loss 3348.6056\n",
      "Iteration 9070 : Loss 3347.8356\n",
      "Iteration 9080 : Loss 3347.0670\n",
      "Iteration 9090 : Loss 3346.2997\n",
      "Iteration 9100 : Loss 3345.5339\n",
      "Iteration 9110 : Loss 3344.7696\n",
      "Iteration 9120 : Loss 3344.0066\n",
      "Iteration 9130 : Loss 3343.2450\n",
      "Iteration 9140 : Loss 3342.4848\n",
      "Iteration 9150 : Loss 3341.7261\n",
      "Iteration 9160 : Loss 3340.9687\n",
      "Iteration 9170 : Loss 3340.2127\n",
      "Iteration 9180 : Loss 3339.4581\n",
      "Iteration 9190 : Loss 3338.7048\n",
      "Iteration 9200 : Loss 3337.9530\n",
      "Iteration 9210 : Loss 3337.2025\n",
      "Iteration 9220 : Loss 3336.4534\n",
      "Iteration 9230 : Loss 3335.7057\n",
      "Iteration 9240 : Loss 3334.9593\n",
      "Iteration 9250 : Loss 3334.2143\n",
      "Iteration 9260 : Loss 3333.4706\n",
      "Iteration 9270 : Loss 3332.7283\n",
      "Iteration 9280 : Loss 3331.9873\n",
      "Iteration 9290 : Loss 3331.2477\n",
      "Iteration 9300 : Loss 3330.5095\n",
      "Iteration 9310 : Loss 3329.7725\n",
      "Iteration 9320 : Loss 3329.0369\n",
      "Iteration 9330 : Loss 3328.3027\n",
      "Iteration 9340 : Loss 3327.5697\n",
      "Iteration 9350 : Loss 3326.8381\n",
      "Iteration 9360 : Loss 3326.1078\n",
      "Iteration 9370 : Loss 3325.3789\n",
      "Iteration 9380 : Loss 3324.6512\n",
      "Iteration 9390 : Loss 3323.9249\n",
      "Iteration 9400 : Loss 3323.1998\n",
      "Iteration 9410 : Loss 3322.4761\n",
      "Iteration 9420 : Loss 3321.7537\n",
      "Iteration 9430 : Loss 3321.0325\n",
      "Iteration 9440 : Loss 3320.3127\n",
      "Iteration 9450 : Loss 3319.5941\n",
      "Iteration 9460 : Loss 3318.8769\n",
      "Iteration 9470 : Loss 3318.1609\n",
      "Iteration 9480 : Loss 3317.4462\n",
      "Iteration 9490 : Loss 3316.7328\n",
      "Iteration 9500 : Loss 3316.0206\n",
      "Iteration 9510 : Loss 3315.3098\n",
      "Iteration 9520 : Loss 3314.6002\n",
      "Iteration 9530 : Loss 3313.8918\n",
      "Iteration 9540 : Loss 3313.1847\n",
      "Iteration 9550 : Loss 3312.4789\n",
      "Iteration 9560 : Loss 3311.7744\n",
      "Iteration 9570 : Loss 3311.0710\n",
      "Iteration 9580 : Loss 3310.3690\n",
      "Iteration 9590 : Loss 3309.6682\n",
      "Iteration 9600 : Loss 3308.9686\n",
      "Iteration 9610 : Loss 3308.2702\n",
      "Iteration 9620 : Loss 3307.5731\n",
      "Iteration 9630 : Loss 3306.8773\n",
      "Iteration 9640 : Loss 3306.1826\n",
      "Iteration 9650 : Loss 3305.4892\n",
      "Iteration 9660 : Loss 3304.7970\n",
      "Iteration 9670 : Loss 3304.1060\n",
      "Iteration 9680 : Loss 3303.4163\n",
      "Iteration 9690 : Loss 3302.7277\n",
      "Iteration 9700 : Loss 3302.0404\n",
      "Iteration 9710 : Loss 3301.3543\n",
      "Iteration 9720 : Loss 3300.6694\n",
      "Iteration 9730 : Loss 3299.9857\n",
      "Iteration 9740 : Loss 3299.3031\n",
      "Iteration 9750 : Loss 3298.6218\n",
      "Iteration 9760 : Loss 3297.9417\n",
      "Iteration 9770 : Loss 3297.2627\n",
      "Iteration 9780 : Loss 3296.5850\n",
      "Iteration 9790 : Loss 3295.9084\n",
      "Iteration 9800 : Loss 3295.2330\n",
      "Iteration 9810 : Loss 3294.5588\n",
      "Iteration 9820 : Loss 3293.8858\n",
      "Iteration 9830 : Loss 3293.2139\n",
      "Iteration 9840 : Loss 3292.5432\n",
      "Iteration 9850 : Loss 3291.8737\n",
      "Iteration 9860 : Loss 3291.2053\n",
      "Iteration 9870 : Loss 3290.5381\n",
      "Iteration 9880 : Loss 3289.8720\n",
      "Iteration 9890 : Loss 3289.2071\n",
      "Iteration 9900 : Loss 3288.5433\n",
      "Iteration 9910 : Loss 3287.8807\n",
      "Iteration 9920 : Loss 3287.2193\n",
      "Iteration 9930 : Loss 3286.5590\n",
      "Iteration 9940 : Loss 3285.8998\n",
      "Iteration 9950 : Loss 3285.2417\n",
      "Iteration 9960 : Loss 3284.5848\n",
      "Iteration 9970 : Loss 3283.9290\n",
      "Iteration 9980 : Loss 3283.2744\n",
      "Iteration 9990 : Loss 3282.6209\n",
      "Iteration 10000 : Loss 3281.9685\n",
      "Iteration 10010 : Loss 3281.3172\n",
      "Iteration 10020 : Loss 3280.6670\n",
      "Iteration 10030 : Loss 3280.0180\n",
      "Iteration 10040 : Loss 3279.3700\n",
      "Iteration 10050 : Loss 3278.7232\n",
      "Iteration 10060 : Loss 3278.0774\n",
      "Iteration 10070 : Loss 3277.4328\n",
      "Iteration 10080 : Loss 3276.7893\n",
      "Iteration 10090 : Loss 3276.1469\n",
      "Iteration 10100 : Loss 3275.5055\n",
      "Iteration 10110 : Loss 3274.8653\n",
      "Iteration 10120 : Loss 3274.2261\n",
      "Iteration 10130 : Loss 3273.5881\n",
      "Iteration 10140 : Loss 3272.9511\n",
      "Iteration 10150 : Loss 3272.3152\n",
      "Iteration 10160 : Loss 3271.6803\n",
      "Iteration 10170 : Loss 3271.0466\n",
      "Iteration 10180 : Loss 3270.4139\n",
      "Iteration 10190 : Loss 3269.7823\n",
      "Iteration 10200 : Loss 3269.1518\n",
      "Iteration 10210 : Loss 3268.5223\n",
      "Iteration 10220 : Loss 3267.8939\n",
      "Iteration 10230 : Loss 3267.2665\n",
      "Iteration 10240 : Loss 3266.6402\n",
      "Iteration 10250 : Loss 3266.0150\n",
      "Iteration 10260 : Loss 3265.3908\n",
      "Iteration 10270 : Loss 3264.7676\n",
      "Iteration 10280 : Loss 3264.1455\n",
      "Iteration 10290 : Loss 3263.5245\n",
      "Iteration 10300 : Loss 3262.9045\n",
      "Iteration 10310 : Loss 3262.2855\n",
      "Iteration 10320 : Loss 3261.6676\n",
      "Iteration 10330 : Loss 3261.0507\n",
      "Iteration 10340 : Loss 3260.4348\n",
      "Iteration 10350 : Loss 3259.8200\n",
      "Iteration 10360 : Loss 3259.2062\n",
      "Iteration 10370 : Loss 3258.5934\n",
      "Iteration 10380 : Loss 3257.9816\n",
      "Iteration 10390 : Loss 3257.3708\n",
      "Iteration 10400 : Loss 3256.7611\n",
      "Iteration 10410 : Loss 3256.1524\n",
      "Iteration 10420 : Loss 3255.5447\n",
      "Iteration 10430 : Loss 3254.9380\n",
      "Iteration 10440 : Loss 3254.3323\n",
      "Iteration 10450 : Loss 3253.7276\n",
      "Iteration 10460 : Loss 3253.1239\n",
      "Iteration 10470 : Loss 3252.5212\n",
      "Iteration 10480 : Loss 3251.9195\n",
      "Iteration 10490 : Loss 3251.3188\n",
      "Iteration 10500 : Loss 3250.7191\n",
      "Iteration 10510 : Loss 3250.1204\n",
      "Iteration 10520 : Loss 3249.5226\n",
      "Iteration 10530 : Loss 3248.9259\n",
      "Iteration 10540 : Loss 3248.3301\n",
      "Iteration 10550 : Loss 3247.7353\n",
      "Iteration 10560 : Loss 3247.1415\n",
      "Iteration 10570 : Loss 3246.5487\n",
      "Iteration 10580 : Loss 3245.9568\n",
      "Iteration 10590 : Loss 3245.3659\n",
      "Iteration 10600 : Loss 3244.7760\n",
      "Iteration 10610 : Loss 3244.1871\n",
      "Iteration 10620 : Loss 3243.5991\n",
      "Iteration 10630 : Loss 3243.0120\n",
      "Iteration 10640 : Loss 3242.4260\n",
      "Iteration 10650 : Loss 3241.8408\n",
      "Iteration 10660 : Loss 3241.2567\n",
      "Iteration 10670 : Loss 3240.6735\n",
      "Iteration 10680 : Loss 3240.0912\n",
      "Iteration 10690 : Loss 3239.5099\n",
      "Iteration 10700 : Loss 3238.9295\n",
      "Iteration 10710 : Loss 3238.3501\n",
      "Iteration 10720 : Loss 3237.7716\n",
      "Iteration 10730 : Loss 3237.1940\n",
      "Iteration 10740 : Loss 3236.6174\n",
      "Iteration 10750 : Loss 3236.0417\n",
      "Iteration 10760 : Loss 3235.4670\n",
      "Iteration 10770 : Loss 3234.8932\n",
      "Iteration 10780 : Loss 3234.3203\n",
      "Iteration 10790 : Loss 3233.7483\n",
      "Iteration 10800 : Loss 3233.1772\n",
      "Iteration 10810 : Loss 3232.6071\n",
      "Iteration 10820 : Loss 3232.0379\n",
      "Iteration 10830 : Loss 3231.4696\n",
      "Iteration 10840 : Loss 3230.9022\n",
      "Iteration 10850 : Loss 3230.3358\n",
      "Iteration 10860 : Loss 3229.7702\n",
      "Iteration 10870 : Loss 3229.2055\n",
      "Iteration 10880 : Loss 3228.6418\n",
      "Iteration 10890 : Loss 3228.0790\n",
      "Iteration 10900 : Loss 3227.5170\n",
      "Iteration 10910 : Loss 3226.9560\n",
      "Iteration 10920 : Loss 3226.3958\n",
      "Iteration 10930 : Loss 3225.8366\n",
      "Iteration 10940 : Loss 3225.2782\n",
      "Iteration 10950 : Loss 3224.7207\n",
      "Iteration 10960 : Loss 3224.1641\n",
      "Iteration 10970 : Loss 3223.6084\n",
      "Iteration 10980 : Loss 3223.0536\n",
      "Iteration 10990 : Loss 3222.4997\n",
      "Iteration 11000 : Loss 3221.9466\n",
      "Iteration 11010 : Loss 3221.3944\n",
      "Iteration 11020 : Loss 3220.8431\n",
      "Iteration 11030 : Loss 3220.2927\n",
      "Iteration 11040 : Loss 3219.7432\n",
      "Iteration 11050 : Loss 3219.1945\n",
      "Iteration 11060 : Loss 3218.6467\n",
      "Iteration 11070 : Loss 3218.0997\n",
      "Iteration 11080 : Loss 3217.5536\n",
      "Iteration 11090 : Loss 3217.0084\n",
      "Iteration 11100 : Loss 3216.4640\n",
      "Iteration 11110 : Loss 3215.9205\n",
      "Iteration 11120 : Loss 3215.3778\n",
      "Iteration 11130 : Loss 3214.8360\n",
      "Iteration 11140 : Loss 3214.2951\n",
      "Iteration 11150 : Loss 3213.7550\n",
      "Iteration 11160 : Loss 3213.2157\n",
      "Iteration 11170 : Loss 3212.6773\n",
      "Iteration 11180 : Loss 3212.1397\n",
      "Iteration 11190 : Loss 3211.6030\n",
      "Iteration 11200 : Loss 3211.0671\n",
      "Iteration 11210 : Loss 3210.5320\n",
      "Iteration 11220 : Loss 3209.9978\n",
      "Iteration 11230 : Loss 3209.4644\n",
      "Iteration 11240 : Loss 3208.9319\n",
      "Iteration 11250 : Loss 3208.4002\n",
      "Iteration 11260 : Loss 3207.8693\n",
      "Iteration 11270 : Loss 3207.3392\n",
      "Iteration 11280 : Loss 3206.8100\n",
      "Iteration 11290 : Loss 3206.2815\n",
      "Iteration 11300 : Loss 3205.7539\n",
      "Iteration 11310 : Loss 3205.2271\n",
      "Iteration 11320 : Loss 3204.7012\n",
      "Iteration 11330 : Loss 3204.1760\n",
      "Iteration 11340 : Loss 3203.6517\n",
      "Iteration 11350 : Loss 3203.1281\n",
      "Iteration 11360 : Loss 3202.6054\n",
      "Iteration 11370 : Loss 3202.0835\n",
      "Iteration 11380 : Loss 3201.5624\n",
      "Iteration 11390 : Loss 3201.0421\n",
      "Iteration 11400 : Loss 3200.5226\n",
      "Iteration 11410 : Loss 3200.0039\n",
      "Iteration 11420 : Loss 3199.4860\n",
      "Iteration 11430 : Loss 3198.9688\n",
      "Iteration 11440 : Loss 3198.4525\n",
      "Iteration 11450 : Loss 3197.9370\n",
      "Iteration 11460 : Loss 3197.4223\n",
      "Iteration 11470 : Loss 3196.9083\n",
      "Iteration 11480 : Loss 3196.3951\n",
      "Iteration 11490 : Loss 3195.8828\n",
      "Iteration 11500 : Loss 3195.3712\n",
      "Iteration 11510 : Loss 3194.8604\n",
      "Iteration 11520 : Loss 3194.3503\n",
      "Iteration 11530 : Loss 3193.8411\n",
      "Iteration 11540 : Loss 3193.3326\n",
      "Iteration 11550 : Loss 3192.8249\n",
      "Iteration 11560 : Loss 3192.3179\n",
      "Iteration 11570 : Loss 3191.8118\n",
      "Iteration 11580 : Loss 3191.3064\n",
      "Iteration 11590 : Loss 3190.8018\n",
      "Iteration 11600 : Loss 3190.2979\n",
      "Iteration 11610 : Loss 3189.7948\n",
      "Iteration 11620 : Loss 3189.2925\n",
      "Iteration 11630 : Loss 3188.7909\n",
      "Iteration 11640 : Loss 3188.2901\n",
      "Iteration 11650 : Loss 3187.7900\n",
      "Iteration 11660 : Loss 3187.2907\n",
      "Iteration 11670 : Loss 3186.7922\n",
      "Iteration 11680 : Loss 3186.2944\n",
      "Iteration 11690 : Loss 3185.7973\n",
      "Iteration 11700 : Loss 3185.3010\n",
      "Iteration 11710 : Loss 3184.8055\n",
      "Iteration 11720 : Loss 3184.3107\n",
      "Iteration 11730 : Loss 3183.8166\n",
      "Iteration 11740 : Loss 3183.3233\n",
      "Iteration 11750 : Loss 3182.8307\n",
      "Iteration 11760 : Loss 3182.3388\n",
      "Iteration 11770 : Loss 3181.8477\n",
      "Iteration 11780 : Loss 3181.3574\n",
      "Iteration 11790 : Loss 3180.8677\n",
      "Iteration 11800 : Loss 3180.3788\n",
      "Iteration 11810 : Loss 3179.8906\n",
      "Iteration 11820 : Loss 3179.4032\n",
      "Iteration 11830 : Loss 3178.9165\n",
      "Iteration 11840 : Loss 3178.4305\n",
      "Iteration 11850 : Loss 3177.9452\n",
      "Iteration 11860 : Loss 3177.4606\n",
      "Iteration 11870 : Loss 3176.9768\n",
      "Iteration 11880 : Loss 3176.4937\n",
      "Iteration 11890 : Loss 3176.0113\n",
      "Iteration 11900 : Loss 3175.5296\n",
      "Iteration 11910 : Loss 3175.0487\n",
      "Iteration 11920 : Loss 3174.5684\n",
      "Iteration 11930 : Loss 3174.0889\n",
      "Iteration 11940 : Loss 3173.6100\n",
      "Iteration 11950 : Loss 3173.1319\n",
      "Iteration 11960 : Loss 3172.6545\n",
      "Iteration 11970 : Loss 3172.1778\n",
      "Iteration 11980 : Loss 3171.7018\n",
      "Iteration 11990 : Loss 3171.2264\n",
      "Iteration 12000 : Loss 3170.7518\n",
      "Iteration 12010 : Loss 3170.2779\n",
      "Iteration 12020 : Loss 3169.8047\n",
      "Iteration 12030 : Loss 3169.3322\n",
      "Iteration 12040 : Loss 3168.8604\n",
      "Iteration 12050 : Loss 3168.3892\n",
      "Iteration 12060 : Loss 3167.9188\n",
      "Iteration 12070 : Loss 3167.4490\n",
      "Iteration 12080 : Loss 3166.9800\n",
      "Iteration 12090 : Loss 3166.5116\n",
      "Iteration 12100 : Loss 3166.0439\n",
      "Iteration 12110 : Loss 3165.5769\n",
      "Iteration 12120 : Loss 3165.1105\n",
      "Iteration 12130 : Loss 3164.6449\n",
      "Iteration 12140 : Loss 3164.1799\n",
      "Iteration 12150 : Loss 3163.7156\n",
      "Iteration 12160 : Loss 3163.2520\n",
      "Iteration 12170 : Loss 3162.7891\n",
      "Iteration 12180 : Loss 3162.3268\n",
      "Iteration 12190 : Loss 3161.8652\n",
      "Iteration 12200 : Loss 3161.4043\n",
      "Iteration 12210 : Loss 3160.9440\n",
      "Iteration 12220 : Loss 3160.4844\n",
      "Iteration 12230 : Loss 3160.0255\n",
      "Iteration 12240 : Loss 3159.5672\n",
      "Iteration 12250 : Loss 3159.1096\n",
      "Iteration 12260 : Loss 3158.6527\n",
      "Iteration 12270 : Loss 3158.1964\n",
      "Iteration 12280 : Loss 3157.7408\n",
      "Iteration 12290 : Loss 3157.2858\n",
      "Iteration 12300 : Loss 3156.8315\n",
      "Iteration 12310 : Loss 3156.3778\n",
      "Iteration 12320 : Loss 3155.9248\n",
      "Iteration 12330 : Loss 3155.4725\n",
      "Iteration 12340 : Loss 3155.0208\n",
      "Iteration 12350 : Loss 3154.5697\n",
      "Iteration 12360 : Loss 3154.1193\n",
      "Iteration 12370 : Loss 3153.6695\n",
      "Iteration 12380 : Loss 3153.2204\n",
      "Iteration 12390 : Loss 3152.7719\n",
      "Iteration 12400 : Loss 3152.3241\n",
      "Iteration 12410 : Loss 3151.8769\n",
      "Iteration 12420 : Loss 3151.4304\n",
      "Iteration 12430 : Loss 3150.9845\n",
      "Iteration 12440 : Loss 3150.5392\n",
      "Iteration 12450 : Loss 3150.0945\n",
      "Iteration 12460 : Loss 3149.6505\n",
      "Iteration 12470 : Loss 3149.2071\n",
      "Iteration 12480 : Loss 3148.7644\n",
      "Iteration 12490 : Loss 3148.3223\n",
      "Iteration 12500 : Loss 3147.8808\n",
      "Iteration 12510 : Loss 3147.4399\n",
      "Iteration 12520 : Loss 3146.9997\n",
      "Iteration 12530 : Loss 3146.5600\n",
      "Iteration 12540 : Loss 3146.1210\n",
      "Iteration 12550 : Loss 3145.6827\n",
      "Iteration 12560 : Loss 3145.2449\n",
      "Iteration 12570 : Loss 3144.8078\n",
      "Iteration 12580 : Loss 3144.3713\n",
      "Iteration 12590 : Loss 3143.9354\n",
      "Iteration 12600 : Loss 3143.5001\n",
      "Iteration 12610 : Loss 3143.0654\n",
      "Iteration 12620 : Loss 3142.6313\n",
      "Iteration 12630 : Loss 3142.1979\n",
      "Iteration 12640 : Loss 3141.7650\n",
      "Iteration 12650 : Loss 3141.3328\n",
      "Iteration 12660 : Loss 3140.9012\n",
      "Iteration 12670 : Loss 3140.4702\n",
      "Iteration 12680 : Loss 3140.0397\n",
      "Iteration 12690 : Loss 3139.6099\n",
      "Iteration 12700 : Loss 3139.1807\n",
      "Iteration 12710 : Loss 3138.7521\n",
      "Iteration 12720 : Loss 3138.3241\n",
      "Iteration 12730 : Loss 3137.8967\n",
      "Iteration 12740 : Loss 3137.4699\n",
      "Iteration 12750 : Loss 3137.0436\n",
      "Iteration 12760 : Loss 3136.6180\n",
      "Iteration 12770 : Loss 3136.1930\n",
      "Iteration 12780 : Loss 3135.7685\n",
      "Iteration 12790 : Loss 3135.3447\n",
      "Iteration 12800 : Loss 3134.9214\n",
      "Iteration 12810 : Loss 3134.4987\n",
      "Iteration 12820 : Loss 3134.0767\n",
      "Iteration 12830 : Loss 3133.6552\n",
      "Iteration 12840 : Loss 3133.2342\n",
      "Iteration 12850 : Loss 3132.8139\n",
      "Iteration 12860 : Loss 3132.3942\n",
      "Iteration 12870 : Loss 3131.9750\n",
      "Iteration 12880 : Loss 3131.5564\n",
      "Iteration 12890 : Loss 3131.1384\n",
      "Iteration 12900 : Loss 3130.7210\n",
      "Iteration 12910 : Loss 3130.3041\n",
      "Iteration 12920 : Loss 3129.8878\n",
      "Iteration 12930 : Loss 3129.4721\n",
      "Iteration 12940 : Loss 3129.0570\n",
      "Iteration 12950 : Loss 3128.6424\n",
      "Iteration 12960 : Loss 3128.2284\n",
      "Iteration 12970 : Loss 3127.8150\n",
      "Iteration 12980 : Loss 3127.4021\n",
      "Iteration 12990 : Loss 3126.9898\n",
      "Iteration 13000 : Loss 3126.5781\n",
      "Iteration 13010 : Loss 3126.1669\n",
      "Iteration 13020 : Loss 3125.7563\n",
      "Iteration 13030 : Loss 3125.3463\n",
      "Iteration 13040 : Loss 3124.9368\n",
      "Iteration 13050 : Loss 3124.5279\n",
      "Iteration 13060 : Loss 3124.1195\n",
      "Iteration 13070 : Loss 3123.7117\n",
      "Iteration 13080 : Loss 3123.3045\n",
      "Iteration 13090 : Loss 3122.8978\n",
      "Iteration 13100 : Loss 3122.4916\n",
      "Iteration 13110 : Loss 3122.0861\n",
      "Iteration 13120 : Loss 3121.6810\n",
      "Iteration 13130 : Loss 3121.2765\n",
      "Iteration 13140 : Loss 3120.8726\n",
      "Iteration 13150 : Loss 3120.4692\n",
      "Iteration 13160 : Loss 3120.0664\n",
      "Iteration 13170 : Loss 3119.6641\n",
      "Iteration 13180 : Loss 3119.2624\n",
      "Iteration 13190 : Loss 3118.8611\n",
      "Iteration 13200 : Loss 3118.4605\n",
      "Iteration 13210 : Loss 3118.0604\n",
      "Iteration 13220 : Loss 3117.6608\n",
      "Iteration 13230 : Loss 3117.2618\n",
      "Iteration 13240 : Loss 3116.8633\n",
      "Iteration 13250 : Loss 3116.4653\n",
      "Iteration 13260 : Loss 3116.0679\n",
      "Iteration 13270 : Loss 3115.6710\n",
      "Iteration 13280 : Loss 3115.2746\n",
      "Iteration 13290 : Loss 3114.8788\n",
      "Iteration 13300 : Loss 3114.4835\n",
      "Iteration 13310 : Loss 3114.0887\n",
      "Iteration 13320 : Loss 3113.6945\n",
      "Iteration 13330 : Loss 3113.3008\n",
      "Iteration 13340 : Loss 3112.9076\n",
      "Iteration 13350 : Loss 3112.5150\n",
      "Iteration 13360 : Loss 3112.1229\n",
      "Iteration 13370 : Loss 3111.7313\n",
      "Iteration 13380 : Loss 3111.3402\n",
      "Iteration 13390 : Loss 3110.9496\n",
      "Iteration 13400 : Loss 3110.5596\n",
      "Iteration 13410 : Loss 3110.1701\n",
      "Iteration 13420 : Loss 3109.7811\n",
      "Iteration 13430 : Loss 3109.3926\n",
      "Iteration 13440 : Loss 3109.0047\n",
      "Iteration 13450 : Loss 3108.6172\n",
      "Iteration 13460 : Loss 3108.2303\n",
      "Iteration 13470 : Loss 3107.8439\n",
      "Iteration 13480 : Loss 3107.4580\n",
      "Iteration 13490 : Loss 3107.0726\n",
      "Iteration 13500 : Loss 3106.6877\n",
      "Iteration 13510 : Loss 3106.3034\n",
      "Iteration 13520 : Loss 3105.9195\n",
      "Iteration 13530 : Loss 3105.5362\n",
      "Iteration 13540 : Loss 3105.1533\n",
      "Iteration 13550 : Loss 3104.7710\n",
      "Iteration 13560 : Loss 3104.3892\n",
      "Iteration 13570 : Loss 3104.0078\n",
      "Iteration 13580 : Loss 3103.6270\n",
      "Iteration 13590 : Loss 3103.2467\n",
      "Iteration 13600 : Loss 3102.8669\n",
      "Iteration 13610 : Loss 3102.4875\n",
      "Iteration 13620 : Loss 3102.1087\n",
      "Iteration 13630 : Loss 3101.7304\n",
      "Iteration 13640 : Loss 3101.3526\n",
      "Iteration 13650 : Loss 3100.9752\n",
      "Iteration 13660 : Loss 3100.5984\n",
      "Iteration 13670 : Loss 3100.2221\n",
      "Iteration 13680 : Loss 3099.8462\n",
      "Iteration 13690 : Loss 3099.4709\n",
      "Iteration 13700 : Loss 3099.0960\n",
      "Iteration 13710 : Loss 3098.7216\n",
      "Iteration 13720 : Loss 3098.3477\n",
      "Iteration 13730 : Loss 3097.9743\n",
      "Iteration 13740 : Loss 3097.6014\n",
      "Iteration 13750 : Loss 3097.2290\n",
      "Iteration 13760 : Loss 3096.8571\n",
      "Iteration 13770 : Loss 3096.4856\n",
      "Iteration 13780 : Loss 3096.1147\n",
      "Iteration 13790 : Loss 3095.7442\n",
      "Iteration 13800 : Loss 3095.3742\n",
      "Iteration 13810 : Loss 3095.0047\n",
      "Iteration 13820 : Loss 3094.6356\n",
      "Iteration 13830 : Loss 3094.2670\n",
      "Iteration 13840 : Loss 3093.8990\n",
      "Iteration 13850 : Loss 3093.5314\n",
      "Iteration 13860 : Loss 3093.1642\n",
      "Iteration 13870 : Loss 3092.7976\n",
      "Iteration 13880 : Loss 3092.4314\n",
      "Iteration 13890 : Loss 3092.0657\n",
      "Iteration 13900 : Loss 3091.7004\n",
      "Iteration 13910 : Loss 3091.3357\n",
      "Iteration 13920 : Loss 3090.9714\n",
      "Iteration 13930 : Loss 3090.6076\n",
      "Iteration 13940 : Loss 3090.2442\n",
      "Iteration 13950 : Loss 3089.8813\n",
      "Iteration 13960 : Loss 3089.5189\n",
      "Iteration 13970 : Loss 3089.1569\n",
      "Iteration 13980 : Loss 3088.7954\n",
      "Iteration 13990 : Loss 3088.4344\n",
      "Iteration 14000 : Loss 3088.0739\n",
      "Iteration 14010 : Loss 3087.7138\n",
      "Iteration 14020 : Loss 3087.3541\n",
      "Iteration 14030 : Loss 3086.9950\n",
      "Iteration 14040 : Loss 3086.6362\n",
      "Iteration 14050 : Loss 3086.2780\n",
      "Iteration 14060 : Loss 3085.9202\n",
      "Iteration 14070 : Loss 3085.5628\n",
      "Iteration 14080 : Loss 3085.2060\n",
      "Iteration 14090 : Loss 3084.8495\n",
      "Iteration 14100 : Loss 3084.4936\n",
      "Iteration 14110 : Loss 3084.1380\n",
      "Iteration 14120 : Loss 3083.7830\n",
      "Iteration 14130 : Loss 3083.4284\n",
      "Iteration 14140 : Loss 3083.0742\n",
      "Iteration 14150 : Loss 3082.7205\n",
      "Iteration 14160 : Loss 3082.3672\n",
      "Iteration 14170 : Loss 3082.0144\n",
      "Iteration 14180 : Loss 3081.6620\n",
      "Iteration 14190 : Loss 3081.3101\n",
      "Iteration 14200 : Loss 3080.9586\n",
      "Iteration 14210 : Loss 3080.6076\n",
      "Iteration 14220 : Loss 3080.2570\n",
      "Iteration 14230 : Loss 3079.9069\n",
      "Iteration 14240 : Loss 3079.5572\n",
      "Iteration 14250 : Loss 3079.2080\n",
      "Iteration 14260 : Loss 3078.8591\n",
      "Iteration 14270 : Loss 3078.5108\n",
      "Iteration 14280 : Loss 3078.1628\n",
      "Iteration 14290 : Loss 3077.8153\n",
      "Iteration 14300 : Loss 3077.4683\n",
      "Iteration 14310 : Loss 3077.1217\n",
      "Iteration 14320 : Loss 3076.7755\n",
      "Iteration 14330 : Loss 3076.4297\n",
      "Iteration 14340 : Loss 3076.0844\n",
      "Iteration 14350 : Loss 3075.7395\n",
      "Iteration 14360 : Loss 3075.3951\n",
      "Iteration 14370 : Loss 3075.0511\n",
      "Iteration 14380 : Loss 3074.7075\n",
      "Iteration 14390 : Loss 3074.3644\n",
      "Iteration 14400 : Loss 3074.0216\n",
      "Iteration 14410 : Loss 3073.6793\n",
      "Iteration 14420 : Loss 3073.3375\n",
      "Iteration 14430 : Loss 3072.9960\n",
      "Iteration 14440 : Loss 3072.6550\n",
      "Iteration 14450 : Loss 3072.3144\n",
      "Iteration 14460 : Loss 3071.9743\n",
      "Iteration 14470 : Loss 3071.6346\n",
      "Iteration 14480 : Loss 3071.2952\n",
      "Iteration 14490 : Loss 3070.9564\n",
      "Iteration 14500 : Loss 3070.6179\n",
      "Iteration 14510 : Loss 3070.2798\n",
      "Iteration 14520 : Loss 3069.9422\n",
      "Iteration 14530 : Loss 3069.6050\n",
      "Iteration 14540 : Loss 3069.2682\n",
      "Iteration 14550 : Loss 3068.9319\n",
      "Iteration 14560 : Loss 3068.5959\n",
      "Iteration 14570 : Loss 3068.2604\n",
      "Iteration 14580 : Loss 3067.9253\n",
      "Iteration 14590 : Loss 3067.5906\n",
      "Iteration 14600 : Loss 3067.2563\n",
      "Iteration 14610 : Loss 3066.9224\n",
      "Iteration 14620 : Loss 3066.5889\n",
      "Iteration 14630 : Loss 3066.2559\n",
      "Iteration 14640 : Loss 3065.9232\n",
      "Iteration 14650 : Loss 3065.5910\n",
      "Iteration 14660 : Loss 3065.2592\n",
      "Iteration 14670 : Loss 3064.9278\n",
      "Iteration 14680 : Loss 3064.5968\n",
      "Iteration 14690 : Loss 3064.2662\n",
      "Iteration 14700 : Loss 3063.9360\n",
      "Iteration 14710 : Loss 3063.6062\n",
      "Iteration 14720 : Loss 3063.2768\n",
      "Iteration 14730 : Loss 3062.9479\n",
      "Iteration 14740 : Loss 3062.6193\n",
      "Iteration 14750 : Loss 3062.2911\n",
      "Iteration 14760 : Loss 3061.9634\n",
      "Iteration 14770 : Loss 3061.6360\n",
      "Iteration 14780 : Loss 3061.3090\n",
      "Iteration 14790 : Loss 3060.9825\n",
      "Iteration 14800 : Loss 3060.6563\n",
      "Iteration 14810 : Loss 3060.3306\n",
      "Iteration 14820 : Loss 3060.0052\n",
      "Iteration 14830 : Loss 3059.6802\n",
      "Iteration 14840 : Loss 3059.3557\n",
      "Iteration 14850 : Loss 3059.0315\n",
      "Iteration 14860 : Loss 3058.7077\n",
      "Iteration 14870 : Loss 3058.3843\n",
      "Iteration 14880 : Loss 3058.0613\n",
      "Iteration 14890 : Loss 3057.7387\n",
      "Iteration 14900 : Loss 3057.4165\n",
      "Iteration 14910 : Loss 3057.0947\n",
      "Iteration 14920 : Loss 3056.7733\n",
      "Iteration 14930 : Loss 3056.4523\n",
      "Iteration 14940 : Loss 3056.1316\n",
      "Iteration 14950 : Loss 3055.8114\n",
      "Iteration 14960 : Loss 3055.4915\n",
      "Iteration 14970 : Loss 3055.1720\n",
      "Iteration 14980 : Loss 3054.8529\n",
      "Iteration 14990 : Loss 3054.5342\n",
      "Iteration 15000 : Loss 3054.2159\n",
      "Iteration 15010 : Loss 3053.8980\n",
      "Iteration 15020 : Loss 3053.5804\n",
      "Iteration 15030 : Loss 3053.2633\n",
      "Iteration 15040 : Loss 3052.9465\n",
      "Iteration 15050 : Loss 3052.6301\n",
      "Iteration 15060 : Loss 3052.3140\n",
      "Iteration 15070 : Loss 3051.9984\n",
      "Iteration 15080 : Loss 3051.6831\n",
      "Iteration 15090 : Loss 3051.3683\n",
      "Iteration 15100 : Loss 3051.0538\n",
      "Iteration 15110 : Loss 3050.7396\n",
      "Iteration 15120 : Loss 3050.4259\n",
      "Iteration 15130 : Loss 3050.1125\n",
      "Iteration 15140 : Loss 3049.7995\n",
      "Iteration 15150 : Loss 3049.4869\n",
      "Iteration 15160 : Loss 3049.1747\n",
      "Iteration 15170 : Loss 3048.8628\n",
      "Iteration 15180 : Loss 3048.5513\n",
      "Iteration 15190 : Loss 3048.2402\n",
      "Iteration 15200 : Loss 3047.9294\n",
      "Iteration 15210 : Loss 3047.6190\n",
      "Iteration 15220 : Loss 3047.3090\n",
      "Iteration 15230 : Loss 3046.9994\n",
      "Iteration 15240 : Loss 3046.6901\n",
      "Iteration 15250 : Loss 3046.3812\n",
      "Iteration 15260 : Loss 3046.0727\n",
      "Iteration 15270 : Loss 3045.7645\n",
      "Iteration 15280 : Loss 3045.4567\n",
      "Iteration 15290 : Loss 3045.1493\n",
      "Iteration 15300 : Loss 3044.8422\n",
      "Iteration 15310 : Loss 3044.5355\n",
      "Iteration 15320 : Loss 3044.2291\n",
      "Iteration 15330 : Loss 3043.9232\n",
      "Iteration 15340 : Loss 3043.6176\n",
      "Iteration 15350 : Loss 3043.3123\n",
      "Iteration 15360 : Loss 3043.0074\n",
      "Iteration 15370 : Loss 3042.7029\n",
      "Iteration 15380 : Loss 3042.3987\n",
      "Iteration 15390 : Loss 3042.0949\n",
      "Iteration 15400 : Loss 3041.7915\n",
      "Iteration 15410 : Loss 3041.4884\n",
      "Iteration 15420 : Loss 3041.1856\n",
      "Iteration 15430 : Loss 3040.8833\n",
      "Iteration 15440 : Loss 3040.5813\n",
      "Iteration 15450 : Loss 3040.2796\n",
      "Iteration 15460 : Loss 3039.9783\n",
      "Iteration 15470 : Loss 3039.6773\n",
      "Iteration 15480 : Loss 3039.3767\n",
      "Iteration 15490 : Loss 3039.0765\n",
      "Iteration 15500 : Loss 3038.7766\n",
      "Iteration 15510 : Loss 3038.4771\n",
      "Iteration 15520 : Loss 3038.1779\n",
      "Iteration 15530 : Loss 3037.8791\n",
      "Iteration 15540 : Loss 3037.5806\n",
      "Iteration 15550 : Loss 3037.2825\n",
      "Iteration 15560 : Loss 3036.9847\n",
      "Iteration 15570 : Loss 3036.6872\n",
      "Iteration 15580 : Loss 3036.3902\n",
      "Iteration 15590 : Loss 3036.0934\n",
      "Iteration 15600 : Loss 3035.7970\n",
      "Iteration 15610 : Loss 3035.5010\n",
      "Iteration 15620 : Loss 3035.2053\n",
      "Iteration 15630 : Loss 3034.9099\n",
      "Iteration 15640 : Loss 3034.6149\n",
      "Iteration 15650 : Loss 3034.3203\n",
      "Iteration 15660 : Loss 3034.0259\n",
      "Iteration 15670 : Loss 3033.7320\n",
      "Iteration 15680 : Loss 3033.4383\n",
      "Iteration 15690 : Loss 3033.1450\n",
      "Iteration 15700 : Loss 3032.8521\n",
      "Iteration 15710 : Loss 3032.5595\n",
      "Iteration 15720 : Loss 3032.2672\n",
      "Iteration 15730 : Loss 3031.9753\n",
      "Iteration 15740 : Loss 3031.6837\n",
      "Iteration 15750 : Loss 3031.3924\n",
      "Iteration 15760 : Loss 3031.1015\n",
      "Iteration 15770 : Loss 3030.8109\n",
      "Iteration 15780 : Loss 3030.5207\n",
      "Iteration 15790 : Loss 3030.2308\n",
      "Iteration 15800 : Loss 3029.9412\n",
      "Iteration 15810 : Loss 3029.6520\n",
      "Iteration 15820 : Loss 3029.3631\n",
      "Iteration 15830 : Loss 3029.0745\n",
      "Iteration 15840 : Loss 3028.7863\n",
      "Iteration 15850 : Loss 3028.4984\n",
      "Iteration 15860 : Loss 3028.2108\n",
      "Iteration 15870 : Loss 3027.9236\n",
      "Iteration 15880 : Loss 3027.6367\n",
      "Iteration 15890 : Loss 3027.3501\n",
      "Iteration 15900 : Loss 3027.0639\n",
      "Iteration 15910 : Loss 3026.7780\n",
      "Iteration 15920 : Loss 3026.4924\n",
      "Iteration 15930 : Loss 3026.2071\n",
      "Iteration 15940 : Loss 3025.9222\n",
      "Iteration 15950 : Loss 3025.6376\n",
      "Iteration 15960 : Loss 3025.3533\n",
      "Iteration 15970 : Loss 3025.0694\n",
      "Iteration 15980 : Loss 3024.7857\n",
      "Iteration 15990 : Loss 3024.5024\n",
      "Iteration 16000 : Loss 3024.2195\n",
      "Iteration 16010 : Loss 3023.9368\n",
      "Iteration 16020 : Loss 3023.6545\n",
      "Iteration 16030 : Loss 3023.3725\n",
      "Iteration 16040 : Loss 3023.0908\n",
      "Iteration 16050 : Loss 3022.8095\n",
      "Iteration 16060 : Loss 3022.5284\n",
      "Iteration 16070 : Loss 3022.2477\n",
      "Iteration 16080 : Loss 3021.9673\n",
      "Iteration 16090 : Loss 3021.6872\n",
      "Iteration 16100 : Loss 3021.4075\n",
      "Iteration 16110 : Loss 3021.1280\n",
      "Iteration 16120 : Loss 3020.8489\n",
      "Iteration 16130 : Loss 3020.5701\n",
      "Iteration 16140 : Loss 3020.2916\n",
      "Iteration 16150 : Loss 3020.0135\n",
      "Iteration 16160 : Loss 3019.7356\n",
      "Iteration 16170 : Loss 3019.4581\n",
      "Iteration 16180 : Loss 3019.1809\n",
      "Iteration 16190 : Loss 3018.9040\n",
      "Iteration 16200 : Loss 3018.6274\n",
      "Iteration 16210 : Loss 3018.3511\n",
      "Iteration 16220 : Loss 3018.0751\n",
      "Iteration 16230 : Loss 3017.7995\n",
      "Iteration 16240 : Loss 3017.5241\n",
      "Iteration 16250 : Loss 3017.2491\n",
      "Iteration 16260 : Loss 3016.9744\n",
      "Iteration 16270 : Loss 3016.7000\n",
      "Iteration 16280 : Loss 3016.4259\n",
      "Iteration 16290 : Loss 3016.1521\n",
      "Iteration 16300 : Loss 3015.8786\n",
      "Iteration 16310 : Loss 3015.6054\n",
      "Iteration 16320 : Loss 3015.3326\n",
      "Iteration 16330 : Loss 3015.0600\n",
      "Iteration 16340 : Loss 3014.7878\n",
      "Iteration 16350 : Loss 3014.5158\n",
      "Iteration 16360 : Loss 3014.2442\n",
      "Iteration 16370 : Loss 3013.9729\n",
      "Iteration 16380 : Loss 3013.7018\n",
      "Iteration 16390 : Loss 3013.4311\n",
      "Iteration 16400 : Loss 3013.1607\n",
      "Iteration 16410 : Loss 3012.8906\n",
      "Iteration 16420 : Loss 3012.6208\n",
      "Iteration 16430 : Loss 3012.3513\n",
      "Iteration 16440 : Loss 3012.0821\n",
      "Iteration 16450 : Loss 3011.8132\n",
      "Iteration 16460 : Loss 3011.5446\n",
      "Iteration 16470 : Loss 3011.2763\n",
      "Iteration 16480 : Loss 3011.0083\n",
      "Iteration 16490 : Loss 3010.7406\n",
      "Iteration 16500 : Loss 3010.4732\n",
      "Iteration 16510 : Loss 3010.2061\n",
      "Iteration 16520 : Loss 3009.9393\n",
      "Iteration 16530 : Loss 3009.6728\n",
      "Iteration 16540 : Loss 3009.4066\n",
      "Iteration 16550 : Loss 3009.1406\n",
      "Iteration 16560 : Loss 3008.8750\n",
      "Iteration 16570 : Loss 3008.6097\n",
      "Iteration 16580 : Loss 3008.3447\n",
      "Iteration 16590 : Loss 3008.0799\n",
      "Iteration 16600 : Loss 3007.8155\n",
      "Iteration 16610 : Loss 3007.5514\n",
      "Iteration 16620 : Loss 3007.2875\n",
      "Iteration 16630 : Loss 3007.0240\n",
      "Iteration 16640 : Loss 3006.7607\n",
      "Iteration 16650 : Loss 3006.4977\n",
      "Iteration 16660 : Loss 3006.2351\n",
      "Iteration 16670 : Loss 3005.9727\n",
      "Iteration 16680 : Loss 3005.7106\n",
      "Iteration 16690 : Loss 3005.4488\n",
      "Iteration 16700 : Loss 3005.1873\n",
      "Iteration 16710 : Loss 3004.9260\n",
      "Iteration 16720 : Loss 3004.6651\n",
      "Iteration 16730 : Loss 3004.4045\n",
      "Iteration 16740 : Loss 3004.1441\n",
      "Iteration 16750 : Loss 3003.8840\n",
      "Iteration 16760 : Loss 3003.6242\n",
      "Iteration 16770 : Loss 3003.3647\n",
      "Iteration 16780 : Loss 3003.1055\n",
      "Iteration 16790 : Loss 3002.8466\n",
      "Iteration 16800 : Loss 3002.5880\n",
      "Iteration 16810 : Loss 3002.3296\n",
      "Iteration 16820 : Loss 3002.0715\n",
      "Iteration 16830 : Loss 3001.8137\n",
      "Iteration 16840 : Loss 3001.5562\n",
      "Iteration 16850 : Loss 3001.2990\n",
      "Iteration 16860 : Loss 3001.0421\n",
      "Iteration 16870 : Loss 3000.7854\n",
      "Iteration 16880 : Loss 3000.5291\n",
      "Iteration 16890 : Loss 3000.2730\n",
      "Iteration 16900 : Loss 3000.0171\n",
      "Iteration 16910 : Loss 2999.7616\n",
      "Iteration 16920 : Loss 2999.5064\n",
      "Iteration 16930 : Loss 2999.2514\n",
      "Iteration 16940 : Loss 2998.9967\n",
      "Iteration 16950 : Loss 2998.7423\n",
      "Iteration 16960 : Loss 2998.4882\n",
      "Iteration 16970 : Loss 2998.2343\n",
      "Iteration 16980 : Loss 2997.9807\n",
      "Iteration 16990 : Loss 2997.7274\n",
      "Iteration 17000 : Loss 2997.4744\n",
      "Iteration 17010 : Loss 2997.2216\n",
      "Iteration 17020 : Loss 2996.9692\n",
      "Iteration 17030 : Loss 2996.7170\n",
      "Iteration 17040 : Loss 2996.4650\n",
      "Iteration 17050 : Loss 2996.2134\n",
      "Iteration 17060 : Loss 2995.9620\n",
      "Iteration 17070 : Loss 2995.7109\n",
      "Iteration 17080 : Loss 2995.4601\n",
      "Iteration 17090 : Loss 2995.2095\n",
      "Iteration 17100 : Loss 2994.9593\n",
      "Iteration 17110 : Loss 2994.7092\n",
      "Iteration 17120 : Loss 2994.4595\n",
      "Iteration 17130 : Loss 2994.2100\n",
      "Iteration 17140 : Loss 2993.9608\n",
      "Iteration 17150 : Loss 2993.7119\n",
      "Iteration 17160 : Loss 2993.4633\n",
      "Iteration 17170 : Loss 2993.2149\n",
      "Iteration 17180 : Loss 2992.9668\n",
      "Iteration 17190 : Loss 2992.7189\n",
      "Iteration 17200 : Loss 2992.4713\n",
      "Iteration 17210 : Loss 2992.2240\n",
      "Iteration 17220 : Loss 2991.9770\n",
      "Iteration 17230 : Loss 2991.7302\n",
      "Iteration 17240 : Loss 2991.4837\n",
      "Iteration 17250 : Loss 2991.2374\n",
      "Iteration 17260 : Loss 2990.9914\n",
      "Iteration 17270 : Loss 2990.7457\n",
      "Iteration 17280 : Loss 2990.5003\n",
      "Iteration 17290 : Loss 2990.2551\n",
      "Iteration 17300 : Loss 2990.0102\n",
      "Iteration 17310 : Loss 2989.7655\n",
      "Iteration 17320 : Loss 2989.5211\n",
      "Iteration 17330 : Loss 2989.2770\n",
      "Iteration 17340 : Loss 2989.0331\n",
      "Iteration 17350 : Loss 2988.7895\n",
      "Iteration 17360 : Loss 2988.5462\n",
      "Iteration 17370 : Loss 2988.3031\n",
      "Iteration 17380 : Loss 2988.0603\n",
      "Iteration 17390 : Loss 2987.8177\n",
      "Iteration 17400 : Loss 2987.5754\n",
      "Iteration 17410 : Loss 2987.3334\n",
      "Iteration 17420 : Loss 2987.0916\n",
      "Iteration 17430 : Loss 2986.8501\n",
      "Iteration 17440 : Loss 2986.6088\n",
      "Iteration 17450 : Loss 2986.3678\n",
      "Iteration 17460 : Loss 2986.1271\n",
      "Iteration 17470 : Loss 2985.8866\n",
      "Iteration 17480 : Loss 2985.6463\n",
      "Iteration 17490 : Loss 2985.4064\n",
      "Iteration 17500 : Loss 2985.1667\n",
      "Iteration 17510 : Loss 2984.9272\n",
      "Iteration 17520 : Loss 2984.6880\n",
      "Iteration 17530 : Loss 2984.4490\n",
      "Iteration 17540 : Loss 2984.2103\n",
      "Iteration 17550 : Loss 2983.9719\n",
      "Iteration 17560 : Loss 2983.7337\n",
      "Iteration 17570 : Loss 2983.4958\n",
      "Iteration 17580 : Loss 2983.2581\n",
      "Iteration 17590 : Loss 2983.0207\n",
      "Iteration 17600 : Loss 2982.7835\n",
      "Iteration 17610 : Loss 2982.5466\n",
      "Iteration 17620 : Loss 2982.3099\n",
      "Iteration 17630 : Loss 2982.0735\n",
      "Iteration 17640 : Loss 2981.8373\n",
      "Iteration 17650 : Loss 2981.6014\n",
      "Iteration 17660 : Loss 2981.3657\n",
      "Iteration 17670 : Loss 2981.1303\n",
      "Iteration 17680 : Loss 2980.8951\n",
      "Iteration 17690 : Loss 2980.6602\n",
      "Iteration 17700 : Loss 2980.4256\n",
      "Iteration 17710 : Loss 2980.1911\n",
      "Iteration 17720 : Loss 2979.9570\n",
      "Iteration 17730 : Loss 2979.7230\n",
      "Iteration 17740 : Loss 2979.4894\n",
      "Iteration 17750 : Loss 2979.2559\n",
      "Iteration 17760 : Loss 2979.0227\n",
      "Iteration 17770 : Loss 2978.7898\n",
      "Iteration 17780 : Loss 2978.5571\n",
      "Iteration 17790 : Loss 2978.3247\n",
      "Iteration 17800 : Loss 2978.0925\n",
      "Iteration 17810 : Loss 2977.8605\n",
      "Iteration 17820 : Loss 2977.6288\n",
      "Iteration 17830 : Loss 2977.3973\n",
      "Iteration 17840 : Loss 2977.1661\n",
      "Iteration 17850 : Loss 2976.9351\n",
      "Iteration 17860 : Loss 2976.7044\n",
      "Iteration 17870 : Loss 2976.4739\n",
      "Iteration 17880 : Loss 2976.2437\n",
      "Iteration 17890 : Loss 2976.0136\n",
      "Iteration 17900 : Loss 2975.7839\n",
      "Iteration 17910 : Loss 2975.5544\n",
      "Iteration 17920 : Loss 2975.3251\n",
      "Iteration 17930 : Loss 2975.0960\n",
      "Iteration 17940 : Loss 2974.8672\n",
      "Iteration 17950 : Loss 2974.6387\n",
      "Iteration 17960 : Loss 2974.4103\n",
      "Iteration 17970 : Loss 2974.1823\n",
      "Iteration 17980 : Loss 2973.9544\n",
      "Iteration 17990 : Loss 2973.7268\n",
      "Iteration 18000 : Loss 2973.4994\n",
      "Iteration 18010 : Loss 2973.2723\n",
      "Iteration 18020 : Loss 2973.0454\n",
      "Iteration 18030 : Loss 2972.8188\n",
      "Iteration 18040 : Loss 2972.5923\n",
      "Iteration 18050 : Loss 2972.3661\n",
      "Iteration 18060 : Loss 2972.1402\n",
      "Iteration 18070 : Loss 2971.9145\n",
      "Iteration 18080 : Loss 2971.6890\n",
      "Iteration 18090 : Loss 2971.4638\n",
      "Iteration 18100 : Loss 2971.2388\n",
      "Iteration 18110 : Loss 2971.0140\n",
      "Iteration 18120 : Loss 2970.7895\n",
      "Iteration 18130 : Loss 2970.5652\n",
      "Iteration 18140 : Loss 2970.3411\n",
      "Iteration 18150 : Loss 2970.1173\n",
      "Iteration 18160 : Loss 2969.8937\n",
      "Iteration 18170 : Loss 2969.6703\n",
      "Iteration 18180 : Loss 2969.4471\n",
      "Iteration 18190 : Loss 2969.2242\n",
      "Iteration 18200 : Loss 2969.0016\n",
      "Iteration 18210 : Loss 2968.7791\n",
      "Iteration 18220 : Loss 2968.5569\n",
      "Iteration 18230 : Loss 2968.3349\n",
      "Iteration 18240 : Loss 2968.1132\n",
      "Iteration 18250 : Loss 2967.8916\n",
      "Iteration 18260 : Loss 2967.6704\n",
      "Iteration 18270 : Loss 2967.4493\n",
      "Iteration 18280 : Loss 2967.2285\n",
      "Iteration 18290 : Loss 2967.0078\n",
      "Iteration 18300 : Loss 2966.7875\n",
      "Iteration 18310 : Loss 2966.5673\n",
      "Iteration 18320 : Loss 2966.3474\n",
      "Iteration 18330 : Loss 2966.1277\n",
      "Iteration 18340 : Loss 2965.9082\n",
      "Iteration 18350 : Loss 2965.6890\n",
      "Iteration 18360 : Loss 2965.4700\n",
      "Iteration 18370 : Loss 2965.2512\n",
      "Iteration 18380 : Loss 2965.0326\n",
      "Iteration 18390 : Loss 2964.8143\n",
      "Iteration 18400 : Loss 2964.5962\n",
      "Iteration 18410 : Loss 2964.3783\n",
      "Iteration 18420 : Loss 2964.1606\n",
      "Iteration 18430 : Loss 2963.9432\n",
      "Iteration 18440 : Loss 2963.7260\n",
      "Iteration 18450 : Loss 2963.5090\n",
      "Iteration 18460 : Loss 2963.2922\n",
      "Iteration 18470 : Loss 2963.0756\n",
      "Iteration 18480 : Loss 2962.8593\n",
      "Iteration 18490 : Loss 2962.6432\n",
      "Iteration 18500 : Loss 2962.4273\n",
      "Iteration 18510 : Loss 2962.2117\n",
      "Iteration 18520 : Loss 2961.9962\n",
      "Iteration 18530 : Loss 2961.7810\n",
      "Iteration 18540 : Loss 2961.5660\n",
      "Iteration 18550 : Loss 2961.3513\n",
      "Iteration 18560 : Loss 2961.1367\n",
      "Iteration 18570 : Loss 2960.9224\n",
      "Iteration 18580 : Loss 2960.7082\n",
      "Iteration 18590 : Loss 2960.4943\n",
      "Iteration 18600 : Loss 2960.2807\n",
      "Iteration 18610 : Loss 2960.0672\n",
      "Iteration 18620 : Loss 2959.8540\n",
      "Iteration 18630 : Loss 2959.6409\n",
      "Iteration 18640 : Loss 2959.4281\n",
      "Iteration 18650 : Loss 2959.2155\n",
      "Iteration 18660 : Loss 2959.0032\n",
      "Iteration 18670 : Loss 2958.7910\n",
      "Iteration 18680 : Loss 2958.5791\n",
      "Iteration 18690 : Loss 2958.3673\n",
      "Iteration 18700 : Loss 2958.1558\n",
      "Iteration 18710 : Loss 2957.9445\n",
      "Iteration 18720 : Loss 2957.7335\n",
      "Iteration 18730 : Loss 2957.5226\n",
      "Iteration 18740 : Loss 2957.3120\n",
      "Iteration 18750 : Loss 2957.1015\n",
      "Iteration 18760 : Loss 2956.8913\n",
      "Iteration 18770 : Loss 2956.6813\n",
      "Iteration 18780 : Loss 2956.4715\n",
      "Iteration 18790 : Loss 2956.2619\n",
      "Iteration 18800 : Loss 2956.0526\n",
      "Iteration 18810 : Loss 2955.8434\n",
      "Iteration 18820 : Loss 2955.6345\n",
      "Iteration 18830 : Loss 2955.4257\n",
      "Iteration 18840 : Loss 2955.2172\n",
      "Iteration 18850 : Loss 2955.0089\n",
      "Iteration 18860 : Loss 2954.8008\n",
      "Iteration 18870 : Loss 2954.5929\n",
      "Iteration 18880 : Loss 2954.3853\n",
      "Iteration 18890 : Loss 2954.1778\n",
      "Iteration 18900 : Loss 2953.9705\n",
      "Iteration 18910 : Loss 2953.7635\n",
      "Iteration 18920 : Loss 2953.5567\n",
      "Iteration 18930 : Loss 2953.3500\n",
      "Iteration 18940 : Loss 2953.1436\n",
      "Iteration 18950 : Loss 2952.9374\n",
      "Iteration 18960 : Loss 2952.7314\n",
      "Iteration 18970 : Loss 2952.5256\n",
      "Iteration 18980 : Loss 2952.3200\n",
      "Iteration 18990 : Loss 2952.1146\n",
      "Iteration 19000 : Loss 2951.9095\n",
      "Iteration 19010 : Loss 2951.7045\n",
      "Iteration 19020 : Loss 2951.4997\n",
      "Iteration 19030 : Loss 2951.2952\n",
      "Iteration 19040 : Loss 2951.0909\n",
      "Iteration 19050 : Loss 2950.8867\n",
      "Iteration 19060 : Loss 2950.6828\n",
      "Iteration 19070 : Loss 2950.4790\n",
      "Iteration 19080 : Loss 2950.2755\n",
      "Iteration 19090 : Loss 2950.0722\n",
      "Iteration 19100 : Loss 2949.8691\n",
      "Iteration 19110 : Loss 2949.6662\n",
      "Iteration 19120 : Loss 2949.4635\n",
      "Iteration 19130 : Loss 2949.2610\n",
      "Iteration 19140 : Loss 2949.0587\n",
      "Iteration 19150 : Loss 2948.8566\n",
      "Iteration 19160 : Loss 2948.6547\n",
      "Iteration 19170 : Loss 2948.4530\n",
      "Iteration 19180 : Loss 2948.2515\n",
      "Iteration 19190 : Loss 2948.0502\n",
      "Iteration 19200 : Loss 2947.8491\n",
      "Iteration 19210 : Loss 2947.6482\n",
      "Iteration 19220 : Loss 2947.4475\n",
      "Iteration 19230 : Loss 2947.2470\n",
      "Iteration 19240 : Loss 2947.0468\n",
      "Iteration 19250 : Loss 2946.8467\n",
      "Iteration 19260 : Loss 2946.6468\n",
      "Iteration 19270 : Loss 2946.4471\n",
      "Iteration 19280 : Loss 2946.2476\n",
      "Iteration 19290 : Loss 2946.0483\n",
      "Iteration 19300 : Loss 2945.8492\n",
      "Iteration 19310 : Loss 2945.6504\n",
      "Iteration 19320 : Loss 2945.4517\n",
      "Iteration 19330 : Loss 2945.2532\n",
      "Iteration 19340 : Loss 2945.0549\n",
      "Iteration 19350 : Loss 2944.8568\n",
      "Iteration 19360 : Loss 2944.6589\n",
      "Iteration 19370 : Loss 2944.4612\n",
      "Iteration 19380 : Loss 2944.2637\n",
      "Iteration 19390 : Loss 2944.0664\n",
      "Iteration 19400 : Loss 2943.8692\n",
      "Iteration 19410 : Loss 2943.6723\n",
      "Iteration 19420 : Loss 2943.4756\n",
      "Iteration 19430 : Loss 2943.2791\n",
      "Iteration 19440 : Loss 2943.0827\n",
      "Iteration 19450 : Loss 2942.8866\n",
      "Iteration 19460 : Loss 2942.6907\n",
      "Iteration 19470 : Loss 2942.4949\n",
      "Iteration 19480 : Loss 2942.2994\n",
      "Iteration 19490 : Loss 2942.1040\n",
      "Iteration 19500 : Loss 2941.9088\n",
      "Iteration 19510 : Loss 2941.7139\n",
      "Iteration 19520 : Loss 2941.5191\n",
      "Iteration 19530 : Loss 2941.3245\n",
      "Iteration 19540 : Loss 2941.1301\n",
      "Iteration 19550 : Loss 2940.9359\n",
      "Iteration 19560 : Loss 2940.7419\n",
      "Iteration 19570 : Loss 2940.5481\n",
      "Iteration 19580 : Loss 2940.3544\n",
      "Iteration 19590 : Loss 2940.1610\n",
      "Iteration 19600 : Loss 2939.9678\n",
      "Iteration 19610 : Loss 2939.7747\n",
      "Iteration 19620 : Loss 2939.5819\n",
      "Iteration 19630 : Loss 2939.3892\n",
      "Iteration 19640 : Loss 2939.1967\n",
      "Iteration 19650 : Loss 2939.0044\n",
      "Iteration 19660 : Loss 2938.8123\n",
      "Iteration 19670 : Loss 2938.6204\n",
      "Iteration 19680 : Loss 2938.4287\n",
      "Iteration 19690 : Loss 2938.2371\n",
      "Iteration 19700 : Loss 2938.0458\n",
      "Iteration 19710 : Loss 2937.8546\n",
      "Iteration 19720 : Loss 2937.6637\n",
      "Iteration 19730 : Loss 2937.4729\n",
      "Iteration 19740 : Loss 2937.2823\n",
      "Iteration 19750 : Loss 2937.0919\n",
      "Iteration 19760 : Loss 2936.9016\n",
      "Iteration 19770 : Loss 2936.7116\n",
      "Iteration 19780 : Loss 2936.5218\n",
      "Iteration 19790 : Loss 2936.3321\n",
      "Iteration 19800 : Loss 2936.1426\n",
      "Iteration 19810 : Loss 2935.9533\n",
      "Iteration 19820 : Loss 2935.7642\n",
      "Iteration 19830 : Loss 2935.5753\n",
      "Iteration 19840 : Loss 2935.3866\n",
      "Iteration 19850 : Loss 2935.1980\n",
      "Iteration 19860 : Loss 2935.0097\n",
      "Iteration 19870 : Loss 2934.8215\n",
      "Iteration 19880 : Loss 2934.6335\n",
      "Iteration 19890 : Loss 2934.4457\n",
      "Iteration 19900 : Loss 2934.2581\n",
      "Iteration 19910 : Loss 2934.0706\n",
      "Iteration 19920 : Loss 2933.8834\n",
      "Iteration 19930 : Loss 2933.6963\n",
      "Iteration 19940 : Loss 2933.5094\n",
      "Iteration 19950 : Loss 2933.3227\n",
      "Iteration 19960 : Loss 2933.1362\n",
      "Iteration 19970 : Loss 2932.9498\n",
      "Iteration 19980 : Loss 2932.7636\n",
      "Iteration 19990 : Loss 2932.5777\n",
      "Iteration 20000 : Loss 2932.3919\n",
      "Iteration 20010 : Loss 2932.2062\n",
      "Iteration 20020 : Loss 2932.0208\n",
      "Iteration 20030 : Loss 2931.8355\n",
      "Iteration 20040 : Loss 2931.6505\n",
      "Iteration 20050 : Loss 2931.4656\n",
      "Iteration 20060 : Loss 2931.2808\n",
      "Iteration 20070 : Loss 2931.0963\n",
      "Iteration 20080 : Loss 2930.9119\n",
      "Iteration 20090 : Loss 2930.7278\n",
      "Iteration 20100 : Loss 2930.5438\n",
      "Iteration 20110 : Loss 2930.3599\n",
      "Iteration 20120 : Loss 2930.1763\n",
      "Iteration 20130 : Loss 2929.9928\n",
      "Iteration 20140 : Loss 2929.8095\n",
      "Iteration 20150 : Loss 2929.6264\n",
      "Iteration 20160 : Loss 2929.4435\n",
      "Iteration 20170 : Loss 2929.2607\n",
      "Iteration 20180 : Loss 2929.0782\n",
      "Iteration 20190 : Loss 2928.8958\n",
      "Iteration 20200 : Loss 2928.7135\n",
      "Iteration 20210 : Loss 2928.5315\n",
      "Iteration 20220 : Loss 2928.3496\n",
      "Iteration 20230 : Loss 2928.1679\n",
      "Iteration 20240 : Loss 2927.9864\n",
      "Iteration 20250 : Loss 2927.8051\n",
      "Iteration 20260 : Loss 2927.6239\n",
      "Iteration 20270 : Loss 2927.4429\n",
      "Iteration 20280 : Loss 2927.2621\n",
      "Iteration 20290 : Loss 2927.0815\n",
      "Iteration 20300 : Loss 2926.9010\n",
      "Iteration 20310 : Loss 2926.7207\n",
      "Iteration 20320 : Loss 2926.5406\n",
      "Iteration 20330 : Loss 2926.3606\n",
      "Iteration 20340 : Loss 2926.1809\n",
      "Iteration 20350 : Loss 2926.0013\n",
      "Iteration 20360 : Loss 2925.8218\n",
      "Iteration 20370 : Loss 2925.6426\n",
      "Iteration 20380 : Loss 2925.4635\n",
      "Iteration 20390 : Loss 2925.2846\n",
      "Iteration 20400 : Loss 2925.1059\n",
      "Iteration 20410 : Loss 2924.9273\n",
      "Iteration 20420 : Loss 2924.7489\n",
      "Iteration 20430 : Loss 2924.5707\n",
      "Iteration 20440 : Loss 2924.3927\n",
      "Iteration 20450 : Loss 2924.2148\n",
      "Iteration 20460 : Loss 2924.0371\n",
      "Iteration 20470 : Loss 2923.8595\n",
      "Iteration 20480 : Loss 2923.6822\n",
      "Iteration 20490 : Loss 2923.5050\n",
      "Iteration 20500 : Loss 2923.3280\n",
      "Iteration 20510 : Loss 2923.1511\n",
      "Iteration 20520 : Loss 2922.9744\n",
      "Iteration 20530 : Loss 2922.7979\n",
      "Iteration 20540 : Loss 2922.6216\n",
      "Iteration 20550 : Loss 2922.4454\n",
      "Iteration 20560 : Loss 2922.2694\n",
      "Iteration 20570 : Loss 2922.0936\n",
      "Iteration 20580 : Loss 2921.9179\n",
      "Iteration 20590 : Loss 2921.7424\n",
      "Iteration 20600 : Loss 2921.5671\n",
      "Iteration 20610 : Loss 2921.3919\n",
      "Iteration 20620 : Loss 2921.2169\n",
      "Iteration 20630 : Loss 2921.0421\n",
      "Iteration 20640 : Loss 2920.8674\n",
      "Iteration 20650 : Loss 2920.6929\n",
      "Iteration 20660 : Loss 2920.5186\n",
      "Iteration 20670 : Loss 2920.3444\n",
      "Iteration 20680 : Loss 2920.1704\n",
      "Iteration 20690 : Loss 2919.9966\n",
      "Iteration 20700 : Loss 2919.8229\n",
      "Iteration 20710 : Loss 2919.6494\n",
      "Iteration 20720 : Loss 2919.4761\n",
      "Iteration 20730 : Loss 2919.3029\n",
      "Iteration 20740 : Loss 2919.1299\n",
      "Iteration 20750 : Loss 2918.9571\n",
      "Iteration 20760 : Loss 2918.7844\n",
      "Iteration 20770 : Loss 2918.6119\n",
      "Iteration 20780 : Loss 2918.4396\n",
      "Iteration 20790 : Loss 2918.2674\n",
      "Iteration 20800 : Loss 2918.0954\n",
      "Iteration 20810 : Loss 2917.9235\n",
      "Iteration 20820 : Loss 2917.7519\n",
      "Iteration 20830 : Loss 2917.5803\n",
      "Iteration 20840 : Loss 2917.4090\n",
      "Iteration 20850 : Loss 2917.2378\n",
      "Iteration 20860 : Loss 2917.0667\n",
      "Iteration 20870 : Loss 2916.8959\n",
      "Iteration 20880 : Loss 2916.7252\n",
      "Iteration 20890 : Loss 2916.5546\n",
      "Iteration 20900 : Loss 2916.3842\n",
      "Iteration 20910 : Loss 2916.2140\n",
      "Iteration 20920 : Loss 2916.0439\n",
      "Iteration 20930 : Loss 2915.8740\n",
      "Iteration 20940 : Loss 2915.7043\n",
      "Iteration 20950 : Loss 2915.5347\n",
      "Iteration 20960 : Loss 2915.3653\n",
      "Iteration 20970 : Loss 2915.1961\n",
      "Iteration 20980 : Loss 2915.0270\n",
      "Iteration 20990 : Loss 2914.8580\n",
      "Iteration 21000 : Loss 2914.6892\n",
      "Iteration 21010 : Loss 2914.5206\n",
      "Iteration 21020 : Loss 2914.3522\n",
      "Iteration 21030 : Loss 2914.1839\n",
      "Iteration 21040 : Loss 2914.0157\n",
      "Iteration 21050 : Loss 2913.8477\n",
      "Iteration 21060 : Loss 2913.6799\n",
      "Iteration 21070 : Loss 2913.5123\n",
      "Iteration 21080 : Loss 2913.3448\n",
      "Iteration 21090 : Loss 2913.1774\n",
      "Iteration 21100 : Loss 2913.0102\n",
      "Iteration 21110 : Loss 2912.8432\n",
      "Iteration 21120 : Loss 2912.6763\n",
      "Iteration 21130 : Loss 2912.5096\n",
      "Iteration 21140 : Loss 2912.3430\n",
      "Iteration 21150 : Loss 2912.1766\n",
      "Iteration 21160 : Loss 2912.0104\n",
      "Iteration 21170 : Loss 2911.8443\n",
      "Iteration 21180 : Loss 2911.6784\n",
      "Iteration 21190 : Loss 2911.5126\n",
      "Iteration 21200 : Loss 2911.3470\n",
      "Iteration 21210 : Loss 2911.1815\n",
      "Iteration 21220 : Loss 2911.0162\n",
      "Iteration 21230 : Loss 2910.8511\n",
      "Iteration 21240 : Loss 2910.6861\n",
      "Iteration 21250 : Loss 2910.5212\n",
      "Iteration 21260 : Loss 2910.3565\n",
      "Iteration 21270 : Loss 2910.1920\n",
      "Iteration 21280 : Loss 2910.0276\n",
      "Iteration 21290 : Loss 2909.8634\n",
      "Iteration 21300 : Loss 2909.6994\n",
      "Iteration 21310 : Loss 2909.5354\n",
      "Iteration 21320 : Loss 2909.3717\n",
      "Iteration 21330 : Loss 2909.2081\n",
      "Iteration 21340 : Loss 2909.0446\n",
      "Iteration 21350 : Loss 2908.8813\n",
      "Iteration 21360 : Loss 2908.7182\n",
      "Iteration 21370 : Loss 2908.5552\n",
      "Iteration 21380 : Loss 2908.3923\n",
      "Iteration 21390 : Loss 2908.2297\n",
      "Iteration 21400 : Loss 2908.0671\n",
      "Iteration 21410 : Loss 2907.9047\n",
      "Iteration 21420 : Loss 2907.7425\n",
      "Iteration 21430 : Loss 2907.5804\n",
      "Iteration 21440 : Loss 2907.4185\n",
      "Iteration 21450 : Loss 2907.2567\n",
      "Iteration 21460 : Loss 2907.0951\n",
      "Iteration 21470 : Loss 2906.9336\n",
      "Iteration 21480 : Loss 2906.7723\n",
      "Iteration 21490 : Loss 2906.6111\n",
      "Iteration 21500 : Loss 2906.4501\n",
      "Iteration 21510 : Loss 2906.2892\n",
      "Iteration 21520 : Loss 2906.1285\n",
      "Iteration 21530 : Loss 2905.9679\n",
      "Iteration 21540 : Loss 2905.8075\n",
      "Iteration 21550 : Loss 2905.6472\n",
      "Iteration 21560 : Loss 2905.4871\n",
      "Iteration 21570 : Loss 2905.3271\n",
      "Iteration 21580 : Loss 2905.1673\n",
      "Iteration 21590 : Loss 2905.0076\n",
      "Iteration 21600 : Loss 2904.8481\n",
      "Iteration 21610 : Loss 2904.6887\n",
      "Iteration 21620 : Loss 2904.5295\n",
      "Iteration 21630 : Loss 2904.3704\n",
      "Iteration 21640 : Loss 2904.2115\n",
      "Iteration 21650 : Loss 2904.0527\n",
      "Iteration 21660 : Loss 2903.8941\n",
      "Iteration 21670 : Loss 2903.7356\n",
      "Iteration 21680 : Loss 2903.5772\n",
      "Iteration 21690 : Loss 2903.4190\n",
      "Iteration 21700 : Loss 2903.2610\n",
      "Iteration 21710 : Loss 2903.1031\n",
      "Iteration 21720 : Loss 2902.9453\n",
      "Iteration 21730 : Loss 2902.7877\n",
      "Iteration 21740 : Loss 2902.6303\n",
      "Iteration 21750 : Loss 2902.4730\n",
      "Iteration 21760 : Loss 2902.3158\n",
      "Iteration 21770 : Loss 2902.1588\n",
      "Iteration 21780 : Loss 2902.0019\n",
      "Iteration 21790 : Loss 2901.8451\n",
      "Iteration 21800 : Loss 2901.6886\n",
      "Iteration 21810 : Loss 2901.5321\n",
      "Iteration 21820 : Loss 2901.3758\n",
      "Iteration 21830 : Loss 2901.2197\n",
      "Iteration 21840 : Loss 2901.0637\n",
      "Iteration 21850 : Loss 2900.9078\n",
      "Iteration 21860 : Loss 2900.7521\n",
      "Iteration 21870 : Loss 2900.5965\n",
      "Iteration 21880 : Loss 2900.4411\n",
      "Iteration 21890 : Loss 2900.2858\n",
      "Iteration 21900 : Loss 2900.1306\n",
      "Iteration 21910 : Loss 2899.9756\n",
      "Iteration 21920 : Loss 2899.8208\n",
      "Iteration 21930 : Loss 2899.6661\n",
      "Iteration 21940 : Loss 2899.5115\n",
      "Iteration 21950 : Loss 2899.3570\n",
      "Iteration 21960 : Loss 2899.2028\n",
      "Iteration 21970 : Loss 2899.0486\n",
      "Iteration 21980 : Loss 2898.8946\n",
      "Iteration 21990 : Loss 2898.7408\n",
      "Iteration 22000 : Loss 2898.5870\n",
      "Iteration 22010 : Loss 2898.4335\n",
      "Iteration 22020 : Loss 2898.2800\n",
      "Iteration 22030 : Loss 2898.1267\n",
      "Iteration 22040 : Loss 2897.9736\n",
      "Iteration 22050 : Loss 2897.8206\n",
      "Iteration 22060 : Loss 2897.6677\n",
      "Iteration 22070 : Loss 2897.5150\n",
      "Iteration 22080 : Loss 2897.3624\n",
      "Iteration 22090 : Loss 2897.2099\n",
      "Iteration 22100 : Loss 2897.0576\n",
      "Iteration 22110 : Loss 2896.9054\n",
      "Iteration 22120 : Loss 2896.7534\n",
      "Iteration 22130 : Loss 2896.6015\n",
      "Iteration 22140 : Loss 2896.4498\n",
      "Iteration 22150 : Loss 2896.2982\n",
      "Iteration 22160 : Loss 2896.1467\n",
      "Iteration 22170 : Loss 2895.9954\n",
      "Iteration 22180 : Loss 2895.8442\n",
      "Iteration 22190 : Loss 2895.6931\n",
      "Iteration 22200 : Loss 2895.5422\n",
      "Iteration 22210 : Loss 2895.3914\n",
      "Iteration 22220 : Loss 2895.2408\n",
      "Iteration 22230 : Loss 2895.0903\n",
      "Iteration 22240 : Loss 2894.9399\n",
      "Iteration 22250 : Loss 2894.7897\n",
      "Iteration 22260 : Loss 2894.6396\n",
      "Iteration 22270 : Loss 2894.4897\n",
      "Iteration 22280 : Loss 2894.3399\n",
      "Iteration 22290 : Loss 2894.1902\n",
      "Iteration 22300 : Loss 2894.0406\n",
      "Iteration 22310 : Loss 2893.8912\n",
      "Iteration 22320 : Loss 2893.7420\n",
      "Iteration 22330 : Loss 2893.5928\n",
      "Iteration 22340 : Loss 2893.4439\n",
      "Iteration 22350 : Loss 2893.2950\n",
      "Iteration 22360 : Loss 2893.1463\n",
      "Iteration 22370 : Loss 2892.9977\n",
      "Iteration 22380 : Loss 2892.8492\n",
      "Iteration 22390 : Loss 2892.7009\n",
      "Iteration 22400 : Loss 2892.5528\n",
      "Iteration 22410 : Loss 2892.4047\n",
      "Iteration 22420 : Loss 2892.2568\n",
      "Iteration 22430 : Loss 2892.1090\n",
      "Iteration 22440 : Loss 2891.9614\n",
      "Iteration 22450 : Loss 2891.8139\n",
      "Iteration 22460 : Loss 2891.6665\n",
      "Iteration 22470 : Loss 2891.5193\n",
      "Iteration 22480 : Loss 2891.3722\n",
      "Iteration 22490 : Loss 2891.2252\n",
      "Iteration 22500 : Loss 2891.0784\n",
      "Iteration 22510 : Loss 2890.9317\n",
      "Iteration 22520 : Loss 2890.7851\n",
      "Iteration 22530 : Loss 2890.6387\n",
      "Iteration 22540 : Loss 2890.4924\n",
      "Iteration 22550 : Loss 2890.3462\n",
      "Iteration 22560 : Loss 2890.2002\n",
      "Iteration 22570 : Loss 2890.0543\n",
      "Iteration 22580 : Loss 2889.9086\n",
      "Iteration 22590 : Loss 2889.7629\n",
      "Iteration 22600 : Loss 2889.6174\n",
      "Iteration 22610 : Loss 2889.4720\n",
      "Iteration 22620 : Loss 2889.3268\n",
      "Iteration 22630 : Loss 2889.1817\n",
      "Iteration 22640 : Loss 2889.0367\n",
      "Iteration 22650 : Loss 2888.8919\n",
      "Iteration 22660 : Loss 2888.7472\n",
      "Iteration 22670 : Loss 2888.6026\n",
      "Iteration 22680 : Loss 2888.4582\n",
      "Iteration 22690 : Loss 2888.3138\n",
      "Iteration 22700 : Loss 2888.1697\n",
      "Iteration 22710 : Loss 2888.0256\n",
      "Iteration 22720 : Loss 2887.8817\n",
      "Iteration 22730 : Loss 2887.7379\n",
      "Iteration 22740 : Loss 2887.5942\n",
      "Iteration 22750 : Loss 2887.4507\n",
      "Iteration 22760 : Loss 2887.3073\n",
      "Iteration 22770 : Loss 2887.1640\n",
      "Iteration 22780 : Loss 2887.0209\n",
      "Iteration 22790 : Loss 2886.8778\n",
      "Iteration 22800 : Loss 2886.7350\n",
      "Iteration 22810 : Loss 2886.5922\n",
      "Iteration 22820 : Loss 2886.4496\n",
      "Iteration 22830 : Loss 2886.3071\n",
      "Iteration 22840 : Loss 2886.1647\n",
      "Iteration 22850 : Loss 2886.0225\n",
      "Iteration 22860 : Loss 2885.8804\n",
      "Iteration 22870 : Loss 2885.7384\n",
      "Iteration 22880 : Loss 2885.5965\n",
      "Iteration 22890 : Loss 2885.4548\n",
      "Iteration 22900 : Loss 2885.3132\n",
      "Iteration 22910 : Loss 2885.1717\n",
      "Iteration 22920 : Loss 2885.0304\n",
      "Iteration 22930 : Loss 2884.8892\n",
      "Iteration 22940 : Loss 2884.7481\n",
      "Iteration 22950 : Loss 2884.6071\n",
      "Iteration 22960 : Loss 2884.4663\n",
      "Iteration 22970 : Loss 2884.3256\n",
      "Iteration 22980 : Loss 2884.1850\n",
      "Iteration 22990 : Loss 2884.0445\n",
      "Iteration 23000 : Loss 2883.9042\n",
      "Iteration 23010 : Loss 2883.7640\n",
      "Iteration 23020 : Loss 2883.6239\n",
      "Iteration 23030 : Loss 2883.4840\n",
      "Iteration 23040 : Loss 2883.3441\n",
      "Iteration 23050 : Loss 2883.2044\n",
      "Iteration 23060 : Loss 2883.0649\n",
      "Iteration 23070 : Loss 2882.9254\n",
      "Iteration 23080 : Loss 2882.7861\n",
      "Iteration 23090 : Loss 2882.6469\n",
      "Iteration 23100 : Loss 2882.5078\n",
      "Iteration 23110 : Loss 2882.3689\n",
      "Iteration 23120 : Loss 2882.2301\n",
      "Iteration 23130 : Loss 2882.0914\n",
      "Iteration 23140 : Loss 2881.9528\n",
      "Iteration 23150 : Loss 2881.8143\n",
      "Iteration 23160 : Loss 2881.6760\n",
      "Iteration 23170 : Loss 2881.5378\n",
      "Iteration 23180 : Loss 2881.3997\n",
      "Iteration 23190 : Loss 2881.2618\n",
      "Iteration 23200 : Loss 2881.1239\n",
      "Iteration 23210 : Loss 2880.9862\n",
      "Iteration 23220 : Loss 2880.8487\n",
      "Iteration 23230 : Loss 2880.7112\n",
      "Iteration 23240 : Loss 2880.5739\n",
      "Iteration 23250 : Loss 2880.4367\n",
      "Iteration 23260 : Loss 2880.2996\n",
      "Iteration 23270 : Loss 2880.1626\n",
      "Iteration 23280 : Loss 2880.0257\n",
      "Iteration 23290 : Loss 2879.8890\n",
      "Iteration 23300 : Loss 2879.7524\n",
      "Iteration 23310 : Loss 2879.6159\n",
      "Iteration 23320 : Loss 2879.4796\n",
      "Iteration 23330 : Loss 2879.3434\n",
      "Iteration 23340 : Loss 2879.2072\n",
      "Iteration 23350 : Loss 2879.0713\n",
      "Iteration 23360 : Loss 2878.9354\n",
      "Iteration 23370 : Loss 2878.7996\n",
      "Iteration 23380 : Loss 2878.6640\n",
      "Iteration 23390 : Loss 2878.5285\n",
      "Iteration 23400 : Loss 2878.3931\n",
      "Iteration 23410 : Loss 2878.2579\n",
      "Iteration 23420 : Loss 2878.1227\n",
      "Iteration 23430 : Loss 2877.9877\n",
      "Iteration 23440 : Loss 2877.8528\n",
      "Iteration 23450 : Loss 2877.7180\n",
      "Iteration 23460 : Loss 2877.5833\n",
      "Iteration 23470 : Loss 2877.4488\n",
      "Iteration 23480 : Loss 2877.3144\n",
      "Iteration 23490 : Loss 2877.1801\n",
      "Iteration 23500 : Loss 2877.0459\n",
      "Iteration 23510 : Loss 2876.9118\n",
      "Iteration 23520 : Loss 2876.7779\n",
      "Iteration 23530 : Loss 2876.6441\n",
      "Iteration 23540 : Loss 2876.5103\n",
      "Iteration 23550 : Loss 2876.3768\n",
      "Iteration 23560 : Loss 2876.2433\n",
      "Iteration 23570 : Loss 2876.1099\n",
      "Iteration 23580 : Loss 2875.9767\n",
      "Iteration 23590 : Loss 2875.8436\n",
      "Iteration 23600 : Loss 2875.7106\n",
      "Iteration 23610 : Loss 2875.5777\n",
      "Iteration 23620 : Loss 2875.4450\n",
      "Iteration 23630 : Loss 2875.3123\n",
      "Iteration 23640 : Loss 2875.1798\n",
      "Iteration 23650 : Loss 2875.0474\n",
      "Iteration 23660 : Loss 2874.9151\n",
      "Iteration 23670 : Loss 2874.7829\n",
      "Iteration 23680 : Loss 2874.6509\n",
      "Iteration 23690 : Loss 2874.5189\n",
      "Iteration 23700 : Loss 2874.3871\n",
      "Iteration 23710 : Loss 2874.2554\n",
      "Iteration 23720 : Loss 2874.1238\n",
      "Iteration 23730 : Loss 2873.9924\n",
      "Iteration 23740 : Loss 2873.8610\n",
      "Iteration 23750 : Loss 2873.7298\n",
      "Iteration 23760 : Loss 2873.5987\n",
      "Iteration 23770 : Loss 2873.4677\n",
      "Iteration 23780 : Loss 2873.3368\n",
      "Iteration 23790 : Loss 2873.2060\n",
      "Iteration 23800 : Loss 2873.0753\n",
      "Iteration 23810 : Loss 2872.9448\n",
      "Iteration 23820 : Loss 2872.8144\n",
      "Iteration 23830 : Loss 2872.6841\n",
      "Iteration 23840 : Loss 2872.5539\n",
      "Iteration 23850 : Loss 2872.4238\n",
      "Iteration 23860 : Loss 2872.2938\n",
      "Iteration 23870 : Loss 2872.1640\n",
      "Iteration 23880 : Loss 2872.0342\n",
      "Iteration 23890 : Loss 2871.9046\n",
      "Iteration 23900 : Loss 2871.7751\n",
      "Iteration 23910 : Loss 2871.6457\n",
      "Iteration 23920 : Loss 2871.5164\n",
      "Iteration 23930 : Loss 2871.3873\n",
      "Iteration 23940 : Loss 2871.2582\n",
      "Iteration 23950 : Loss 2871.1293\n",
      "Iteration 23960 : Loss 2871.0005\n",
      "Iteration 23970 : Loss 2870.8718\n",
      "Iteration 23980 : Loss 2870.7432\n",
      "Iteration 23990 : Loss 2870.6147\n",
      "Iteration 24000 : Loss 2870.4863\n",
      "Iteration 24010 : Loss 2870.3580\n",
      "Iteration 24020 : Loss 2870.2299\n",
      "Iteration 24030 : Loss 2870.1019\n",
      "Iteration 24040 : Loss 2869.9740\n",
      "Iteration 24050 : Loss 2869.8461\n",
      "Iteration 24060 : Loss 2869.7185\n",
      "Iteration 24070 : Loss 2869.5909\n",
      "Iteration 24080 : Loss 2869.4634\n",
      "Iteration 24090 : Loss 2869.3361\n",
      "Iteration 24100 : Loss 2869.2088\n",
      "Iteration 24110 : Loss 2869.0817\n",
      "Iteration 24120 : Loss 2868.9547\n",
      "Iteration 24130 : Loss 2868.8277\n",
      "Iteration 24140 : Loss 2868.7009\n",
      "Iteration 24150 : Loss 2868.5743\n",
      "Iteration 24160 : Loss 2868.4477\n",
      "Iteration 24170 : Loss 2868.3212\n",
      "Iteration 24180 : Loss 2868.1949\n",
      "Iteration 24190 : Loss 2868.0686\n",
      "Iteration 24200 : Loss 2867.9425\n",
      "Iteration 24210 : Loss 2867.8165\n",
      "Iteration 24220 : Loss 2867.6906\n",
      "Iteration 24230 : Loss 2867.5648\n",
      "Iteration 24240 : Loss 2867.4391\n",
      "Iteration 24250 : Loss 2867.3135\n",
      "Iteration 24260 : Loss 2867.1880\n",
      "Iteration 24270 : Loss 2867.0627\n",
      "Iteration 24280 : Loss 2866.9374\n",
      "Iteration 24290 : Loss 2866.8123\n",
      "Iteration 24300 : Loss 2866.6872\n",
      "Iteration 24310 : Loss 2866.5623\n",
      "Iteration 24320 : Loss 2866.4375\n",
      "Iteration 24330 : Loss 2866.3128\n",
      "Iteration 24340 : Loss 2866.1882\n",
      "Iteration 24350 : Loss 2866.0637\n",
      "Iteration 24360 : Loss 2865.9394\n",
      "Iteration 24370 : Loss 2865.8151\n",
      "Iteration 24380 : Loss 2865.6909\n",
      "Iteration 24390 : Loss 2865.5669\n",
      "Iteration 24400 : Loss 2865.4429\n",
      "Iteration 24410 : Loss 2865.3191\n",
      "Iteration 24420 : Loss 2865.1954\n",
      "Iteration 24430 : Loss 2865.0718\n",
      "Iteration 24440 : Loss 2864.9483\n",
      "Iteration 24450 : Loss 2864.8249\n",
      "Iteration 24460 : Loss 2864.7016\n",
      "Iteration 24470 : Loss 2864.5784\n",
      "Iteration 24480 : Loss 2864.4553\n",
      "Iteration 24490 : Loss 2864.3323\n",
      "Iteration 24500 : Loss 2864.2095\n",
      "Iteration 24510 : Loss 2864.0867\n",
      "Iteration 24520 : Loss 2863.9641\n",
      "Iteration 24530 : Loss 2863.8415\n",
      "Iteration 24540 : Loss 2863.7191\n",
      "Iteration 24550 : Loss 2863.5967\n",
      "Iteration 24560 : Loss 2863.4745\n",
      "Iteration 24570 : Loss 2863.3524\n",
      "Iteration 24580 : Loss 2863.2304\n",
      "Iteration 24590 : Loss 2863.1085\n",
      "Iteration 24600 : Loss 2862.9867\n",
      "Iteration 24610 : Loss 2862.8650\n",
      "Iteration 24620 : Loss 2862.7434\n",
      "Iteration 24630 : Loss 2862.6219\n",
      "Iteration 24640 : Loss 2862.5006\n",
      "Iteration 24650 : Loss 2862.3793\n",
      "Iteration 24660 : Loss 2862.2581\n",
      "Iteration 24670 : Loss 2862.1371\n",
      "Iteration 24680 : Loss 2862.0161\n",
      "Iteration 24690 : Loss 2861.8953\n",
      "Iteration 24700 : Loss 2861.7745\n",
      "Iteration 24710 : Loss 2861.6539\n",
      "Iteration 24720 : Loss 2861.5334\n",
      "Iteration 24730 : Loss 2861.4129\n",
      "Iteration 24740 : Loss 2861.2926\n",
      "Iteration 24750 : Loss 2861.1724\n",
      "Iteration 24760 : Loss 2861.0523\n",
      "Iteration 24770 : Loss 2860.9322\n",
      "Iteration 24780 : Loss 2860.8123\n",
      "Iteration 24790 : Loss 2860.6925\n",
      "Iteration 24800 : Loss 2860.5728\n",
      "Iteration 24810 : Loss 2860.4532\n",
      "Iteration 24820 : Loss 2860.3337\n",
      "Iteration 24830 : Loss 2860.2144\n",
      "Iteration 24840 : Loss 2860.0951\n",
      "Iteration 24850 : Loss 2859.9759\n",
      "Iteration 24860 : Loss 2859.8568\n",
      "Iteration 24870 : Loss 2859.7378\n",
      "Iteration 24880 : Loss 2859.6190\n",
      "Iteration 24890 : Loss 2859.5002\n",
      "Iteration 24900 : Loss 2859.3815\n",
      "Iteration 24910 : Loss 2859.2630\n",
      "Iteration 24920 : Loss 2859.1445\n",
      "Iteration 24930 : Loss 2859.0261\n",
      "Iteration 24940 : Loss 2858.9079\n",
      "Iteration 24950 : Loss 2858.7897\n",
      "Iteration 24960 : Loss 2858.6717\n",
      "Iteration 24970 : Loss 2858.5537\n",
      "Iteration 24980 : Loss 2858.4359\n",
      "Iteration 24990 : Loss 2858.3181\n",
      "Iteration 25000 : Loss 2858.2005\n",
      "Iteration 25010 : Loss 2858.0829\n",
      "Iteration 25020 : Loss 2857.9655\n",
      "Iteration 25030 : Loss 2857.8481\n",
      "Iteration 25040 : Loss 2857.7309\n",
      "Iteration 25050 : Loss 2857.6138\n",
      "Iteration 25060 : Loss 2857.4967\n",
      "Iteration 25070 : Loss 2857.3798\n",
      "Iteration 25080 : Loss 2857.2629\n",
      "Iteration 25090 : Loss 2857.1462\n",
      "Iteration 25100 : Loss 2857.0296\n",
      "Iteration 25110 : Loss 2856.9130\n",
      "Iteration 25120 : Loss 2856.7966\n",
      "Iteration 25130 : Loss 2856.6803\n",
      "Iteration 25140 : Loss 2856.5640\n",
      "Iteration 25150 : Loss 2856.4479\n",
      "Iteration 25160 : Loss 2856.3319\n",
      "Iteration 25170 : Loss 2856.2159\n",
      "Iteration 25180 : Loss 2856.1001\n",
      "Iteration 25190 : Loss 2855.9844\n",
      "Iteration 25200 : Loss 2855.8687\n",
      "Iteration 25210 : Loss 2855.7532\n",
      "Iteration 25220 : Loss 2855.6378\n",
      "Iteration 25230 : Loss 2855.5224\n",
      "Iteration 25240 : Loss 2855.4072\n",
      "Iteration 25250 : Loss 2855.2920\n",
      "Iteration 25260 : Loss 2855.1770\n",
      "Iteration 25270 : Loss 2855.0621\n",
      "Iteration 25280 : Loss 2854.9472\n",
      "Iteration 25290 : Loss 2854.8325\n",
      "Iteration 25300 : Loss 2854.7178\n",
      "Iteration 25310 : Loss 2854.6033\n",
      "Iteration 25320 : Loss 2854.4888\n",
      "Iteration 25330 : Loss 2854.3745\n",
      "Iteration 25340 : Loss 2854.2602\n",
      "Iteration 25350 : Loss 2854.1461\n",
      "Iteration 25360 : Loss 2854.0320\n",
      "Iteration 25370 : Loss 2853.9181\n",
      "Iteration 25380 : Loss 2853.8042\n",
      "Iteration 25390 : Loss 2853.6904\n",
      "Iteration 25400 : Loss 2853.5768\n",
      "Iteration 25410 : Loss 2853.4632\n",
      "Iteration 25420 : Loss 2853.3497\n",
      "Iteration 25430 : Loss 2853.2363\n",
      "Iteration 25440 : Loss 2853.1231\n",
      "Iteration 25450 : Loss 2853.0099\n",
      "Iteration 25460 : Loss 2852.8968\n",
      "Iteration 25470 : Loss 2852.7838\n",
      "Iteration 25480 : Loss 2852.6709\n",
      "Iteration 25490 : Loss 2852.5581\n",
      "Iteration 25500 : Loss 2852.4454\n",
      "Iteration 25510 : Loss 2852.3328\n",
      "Iteration 25520 : Loss 2852.2203\n",
      "Iteration 25530 : Loss 2852.1079\n",
      "Iteration 25540 : Loss 2851.9956\n",
      "Iteration 25550 : Loss 2851.8834\n",
      "Iteration 25560 : Loss 2851.7713\n",
      "Iteration 25570 : Loss 2851.6592\n",
      "Iteration 25580 : Loss 2851.5473\n",
      "Iteration 25590 : Loss 2851.4355\n",
      "Iteration 25600 : Loss 2851.3237\n",
      "Iteration 25610 : Loss 2851.2121\n",
      "Iteration 25620 : Loss 2851.1006\n",
      "Iteration 25630 : Loss 2850.9891\n",
      "Iteration 25640 : Loss 2850.8777\n",
      "Iteration 25650 : Loss 2850.7665\n",
      "Iteration 25660 : Loss 2850.6553\n",
      "Iteration 25670 : Loss 2850.5442\n",
      "Iteration 25680 : Loss 2850.4333\n",
      "Iteration 25690 : Loss 2850.3224\n",
      "Iteration 25700 : Loss 2850.2116\n",
      "Iteration 25710 : Loss 2850.1009\n",
      "Iteration 25720 : Loss 2849.9903\n",
      "Iteration 25730 : Loss 2849.8798\n",
      "Iteration 25740 : Loss 2849.7694\n",
      "Iteration 25750 : Loss 2849.6591\n",
      "Iteration 25760 : Loss 2849.5488\n",
      "Iteration 25770 : Loss 2849.4387\n",
      "Iteration 25780 : Loss 2849.3287\n",
      "Iteration 25790 : Loss 2849.2187\n",
      "Iteration 25800 : Loss 2849.1089\n",
      "Iteration 25810 : Loss 2848.9991\n",
      "Iteration 25820 : Loss 2848.8895\n",
      "Iteration 25830 : Loss 2848.7799\n",
      "Iteration 25840 : Loss 2848.6704\n",
      "Iteration 25850 : Loss 2848.5610\n",
      "Iteration 25860 : Loss 2848.4517\n",
      "Iteration 25870 : Loss 2848.3425\n",
      "Iteration 25880 : Loss 2848.2334\n",
      "Iteration 25890 : Loss 2848.1244\n",
      "Iteration 25900 : Loss 2848.0155\n",
      "Iteration 25910 : Loss 2847.9067\n",
      "Iteration 25920 : Loss 2847.7979\n",
      "Iteration 25930 : Loss 2847.6893\n",
      "Iteration 25940 : Loss 2847.5807\n",
      "Iteration 25950 : Loss 2847.4723\n",
      "Iteration 25960 : Loss 2847.3639\n",
      "Iteration 25970 : Loss 2847.2556\n",
      "Iteration 25980 : Loss 2847.1475\n",
      "Iteration 25990 : Loss 2847.0394\n",
      "Iteration 26000 : Loss 2846.9314\n",
      "Iteration 26010 : Loss 2846.8235\n",
      "Iteration 26020 : Loss 2846.7156\n",
      "Iteration 26030 : Loss 2846.6079\n",
      "Iteration 26040 : Loss 2846.5003\n",
      "Iteration 26050 : Loss 2846.3927\n",
      "Iteration 26060 : Loss 2846.2853\n",
      "Iteration 26070 : Loss 2846.1779\n",
      "Iteration 26080 : Loss 2846.0706\n",
      "Iteration 26090 : Loss 2845.9635\n",
      "Iteration 26100 : Loss 2845.8564\n",
      "Iteration 26110 : Loss 2845.7494\n",
      "Iteration 26120 : Loss 2845.6425\n",
      "Iteration 26130 : Loss 2845.5357\n",
      "Iteration 26140 : Loss 2845.4289\n",
      "Iteration 26150 : Loss 2845.3223\n",
      "Iteration 26160 : Loss 2845.2157\n",
      "Iteration 26170 : Loss 2845.1093\n",
      "Iteration 26180 : Loss 2845.0029\n",
      "Iteration 26190 : Loss 2844.8966\n",
      "Iteration 26200 : Loss 2844.7905\n",
      "Iteration 26210 : Loss 2844.6844\n",
      "Iteration 26220 : Loss 2844.5783\n",
      "Iteration 26230 : Loss 2844.4724\n",
      "Iteration 26240 : Loss 2844.3666\n",
      "Iteration 26250 : Loss 2844.2609\n",
      "Iteration 26260 : Loss 2844.1552\n",
      "Iteration 26270 : Loss 2844.0496\n",
      "Iteration 26280 : Loss 2843.9442\n",
      "Iteration 26290 : Loss 2843.8388\n",
      "Iteration 26300 : Loss 2843.7335\n",
      "Iteration 26310 : Loss 2843.6283\n",
      "Iteration 26320 : Loss 2843.5232\n",
      "Iteration 26330 : Loss 2843.4181\n",
      "Iteration 26340 : Loss 2843.3132\n",
      "Iteration 26350 : Loss 2843.2083\n",
      "Iteration 26360 : Loss 2843.1036\n",
      "Iteration 26370 : Loss 2842.9989\n",
      "Iteration 26380 : Loss 2842.8943\n",
      "Iteration 26390 : Loss 2842.7898\n",
      "Iteration 26400 : Loss 2842.6854\n",
      "Iteration 26410 : Loss 2842.5811\n",
      "Iteration 26420 : Loss 2842.4768\n",
      "Iteration 26430 : Loss 2842.3727\n",
      "Iteration 26440 : Loss 2842.2686\n",
      "Iteration 26450 : Loss 2842.1646\n",
      "Iteration 26460 : Loss 2842.0608\n",
      "Iteration 26470 : Loss 2841.9570\n",
      "Iteration 26480 : Loss 2841.8532\n",
      "Iteration 26490 : Loss 2841.7496\n",
      "Iteration 26500 : Loss 2841.6461\n",
      "Iteration 26510 : Loss 2841.5426\n",
      "Iteration 26520 : Loss 2841.4393\n",
      "Iteration 26530 : Loss 2841.3360\n",
      "Iteration 26540 : Loss 2841.2328\n",
      "Iteration 26550 : Loss 2841.1297\n",
      "Iteration 26560 : Loss 2841.0267\n",
      "Iteration 26570 : Loss 2840.9237\n",
      "Iteration 26580 : Loss 2840.8209\n",
      "Iteration 26590 : Loss 2840.7181\n",
      "Iteration 26600 : Loss 2840.6155\n",
      "Iteration 26610 : Loss 2840.5129\n",
      "Iteration 26620 : Loss 2840.4104\n",
      "Iteration 26630 : Loss 2840.3080\n",
      "Iteration 26640 : Loss 2840.2056\n",
      "Iteration 26650 : Loss 2840.1034\n",
      "Iteration 26660 : Loss 2840.0012\n",
      "Iteration 26670 : Loss 2839.8992\n",
      "Iteration 26680 : Loss 2839.7972\n",
      "Iteration 26690 : Loss 2839.6953\n",
      "Iteration 26700 : Loss 2839.5935\n",
      "Iteration 26710 : Loss 2839.4917\n",
      "Iteration 26720 : Loss 2839.3901\n",
      "Iteration 26730 : Loss 2839.2885\n",
      "Iteration 26740 : Loss 2839.1870\n",
      "Iteration 26750 : Loss 2839.0856\n",
      "Iteration 26760 : Loss 2838.9843\n",
      "Iteration 26770 : Loss 2838.8831\n",
      "Iteration 26780 : Loss 2838.7820\n",
      "Iteration 26790 : Loss 2838.6809\n",
      "Iteration 26800 : Loss 2838.5800\n",
      "Iteration 26810 : Loss 2838.4791\n",
      "Iteration 26820 : Loss 2838.3783\n",
      "Iteration 26830 : Loss 2838.2776\n",
      "Iteration 26840 : Loss 2838.1769\n",
      "Iteration 26850 : Loss 2838.0764\n",
      "Iteration 26860 : Loss 2837.9759\n",
      "Iteration 26870 : Loss 2837.8755\n",
      "Iteration 26880 : Loss 2837.7752\n",
      "Iteration 26890 : Loss 2837.6750\n",
      "Iteration 26900 : Loss 2837.5749\n",
      "Iteration 26910 : Loss 2837.4749\n",
      "Iteration 26920 : Loss 2837.3749\n",
      "Iteration 26930 : Loss 2837.2750\n",
      "Iteration 26940 : Loss 2837.1752\n",
      "Iteration 26950 : Loss 2837.0755\n",
      "Iteration 26960 : Loss 2836.9759\n",
      "Iteration 26970 : Loss 2836.8763\n",
      "Iteration 26980 : Loss 2836.7769\n",
      "Iteration 26990 : Loss 2836.6775\n",
      "Iteration 27000 : Loss 2836.5782\n",
      "Iteration 27010 : Loss 2836.4790\n",
      "Iteration 27020 : Loss 2836.3798\n",
      "Iteration 27030 : Loss 2836.2808\n",
      "Iteration 27040 : Loss 2836.1818\n",
      "Iteration 27050 : Loss 2836.0829\n",
      "Iteration 27060 : Loss 2835.9841\n",
      "Iteration 27070 : Loss 2835.8854\n",
      "Iteration 27080 : Loss 2835.7868\n",
      "Iteration 27090 : Loss 2835.6882\n",
      "Iteration 27100 : Loss 2835.5897\n",
      "Iteration 27110 : Loss 2835.4913\n",
      "Iteration 27120 : Loss 2835.3930\n",
      "Iteration 27130 : Loss 2835.2948\n",
      "Iteration 27140 : Loss 2835.1967\n",
      "Iteration 27150 : Loss 2835.0986\n",
      "Iteration 27160 : Loss 2835.0006\n",
      "Iteration 27170 : Loss 2834.9027\n",
      "Iteration 27180 : Loss 2834.8049\n",
      "Iteration 27190 : Loss 2834.7071\n",
      "Iteration 27200 : Loss 2834.6095\n",
      "Iteration 27210 : Loss 2834.5119\n",
      "Iteration 27220 : Loss 2834.4144\n",
      "Iteration 27230 : Loss 2834.3170\n",
      "Iteration 27240 : Loss 2834.2196\n",
      "Iteration 27250 : Loss 2834.1224\n",
      "Iteration 27260 : Loss 2834.0252\n",
      "Iteration 27270 : Loss 2833.9281\n",
      "Iteration 27280 : Loss 2833.8311\n",
      "Iteration 27290 : Loss 2833.7342\n",
      "Iteration 27300 : Loss 2833.6373\n",
      "Iteration 27310 : Loss 2833.5405\n",
      "Iteration 27320 : Loss 2833.4438\n",
      "Iteration 27330 : Loss 2833.3472\n",
      "Iteration 27340 : Loss 2833.2507\n",
      "Iteration 27350 : Loss 2833.1542\n",
      "Iteration 27360 : Loss 2833.0579\n",
      "Iteration 27370 : Loss 2832.9616\n",
      "Iteration 27380 : Loss 2832.8653\n",
      "Iteration 27390 : Loss 2832.7692\n",
      "Iteration 27400 : Loss 2832.6732\n",
      "Iteration 27410 : Loss 2832.5772\n",
      "Iteration 27420 : Loss 2832.4813\n",
      "Iteration 27430 : Loss 2832.3855\n",
      "Iteration 27440 : Loss 2832.2897\n",
      "Iteration 27450 : Loss 2832.1941\n",
      "Iteration 27460 : Loss 2832.0985\n",
      "Iteration 27470 : Loss 2832.0030\n",
      "Iteration 27480 : Loss 2831.9076\n",
      "Iteration 27490 : Loss 2831.8122\n",
      "Iteration 27500 : Loss 2831.7170\n",
      "Iteration 27510 : Loss 2831.6218\n",
      "Iteration 27520 : Loss 2831.5267\n",
      "Iteration 27530 : Loss 2831.4316\n",
      "Iteration 27540 : Loss 2831.3367\n",
      "Iteration 27550 : Loss 2831.2418\n",
      "Iteration 27560 : Loss 2831.1470\n",
      "Iteration 27570 : Loss 2831.0523\n",
      "Iteration 27580 : Loss 2830.9577\n",
      "Iteration 27590 : Loss 2830.8631\n",
      "Iteration 27600 : Loss 2830.7686\n",
      "Iteration 27610 : Loss 2830.6742\n",
      "Iteration 27620 : Loss 2830.5799\n",
      "Iteration 27630 : Loss 2830.4856\n",
      "Iteration 27640 : Loss 2830.3915\n",
      "Iteration 27650 : Loss 2830.2974\n",
      "Iteration 27660 : Loss 2830.2033\n",
      "Iteration 27670 : Loss 2830.1094\n",
      "Iteration 27680 : Loss 2830.0155\n",
      "Iteration 27690 : Loss 2829.9218\n",
      "Iteration 27700 : Loss 2829.8281\n",
      "Iteration 27710 : Loss 2829.7344\n",
      "Iteration 27720 : Loss 2829.6409\n",
      "Iteration 27730 : Loss 2829.5474\n",
      "Iteration 27740 : Loss 2829.4540\n",
      "Iteration 27750 : Loss 2829.3607\n",
      "Iteration 27760 : Loss 2829.2674\n",
      "Iteration 27770 : Loss 2829.1743\n",
      "Iteration 27780 : Loss 2829.0812\n",
      "Iteration 27790 : Loss 2828.9881\n",
      "Iteration 27800 : Loss 2828.8952\n",
      "Iteration 27810 : Loss 2828.8023\n",
      "Iteration 27820 : Loss 2828.7095\n",
      "Iteration 27830 : Loss 2828.6168\n",
      "Iteration 27840 : Loss 2828.5242\n",
      "Iteration 27850 : Loss 2828.4316\n",
      "Iteration 27860 : Loss 2828.3392\n",
      "Iteration 27870 : Loss 2828.2468\n",
      "Iteration 27880 : Loss 2828.1544\n",
      "Iteration 27890 : Loss 2828.0622\n",
      "Iteration 27900 : Loss 2827.9700\n",
      "Iteration 27910 : Loss 2827.8779\n",
      "Iteration 27920 : Loss 2827.7858\n",
      "Iteration 27930 : Loss 2827.6939\n",
      "Iteration 27940 : Loss 2827.6020\n",
      "Iteration 27950 : Loss 2827.5102\n",
      "Iteration 27960 : Loss 2827.4185\n",
      "Iteration 27970 : Loss 2827.3268\n",
      "Iteration 27980 : Loss 2827.2353\n",
      "Iteration 27990 : Loss 2827.1437\n",
      "Iteration 28000 : Loss 2827.0523\n",
      "Iteration 28010 : Loss 2826.9610\n",
      "Iteration 28020 : Loss 2826.8697\n",
      "Iteration 28030 : Loss 2826.7785\n",
      "Iteration 28040 : Loss 2826.6874\n",
      "Iteration 28050 : Loss 2826.5963\n",
      "Iteration 28060 : Loss 2826.5053\n",
      "Iteration 28070 : Loss 2826.4144\n",
      "Iteration 28080 : Loss 2826.3236\n",
      "Iteration 28090 : Loss 2826.2328\n",
      "Iteration 28100 : Loss 2826.1421\n",
      "Iteration 28110 : Loss 2826.0515\n",
      "Iteration 28120 : Loss 2825.9610\n",
      "Iteration 28130 : Loss 2825.8705\n",
      "Iteration 28140 : Loss 2825.7801\n",
      "Iteration 28150 : Loss 2825.6898\n",
      "Iteration 28160 : Loss 2825.5996\n",
      "Iteration 28170 : Loss 2825.5094\n",
      "Iteration 28180 : Loss 2825.4193\n",
      "Iteration 28190 : Loss 2825.3293\n",
      "Iteration 28200 : Loss 2825.2394\n",
      "Iteration 28210 : Loss 2825.1495\n",
      "Iteration 28220 : Loss 2825.0597\n",
      "Iteration 28230 : Loss 2824.9700\n",
      "Iteration 28240 : Loss 2824.8803\n",
      "Iteration 28250 : Loss 2824.7907\n",
      "Iteration 28260 : Loss 2824.7012\n",
      "Iteration 28270 : Loss 2824.6118\n",
      "Iteration 28280 : Loss 2824.5224\n",
      "Iteration 28290 : Loss 2824.4332\n",
      "Iteration 28300 : Loss 2824.3439\n",
      "Iteration 28310 : Loss 2824.2548\n",
      "Iteration 28320 : Loss 2824.1657\n",
      "Iteration 28330 : Loss 2824.0767\n",
      "Iteration 28340 : Loss 2823.9878\n",
      "Iteration 28350 : Loss 2823.8990\n",
      "Iteration 28360 : Loss 2823.8102\n",
      "Iteration 28370 : Loss 2823.7215\n",
      "Iteration 28380 : Loss 2823.6328\n",
      "Iteration 28390 : Loss 2823.5443\n",
      "Iteration 28400 : Loss 2823.4558\n",
      "Iteration 28410 : Loss 2823.3674\n",
      "Iteration 28420 : Loss 2823.2790\n",
      "Iteration 28430 : Loss 2823.1907\n",
      "Iteration 28440 : Loss 2823.1025\n",
      "Iteration 28450 : Loss 2823.0144\n",
      "Iteration 28460 : Loss 2822.9263\n",
      "Iteration 28470 : Loss 2822.8383\n",
      "Iteration 28480 : Loss 2822.7504\n",
      "Iteration 28490 : Loss 2822.6626\n",
      "Iteration 28500 : Loss 2822.5748\n",
      "Iteration 28510 : Loss 2822.4871\n",
      "Iteration 28520 : Loss 2822.3995\n",
      "Iteration 28530 : Loss 2822.3119\n",
      "Iteration 28540 : Loss 2822.2244\n",
      "Iteration 28550 : Loss 2822.1370\n",
      "Iteration 28560 : Loss 2822.0496\n",
      "Iteration 28570 : Loss 2821.9624\n",
      "Iteration 28580 : Loss 2821.8752\n",
      "Iteration 28590 : Loss 2821.7880\n",
      "Iteration 28600 : Loss 2821.7010\n",
      "Iteration 28610 : Loss 2821.6140\n",
      "Iteration 28620 : Loss 2821.5270\n",
      "Iteration 28630 : Loss 2821.4402\n",
      "Iteration 28640 : Loss 2821.3534\n",
      "Iteration 28650 : Loss 2821.2667\n",
      "Iteration 28660 : Loss 2821.1800\n",
      "Iteration 28670 : Loss 2821.0935\n",
      "Iteration 28680 : Loss 2821.0070\n",
      "Iteration 28690 : Loss 2820.9205\n",
      "Iteration 28700 : Loss 2820.8342\n",
      "Iteration 28710 : Loss 2820.7479\n",
      "Iteration 28720 : Loss 2820.6617\n",
      "Iteration 28730 : Loss 2820.5755\n",
      "Iteration 28740 : Loss 2820.4894\n",
      "Iteration 28750 : Loss 2820.4034\n",
      "Iteration 28760 : Loss 2820.3175\n",
      "Iteration 28770 : Loss 2820.2316\n",
      "Iteration 28780 : Loss 2820.1458\n",
      "Iteration 28790 : Loss 2820.0600\n",
      "Iteration 28800 : Loss 2819.9744\n",
      "Iteration 28810 : Loss 2819.8888\n",
      "Iteration 28820 : Loss 2819.8033\n",
      "Iteration 28830 : Loss 2819.7178\n",
      "Iteration 28840 : Loss 2819.6324\n",
      "Iteration 28850 : Loss 2819.5471\n",
      "Iteration 28860 : Loss 2819.4618\n",
      "Iteration 28870 : Loss 2819.3766\n",
      "Iteration 28880 : Loss 2819.2915\n",
      "Iteration 28890 : Loss 2819.2065\n",
      "Iteration 28900 : Loss 2819.1215\n",
      "Iteration 28910 : Loss 2819.0366\n",
      "Iteration 28920 : Loss 2818.9518\n",
      "Iteration 28930 : Loss 2818.8670\n",
      "Iteration 28940 : Loss 2818.7823\n",
      "Iteration 28950 : Loss 2818.6976\n",
      "Iteration 28960 : Loss 2818.6131\n",
      "Iteration 28970 : Loss 2818.5286\n",
      "Iteration 28980 : Loss 2818.4441\n",
      "Iteration 28990 : Loss 2818.3598\n",
      "Iteration 29000 : Loss 2818.2755\n",
      "Iteration 29010 : Loss 2818.1913\n",
      "Iteration 29020 : Loss 2818.1071\n",
      "Iteration 29030 : Loss 2818.0230\n",
      "Iteration 29040 : Loss 2817.9390\n",
      "Iteration 29050 : Loss 2817.8550\n",
      "Iteration 29060 : Loss 2817.7711\n",
      "Iteration 29070 : Loss 2817.6873\n",
      "Iteration 29080 : Loss 2817.6036\n",
      "Iteration 29090 : Loss 2817.5199\n",
      "Iteration 29100 : Loss 2817.4362\n",
      "Iteration 29110 : Loss 2817.3527\n",
      "Iteration 29120 : Loss 2817.2692\n",
      "Iteration 29130 : Loss 2817.1858\n",
      "Iteration 29140 : Loss 2817.1024\n",
      "Iteration 29150 : Loss 2817.0192\n",
      "Iteration 29160 : Loss 2816.9359\n",
      "Iteration 29170 : Loss 2816.8528\n",
      "Iteration 29180 : Loss 2816.7697\n",
      "Iteration 29190 : Loss 2816.6867\n",
      "Iteration 29200 : Loss 2816.6037\n",
      "Iteration 29210 : Loss 2816.5209\n",
      "Iteration 29220 : Loss 2816.4380\n",
      "Iteration 29230 : Loss 2816.3553\n",
      "Iteration 29240 : Loss 2816.2726\n",
      "Iteration 29250 : Loss 2816.1900\n",
      "Iteration 29260 : Loss 2816.1074\n",
      "Iteration 29270 : Loss 2816.0250\n",
      "Iteration 29280 : Loss 2815.9425\n",
      "Iteration 29290 : Loss 2815.8602\n",
      "Iteration 29300 : Loss 2815.7779\n",
      "Iteration 29310 : Loss 2815.6957\n",
      "Iteration 29320 : Loss 2815.6135\n",
      "Iteration 29330 : Loss 2815.5314\n",
      "Iteration 29340 : Loss 2815.4494\n",
      "Iteration 29350 : Loss 2815.3674\n",
      "Iteration 29360 : Loss 2815.2856\n",
      "Iteration 29370 : Loss 2815.2037\n",
      "Iteration 29380 : Loss 2815.1220\n",
      "Iteration 29390 : Loss 2815.0403\n",
      "Iteration 29400 : Loss 2814.9586\n",
      "Iteration 29410 : Loss 2814.8771\n",
      "Iteration 29420 : Loss 2814.7956\n",
      "Iteration 29430 : Loss 2814.7141\n",
      "Iteration 29440 : Loss 2814.6328\n",
      "Iteration 29450 : Loss 2814.5515\n",
      "Iteration 29460 : Loss 2814.4702\n",
      "Iteration 29470 : Loss 2814.3891\n",
      "Iteration 29480 : Loss 2814.3079\n",
      "Iteration 29490 : Loss 2814.2269\n",
      "Iteration 29500 : Loss 2814.1459\n",
      "Iteration 29510 : Loss 2814.0650\n",
      "Iteration 29520 : Loss 2813.9842\n",
      "Iteration 29530 : Loss 2813.9034\n",
      "Iteration 29540 : Loss 2813.8227\n",
      "Iteration 29550 : Loss 2813.7420\n",
      "Iteration 29560 : Loss 2813.6614\n",
      "Iteration 29570 : Loss 2813.5809\n",
      "Iteration 29580 : Loss 2813.5004\n",
      "Iteration 29590 : Loss 2813.4200\n",
      "Iteration 29600 : Loss 2813.3397\n",
      "Iteration 29610 : Loss 2813.2594\n",
      "Iteration 29620 : Loss 2813.1792\n",
      "Iteration 29630 : Loss 2813.0991\n",
      "Iteration 29640 : Loss 2813.0190\n",
      "Iteration 29650 : Loss 2812.9390\n",
      "Iteration 29660 : Loss 2812.8590\n",
      "Iteration 29670 : Loss 2812.7791\n",
      "Iteration 29680 : Loss 2812.6993\n",
      "Iteration 29690 : Loss 2812.6195\n",
      "Iteration 29700 : Loss 2812.5398\n",
      "Iteration 29710 : Loss 2812.4602\n",
      "Iteration 29720 : Loss 2812.3806\n",
      "Iteration 29730 : Loss 2812.3011\n",
      "Iteration 29740 : Loss 2812.2217\n",
      "Iteration 29750 : Loss 2812.1423\n",
      "Iteration 29760 : Loss 2812.0630\n",
      "Iteration 29770 : Loss 2811.9837\n",
      "Iteration 29780 : Loss 2811.9045\n",
      "Iteration 29790 : Loss 2811.8254\n",
      "Iteration 29800 : Loss 2811.7464\n",
      "Iteration 29810 : Loss 2811.6674\n",
      "Iteration 29820 : Loss 2811.5884\n",
      "Iteration 29830 : Loss 2811.5095\n",
      "Iteration 29840 : Loss 2811.4307\n",
      "Iteration 29850 : Loss 2811.3520\n",
      "Iteration 29860 : Loss 2811.2733\n",
      "Iteration 29870 : Loss 2811.1947\n",
      "Iteration 29880 : Loss 2811.1161\n",
      "Iteration 29890 : Loss 2811.0376\n",
      "Iteration 29900 : Loss 2810.9592\n",
      "Iteration 29910 : Loss 2810.8808\n",
      "Iteration 29920 : Loss 2810.8025\n",
      "Iteration 29930 : Loss 2810.7242\n",
      "Iteration 29940 : Loss 2810.6460\n",
      "Iteration 29950 : Loss 2810.5679\n",
      "Iteration 29960 : Loss 2810.4898\n",
      "Iteration 29970 : Loss 2810.4118\n",
      "Iteration 29980 : Loss 2810.3339\n",
      "Iteration 29990 : Loss 2810.2560\n",
      "Iteration 30000 : Loss 2810.1782\n",
      "Iteration 30010 : Loss 2810.1004\n",
      "Iteration 30020 : Loss 2810.0227\n",
      "Iteration 30030 : Loss 2809.9451\n",
      "Iteration 30040 : Loss 2809.8675\n",
      "Iteration 30050 : Loss 2809.7900\n",
      "Iteration 30060 : Loss 2809.7126\n",
      "Iteration 30070 : Loss 2809.6352\n",
      "Iteration 30080 : Loss 2809.5579\n",
      "Iteration 30090 : Loss 2809.4806\n",
      "Iteration 30100 : Loss 2809.4034\n",
      "Iteration 30110 : Loss 2809.3262\n",
      "Iteration 30120 : Loss 2809.2492\n",
      "Iteration 30130 : Loss 2809.1721\n",
      "Iteration 30140 : Loss 2809.0952\n",
      "Iteration 30150 : Loss 2809.0183\n",
      "Iteration 30160 : Loss 2808.9414\n",
      "Iteration 30170 : Loss 2808.8647\n",
      "Iteration 30180 : Loss 2808.7880\n",
      "Iteration 30190 : Loss 2808.7113\n",
      "Iteration 30200 : Loss 2808.6347\n",
      "Iteration 30210 : Loss 2808.5582\n",
      "Iteration 30220 : Loss 2808.4817\n",
      "Iteration 30230 : Loss 2808.4053\n",
      "Iteration 30240 : Loss 2808.3289\n",
      "Iteration 30250 : Loss 2808.2526\n",
      "Iteration 30260 : Loss 2808.1764\n",
      "Iteration 30270 : Loss 2808.1002\n",
      "Iteration 30280 : Loss 2808.0241\n",
      "Iteration 30290 : Loss 2807.9481\n",
      "Iteration 30300 : Loss 2807.8721\n",
      "Iteration 30310 : Loss 2807.7961\n",
      "Iteration 30320 : Loss 2807.7203\n",
      "Iteration 30330 : Loss 2807.6445\n",
      "Iteration 30340 : Loss 2807.5687\n",
      "Iteration 30350 : Loss 2807.4930\n",
      "Iteration 30360 : Loss 2807.4174\n",
      "Iteration 30370 : Loss 2807.3418\n",
      "Iteration 30380 : Loss 2807.2663\n",
      "Iteration 30390 : Loss 2807.1908\n",
      "Iteration 30400 : Loss 2807.1154\n",
      "Iteration 30410 : Loss 2807.0401\n",
      "Iteration 30420 : Loss 2806.9648\n",
      "Iteration 30430 : Loss 2806.8896\n",
      "Iteration 30440 : Loss 2806.8145\n",
      "Iteration 30450 : Loss 2806.7394\n",
      "Iteration 30460 : Loss 2806.6643\n",
      "Iteration 30470 : Loss 2806.5893\n",
      "Iteration 30480 : Loss 2806.5144\n",
      "Iteration 30490 : Loss 2806.4396\n",
      "Iteration 30500 : Loss 2806.3648\n",
      "Iteration 30510 : Loss 2806.2900\n",
      "Iteration 30520 : Loss 2806.2153\n",
      "Iteration 30530 : Loss 2806.1407\n",
      "Iteration 30540 : Loss 2806.0661\n",
      "Iteration 30550 : Loss 2805.9916\n",
      "Iteration 30560 : Loss 2805.9172\n",
      "Iteration 30570 : Loss 2805.8428\n",
      "Iteration 30580 : Loss 2805.7685\n",
      "Iteration 30590 : Loss 2805.6942\n",
      "Iteration 30600 : Loss 2805.6200\n",
      "Iteration 30610 : Loss 2805.5458\n",
      "Iteration 30620 : Loss 2805.4717\n",
      "Iteration 30630 : Loss 2805.3977\n",
      "Iteration 30640 : Loss 2805.3237\n",
      "Iteration 30650 : Loss 2805.2498\n",
      "Iteration 30660 : Loss 2805.1759\n",
      "Iteration 30670 : Loss 2805.1021\n",
      "Iteration 30680 : Loss 2805.0283\n",
      "Iteration 30690 : Loss 2804.9546\n",
      "Iteration 30700 : Loss 2804.8810\n",
      "Iteration 30710 : Loss 2804.8074\n",
      "Iteration 30720 : Loss 2804.7339\n",
      "Iteration 30730 : Loss 2804.6604\n",
      "Iteration 30740 : Loss 2804.5870\n",
      "Iteration 30750 : Loss 2804.5137\n",
      "Iteration 30760 : Loss 2804.4404\n",
      "Iteration 30770 : Loss 2804.3672\n",
      "Iteration 30780 : Loss 2804.2940\n",
      "Iteration 30790 : Loss 2804.2209\n",
      "Iteration 30800 : Loss 2804.1478\n",
      "Iteration 30810 : Loss 2804.0748\n",
      "Iteration 30820 : Loss 2804.0019\n",
      "Iteration 30830 : Loss 2803.9290\n",
      "Iteration 30840 : Loss 2803.8561\n",
      "Iteration 30850 : Loss 2803.7834\n",
      "Iteration 30860 : Loss 2803.7106\n",
      "Iteration 30870 : Loss 2803.6380\n",
      "Iteration 30880 : Loss 2803.5654\n",
      "Iteration 30890 : Loss 2803.4928\n",
      "Iteration 30900 : Loss 2803.4203\n",
      "Iteration 30910 : Loss 2803.3479\n",
      "Iteration 30920 : Loss 2803.2755\n",
      "Iteration 30930 : Loss 2803.2032\n",
      "Iteration 30940 : Loss 2803.1310\n",
      "Iteration 30950 : Loss 2803.0587\n",
      "Iteration 30960 : Loss 2802.9866\n",
      "Iteration 30970 : Loss 2802.9145\n",
      "Iteration 30980 : Loss 2802.8425\n",
      "Iteration 30990 : Loss 2802.7705\n",
      "Iteration 31000 : Loss 2802.6986\n",
      "Iteration 31010 : Loss 2802.6267\n",
      "Iteration 31020 : Loss 2802.5549\n",
      "Iteration 31030 : Loss 2802.4831\n",
      "Iteration 31040 : Loss 2802.4114\n",
      "Iteration 31050 : Loss 2802.3398\n",
      "Iteration 31060 : Loss 2802.2682\n",
      "Iteration 31070 : Loss 2802.1966\n",
      "Iteration 31080 : Loss 2802.1252\n",
      "Iteration 31090 : Loss 2802.0537\n",
      "Iteration 31100 : Loss 2801.9824\n",
      "Iteration 31110 : Loss 2801.9111\n",
      "Iteration 31120 : Loss 2801.8398\n",
      "Iteration 31130 : Loss 2801.7686\n",
      "Iteration 31140 : Loss 2801.6975\n",
      "Iteration 31150 : Loss 2801.6264\n",
      "Iteration 31160 : Loss 2801.5554\n",
      "Iteration 31170 : Loss 2801.4844\n",
      "Iteration 31180 : Loss 2801.4135\n",
      "Iteration 31190 : Loss 2801.3426\n",
      "Iteration 31200 : Loss 2801.2718\n",
      "Iteration 31210 : Loss 2801.2010\n",
      "Iteration 31220 : Loss 2801.1303\n",
      "Iteration 31230 : Loss 2801.0597\n",
      "Iteration 31240 : Loss 2800.9891\n",
      "Iteration 31250 : Loss 2800.9185\n",
      "Iteration 31260 : Loss 2800.8481\n",
      "Iteration 31270 : Loss 2800.7776\n",
      "Iteration 31280 : Loss 2800.7073\n",
      "Iteration 31290 : Loss 2800.6369\n",
      "Iteration 31300 : Loss 2800.5667\n",
      "Iteration 31310 : Loss 2800.4965\n",
      "Iteration 31320 : Loss 2800.4263\n",
      "Iteration 31330 : Loss 2800.3562\n",
      "Iteration 31340 : Loss 2800.2862\n",
      "Iteration 31350 : Loss 2800.2162\n",
      "Iteration 31360 : Loss 2800.1463\n",
      "Iteration 31370 : Loss 2800.0764\n",
      "Iteration 31380 : Loss 2800.0066\n",
      "Iteration 31390 : Loss 2799.9368\n",
      "Iteration 31400 : Loss 2799.8671\n",
      "Iteration 31410 : Loss 2799.7974\n",
      "Iteration 31420 : Loss 2799.7278\n",
      "Iteration 31430 : Loss 2799.6582\n",
      "Iteration 31440 : Loss 2799.5887\n",
      "Iteration 31450 : Loss 2799.5193\n",
      "Iteration 31460 : Loss 2799.4499\n",
      "Iteration 31470 : Loss 2799.3805\n",
      "Iteration 31480 : Loss 2799.3113\n",
      "Iteration 31490 : Loss 2799.2420\n",
      "Iteration 31500 : Loss 2799.1729\n",
      "Iteration 31510 : Loss 2799.1037\n",
      "Iteration 31520 : Loss 2799.0347\n",
      "Iteration 31530 : Loss 2798.9656\n",
      "Iteration 31540 : Loss 2798.8967\n",
      "Iteration 31550 : Loss 2798.8278\n",
      "Iteration 31560 : Loss 2798.7589\n",
      "Iteration 31570 : Loss 2798.6901\n",
      "Iteration 31580 : Loss 2798.6213\n",
      "Iteration 31590 : Loss 2798.5527\n",
      "Iteration 31600 : Loss 2798.4840\n",
      "Iteration 31610 : Loss 2798.4154\n",
      "Iteration 31620 : Loss 2798.3469\n",
      "Iteration 31630 : Loss 2798.2784\n",
      "Iteration 31640 : Loss 2798.2100\n",
      "Iteration 31650 : Loss 2798.1416\n",
      "Iteration 31660 : Loss 2798.0733\n",
      "Iteration 31670 : Loss 2798.0050\n",
      "Iteration 31680 : Loss 2797.9368\n",
      "Iteration 31690 : Loss 2797.8686\n",
      "Iteration 31700 : Loss 2797.8005\n",
      "Iteration 31710 : Loss 2797.7324\n",
      "Iteration 31720 : Loss 2797.6644\n",
      "Iteration 31730 : Loss 2797.5964\n",
      "Iteration 31740 : Loss 2797.5285\n",
      "Iteration 31750 : Loss 2797.4607\n",
      "Iteration 31760 : Loss 2797.3929\n",
      "Iteration 31770 : Loss 2797.3251\n",
      "Iteration 31780 : Loss 2797.2574\n",
      "Iteration 31790 : Loss 2797.1898\n",
      "Iteration 31800 : Loss 2797.1222\n",
      "Iteration 31810 : Loss 2797.0547\n",
      "Iteration 31820 : Loss 2796.9872\n",
      "Iteration 31830 : Loss 2796.9198\n",
      "Iteration 31840 : Loss 2796.8524\n",
      "Iteration 31850 : Loss 2796.7850\n",
      "Iteration 31860 : Loss 2796.7178\n",
      "Iteration 31870 : Loss 2796.6505\n",
      "Iteration 31880 : Loss 2796.5834\n",
      "Iteration 31890 : Loss 2796.5162\n",
      "Iteration 31900 : Loss 2796.4492\n",
      "Iteration 31910 : Loss 2796.3822\n",
      "Iteration 31920 : Loss 2796.3152\n",
      "Iteration 31930 : Loss 2796.2483\n",
      "Iteration 31940 : Loss 2796.1814\n",
      "Iteration 31950 : Loss 2796.1146\n",
      "Iteration 31960 : Loss 2796.0478\n",
      "Iteration 31970 : Loss 2795.9811\n",
      "Iteration 31980 : Loss 2795.9145\n",
      "Iteration 31990 : Loss 2795.8479\n",
      "Iteration 32000 : Loss 2795.7813\n",
      "Iteration 32010 : Loss 2795.7148\n",
      "Iteration 32020 : Loss 2795.6483\n",
      "Iteration 32030 : Loss 2795.5819\n",
      "Iteration 32040 : Loss 2795.5156\n",
      "Iteration 32050 : Loss 2795.4493\n",
      "Iteration 32060 : Loss 2795.3830\n",
      "Iteration 32070 : Loss 2795.3168\n",
      "Iteration 32080 : Loss 2795.2507\n",
      "Iteration 32090 : Loss 2795.1846\n",
      "Iteration 32100 : Loss 2795.1186\n",
      "Iteration 32110 : Loss 2795.0526\n",
      "Iteration 32120 : Loss 2794.9866\n",
      "Iteration 32130 : Loss 2794.9207\n",
      "Iteration 32140 : Loss 2794.8549\n",
      "Iteration 32150 : Loss 2794.7891\n",
      "Iteration 32160 : Loss 2794.7233\n",
      "Iteration 32170 : Loss 2794.6577\n",
      "Iteration 32180 : Loss 2794.5920\n",
      "Iteration 32190 : Loss 2794.5264\n",
      "Iteration 32200 : Loss 2794.4609\n",
      "Iteration 32210 : Loss 2794.3954\n",
      "Iteration 32220 : Loss 2794.3300\n",
      "Iteration 32230 : Loss 2794.2646\n",
      "Iteration 32240 : Loss 2794.1992\n",
      "Iteration 32250 : Loss 2794.1339\n",
      "Iteration 32260 : Loss 2794.0687\n",
      "Iteration 32270 : Loss 2794.0035\n",
      "Iteration 32280 : Loss 2793.9384\n",
      "Iteration 32290 : Loss 2793.8733\n",
      "Iteration 32300 : Loss 2793.8082\n",
      "Iteration 32310 : Loss 2793.7433\n",
      "Iteration 32320 : Loss 2793.6783\n",
      "Iteration 32330 : Loss 2793.6134\n",
      "Iteration 32340 : Loss 2793.5486\n",
      "Iteration 32350 : Loss 2793.4838\n",
      "Iteration 32360 : Loss 2793.4191\n",
      "Iteration 32370 : Loss 2793.3544\n",
      "Iteration 32380 : Loss 2793.2897\n",
      "Iteration 32390 : Loss 2793.2251\n",
      "Iteration 32400 : Loss 2793.1606\n",
      "Iteration 32410 : Loss 2793.0961\n",
      "Iteration 32420 : Loss 2793.0317\n",
      "Iteration 32430 : Loss 2792.9673\n",
      "Iteration 32440 : Loss 2792.9029\n",
      "Iteration 32450 : Loss 2792.8386\n",
      "Iteration 32460 : Loss 2792.7744\n",
      "Iteration 32470 : Loss 2792.7102\n",
      "Iteration 32480 : Loss 2792.6460\n",
      "Iteration 32490 : Loss 2792.5819\n",
      "Iteration 32500 : Loss 2792.5179\n",
      "Iteration 32510 : Loss 2792.4539\n",
      "Iteration 32520 : Loss 2792.3899\n",
      "Iteration 32530 : Loss 2792.3260\n",
      "Iteration 32540 : Loss 2792.2622\n",
      "Iteration 32550 : Loss 2792.1984\n",
      "Iteration 32560 : Loss 2792.1346\n",
      "Iteration 32570 : Loss 2792.0709\n",
      "Iteration 32580 : Loss 2792.0072\n",
      "Iteration 32590 : Loss 2791.9436\n",
      "Iteration 32600 : Loss 2791.8801\n",
      "Iteration 32610 : Loss 2791.8166\n",
      "Iteration 32620 : Loss 2791.7531\n",
      "Iteration 32630 : Loss 2791.6897\n",
      "Iteration 32640 : Loss 2791.6263\n",
      "Iteration 32650 : Loss 2791.5630\n",
      "Iteration 32660 : Loss 2791.4997\n",
      "Iteration 32670 : Loss 2791.4365\n",
      "Iteration 32680 : Loss 2791.3733\n",
      "Iteration 32690 : Loss 2791.3102\n",
      "Iteration 32700 : Loss 2791.2471\n",
      "Iteration 32710 : Loss 2791.1841\n",
      "Iteration 32720 : Loss 2791.1211\n",
      "Iteration 32730 : Loss 2791.0582\n",
      "Iteration 32740 : Loss 2790.9953\n",
      "Iteration 32750 : Loss 2790.9324\n",
      "Iteration 32760 : Loss 2790.8696\n",
      "Iteration 32770 : Loss 2790.8069\n",
      "Iteration 32780 : Loss 2790.7442\n",
      "Iteration 32790 : Loss 2790.6815\n",
      "Iteration 32800 : Loss 2790.6189\n",
      "Iteration 32810 : Loss 2790.5564\n",
      "Iteration 32820 : Loss 2790.4939\n",
      "Iteration 32830 : Loss 2790.4314\n",
      "Iteration 32840 : Loss 2790.3690\n",
      "Iteration 32850 : Loss 2790.3067\n",
      "Iteration 32860 : Loss 2790.2443\n",
      "Iteration 32870 : Loss 2790.1821\n",
      "Iteration 32880 : Loss 2790.1199\n",
      "Iteration 32890 : Loss 2790.0577\n",
      "Iteration 32900 : Loss 2789.9956\n",
      "Iteration 32910 : Loss 2789.9335\n",
      "Iteration 32920 : Loss 2789.8714\n",
      "Iteration 32930 : Loss 2789.8095\n",
      "Iteration 32940 : Loss 2789.7475\n",
      "Iteration 32950 : Loss 2789.6856\n",
      "Iteration 32960 : Loss 2789.6238\n",
      "Iteration 32970 : Loss 2789.5620\n",
      "Iteration 32980 : Loss 2789.5002\n",
      "Iteration 32990 : Loss 2789.4385\n",
      "Iteration 33000 : Loss 2789.3769\n",
      "Iteration 33010 : Loss 2789.3153\n",
      "Iteration 33020 : Loss 2789.2537\n",
      "Iteration 33030 : Loss 2789.1922\n",
      "Iteration 33040 : Loss 2789.1307\n",
      "Iteration 33050 : Loss 2789.0693\n",
      "Iteration 33060 : Loss 2789.0079\n",
      "Iteration 33070 : Loss 2788.9466\n",
      "Iteration 33080 : Loss 2788.8853\n",
      "Iteration 33090 : Loss 2788.8241\n",
      "Iteration 33100 : Loss 2788.7629\n",
      "Iteration 33110 : Loss 2788.7018\n",
      "Iteration 33120 : Loss 2788.6407\n",
      "Iteration 33130 : Loss 2788.5796\n",
      "Iteration 33140 : Loss 2788.5186\n",
      "Iteration 33150 : Loss 2788.4577\n",
      "Iteration 33160 : Loss 2788.3967\n",
      "Iteration 33170 : Loss 2788.3359\n",
      "Iteration 33180 : Loss 2788.2751\n",
      "Iteration 33190 : Loss 2788.2143\n",
      "Iteration 33200 : Loss 2788.1536\n",
      "Iteration 33210 : Loss 2788.0929\n",
      "Iteration 33220 : Loss 2788.0322\n",
      "Iteration 33230 : Loss 2787.9716\n",
      "Iteration 33240 : Loss 2787.9111\n",
      "Iteration 33250 : Loss 2787.8506\n",
      "Iteration 33260 : Loss 2787.7902\n",
      "Iteration 33270 : Loss 2787.7297\n",
      "Iteration 33280 : Loss 2787.6694\n",
      "Iteration 33290 : Loss 2787.6091\n",
      "Iteration 33300 : Loss 2787.5488\n",
      "Iteration 33310 : Loss 2787.4886\n",
      "Iteration 33320 : Loss 2787.4284\n",
      "Iteration 33330 : Loss 2787.3683\n",
      "Iteration 33340 : Loss 2787.3082\n",
      "Iteration 33350 : Loss 2787.2481\n",
      "Iteration 33360 : Loss 2787.1881\n",
      "Iteration 33370 : Loss 2787.1282\n",
      "Iteration 33380 : Loss 2787.0683\n",
      "Iteration 33390 : Loss 2787.0084\n",
      "Iteration 33400 : Loss 2786.9486\n",
      "Iteration 33410 : Loss 2786.8888\n",
      "Iteration 33420 : Loss 2786.8291\n",
      "Iteration 33430 : Loss 2786.7694\n",
      "Iteration 33440 : Loss 2786.7098\n",
      "Iteration 33450 : Loss 2786.6502\n",
      "Iteration 33460 : Loss 2786.5907\n",
      "Iteration 33470 : Loss 2786.5312\n",
      "Iteration 33480 : Loss 2786.4717\n",
      "Iteration 33490 : Loss 2786.4123\n",
      "Iteration 33500 : Loss 2786.3529\n",
      "Iteration 33510 : Loss 2786.2936\n",
      "Iteration 33520 : Loss 2786.2343\n",
      "Iteration 33530 : Loss 2786.1751\n",
      "Iteration 33540 : Loss 2786.1159\n",
      "Iteration 33550 : Loss 2786.0568\n",
      "Iteration 33560 : Loss 2785.9977\n",
      "Iteration 33570 : Loss 2785.9386\n",
      "Iteration 33580 : Loss 2785.8796\n",
      "Iteration 33590 : Loss 2785.8206\n",
      "Iteration 33600 : Loss 2785.7617\n",
      "Iteration 33610 : Loss 2785.7028\n",
      "Iteration 33620 : Loss 2785.6440\n",
      "Iteration 33630 : Loss 2785.5852\n",
      "Iteration 33640 : Loss 2785.5265\n",
      "Iteration 33650 : Loss 2785.4678\n",
      "Iteration 33660 : Loss 2785.4091\n",
      "Iteration 33670 : Loss 2785.3505\n",
      "Iteration 33680 : Loss 2785.2919\n",
      "Iteration 33690 : Loss 2785.2334\n",
      "Iteration 33700 : Loss 2785.1749\n",
      "Iteration 33710 : Loss 2785.1165\n",
      "Iteration 33720 : Loss 2785.0581\n",
      "Iteration 33730 : Loss 2784.9998\n",
      "Iteration 33740 : Loss 2784.9415\n",
      "Iteration 33750 : Loss 2784.8832\n",
      "Iteration 33760 : Loss 2784.8250\n",
      "Iteration 33770 : Loss 2784.7668\n",
      "Iteration 33780 : Loss 2784.7087\n",
      "Iteration 33790 : Loss 2784.6506\n",
      "Iteration 33800 : Loss 2784.5926\n",
      "Iteration 33810 : Loss 2784.5346\n",
      "Iteration 33820 : Loss 2784.4766\n",
      "Iteration 33830 : Loss 2784.4187\n",
      "Iteration 33840 : Loss 2784.3608\n",
      "Iteration 33850 : Loss 2784.3030\n",
      "Iteration 33860 : Loss 2784.2452\n",
      "Iteration 33870 : Loss 2784.1875\n",
      "Iteration 33880 : Loss 2784.1298\n",
      "Iteration 33890 : Loss 2784.0722\n",
      "Iteration 33900 : Loss 2784.0146\n",
      "Iteration 33910 : Loss 2783.9570\n",
      "Iteration 33920 : Loss 2783.8995\n",
      "Iteration 33930 : Loss 2783.8420\n",
      "Iteration 33940 : Loss 2783.7846\n",
      "Iteration 33950 : Loss 2783.7272\n",
      "Iteration 33960 : Loss 2783.6698\n",
      "Iteration 33970 : Loss 2783.6125\n",
      "Iteration 33980 : Loss 2783.5552\n",
      "Iteration 33990 : Loss 2783.4980\n",
      "Iteration 34000 : Loss 2783.4409\n",
      "Iteration 34010 : Loss 2783.3837\n",
      "Iteration 34020 : Loss 2783.3266\n",
      "Iteration 34030 : Loss 2783.2696\n",
      "Iteration 34040 : Loss 2783.2126\n",
      "Iteration 34050 : Loss 2783.1556\n",
      "Iteration 34060 : Loss 2783.0987\n",
      "Iteration 34070 : Loss 2783.0418\n",
      "Iteration 34080 : Loss 2782.9850\n",
      "Iteration 34090 : Loss 2782.9282\n",
      "Iteration 34100 : Loss 2782.8714\n",
      "Iteration 34110 : Loss 2782.8147\n",
      "Iteration 34120 : Loss 2782.7581\n",
      "Iteration 34130 : Loss 2782.7014\n",
      "Iteration 34140 : Loss 2782.6449\n",
      "Iteration 34150 : Loss 2782.5883\n",
      "Iteration 34160 : Loss 2782.5318\n",
      "Iteration 34170 : Loss 2782.4754\n",
      "Iteration 34180 : Loss 2782.4190\n",
      "Iteration 34190 : Loss 2782.3626\n",
      "Iteration 34200 : Loss 2782.3063\n",
      "Iteration 34210 : Loss 2782.2500\n",
      "Iteration 34220 : Loss 2782.1937\n",
      "Iteration 34230 : Loss 2782.1375\n",
      "Iteration 34240 : Loss 2782.0814\n",
      "Iteration 34250 : Loss 2782.0252\n",
      "Iteration 34260 : Loss 2781.9692\n",
      "Iteration 34270 : Loss 2781.9131\n",
      "Iteration 34280 : Loss 2781.8571\n",
      "Iteration 34290 : Loss 2781.8012\n",
      "Iteration 34300 : Loss 2781.7453\n",
      "Iteration 34310 : Loss 2781.6894\n",
      "Iteration 34320 : Loss 2781.6336\n",
      "Iteration 34330 : Loss 2781.5778\n",
      "Iteration 34340 : Loss 2781.5221\n",
      "Iteration 34350 : Loss 2781.4664\n",
      "Iteration 34360 : Loss 2781.4107\n",
      "Iteration 34370 : Loss 2781.3551\n",
      "Iteration 34380 : Loss 2781.2995\n",
      "Iteration 34390 : Loss 2781.2440\n",
      "Iteration 34400 : Loss 2781.1885\n",
      "Iteration 34410 : Loss 2781.1330\n",
      "Iteration 34420 : Loss 2781.0776\n",
      "Iteration 34430 : Loss 2781.0222\n",
      "Iteration 34440 : Loss 2780.9669\n",
      "Iteration 34450 : Loss 2780.9116\n",
      "Iteration 34460 : Loss 2780.8564\n",
      "Iteration 34470 : Loss 2780.8012\n",
      "Iteration 34480 : Loss 2780.7460\n",
      "Iteration 34490 : Loss 2780.6909\n",
      "Iteration 34500 : Loss 2780.6358\n",
      "Iteration 34510 : Loss 2780.5808\n",
      "Iteration 34520 : Loss 2780.5258\n",
      "Iteration 34530 : Loss 2780.4708\n",
      "Iteration 34540 : Loss 2780.4159\n",
      "Iteration 34550 : Loss 2780.3610\n",
      "Iteration 34560 : Loss 2780.3062\n",
      "Iteration 34570 : Loss 2780.2514\n",
      "Iteration 34580 : Loss 2780.1966\n",
      "Iteration 34590 : Loss 2780.1419\n",
      "Iteration 34600 : Loss 2780.0872\n",
      "Iteration 34610 : Loss 2780.0326\n",
      "Iteration 34620 : Loss 2779.9780\n",
      "Iteration 34630 : Loss 2779.9234\n",
      "Iteration 34640 : Loss 2779.8689\n",
      "Iteration 34650 : Loss 2779.8145\n",
      "Iteration 34660 : Loss 2779.7600\n",
      "Iteration 34670 : Loss 2779.7056\n",
      "Iteration 34680 : Loss 2779.6513\n",
      "Iteration 34690 : Loss 2779.5970\n",
      "Iteration 34700 : Loss 2779.5427\n",
      "Iteration 34710 : Loss 2779.4885\n",
      "Iteration 34720 : Loss 2779.4343\n",
      "Iteration 34730 : Loss 2779.3801\n",
      "Iteration 34740 : Loss 2779.3260\n",
      "Iteration 34750 : Loss 2779.2720\n",
      "Iteration 34760 : Loss 2779.2179\n",
      "Iteration 34770 : Loss 2779.1639\n",
      "Iteration 34780 : Loss 2779.1100\n",
      "Iteration 34790 : Loss 2779.0561\n",
      "Iteration 34800 : Loss 2779.0022\n",
      "Iteration 34810 : Loss 2778.9484\n",
      "Iteration 34820 : Loss 2778.8946\n",
      "Iteration 34830 : Loss 2778.8409\n",
      "Iteration 34840 : Loss 2778.7871\n",
      "Iteration 34850 : Loss 2778.7335\n",
      "Iteration 34860 : Loss 2778.6798\n",
      "Iteration 34870 : Loss 2778.6262\n",
      "Iteration 34880 : Loss 2778.5727\n",
      "Iteration 34890 : Loss 2778.5192\n",
      "Iteration 34900 : Loss 2778.4657\n",
      "Iteration 34910 : Loss 2778.4123\n",
      "Iteration 34920 : Loss 2778.3589\n",
      "Iteration 34930 : Loss 2778.3055\n",
      "Iteration 34940 : Loss 2778.2522\n",
      "Iteration 34950 : Loss 2778.1989\n",
      "Iteration 34960 : Loss 2778.1457\n",
      "Iteration 34970 : Loss 2778.0925\n",
      "Iteration 34980 : Loss 2778.0394\n",
      "Iteration 34990 : Loss 2777.9862\n",
      "Iteration 35000 : Loss 2777.9332\n",
      "Iteration 35010 : Loss 2777.8801\n",
      "Iteration 35020 : Loss 2777.8271\n",
      "Iteration 35030 : Loss 2777.7742\n",
      "Iteration 35040 : Loss 2777.7212\n",
      "Iteration 35050 : Loss 2777.6684\n",
      "Iteration 35060 : Loss 2777.6155\n",
      "Iteration 35070 : Loss 2777.5627\n",
      "Iteration 35080 : Loss 2777.5099\n",
      "Iteration 35090 : Loss 2777.4572\n",
      "Iteration 35100 : Loss 2777.4045\n",
      "Iteration 35110 : Loss 2777.3519\n",
      "Iteration 35120 : Loss 2777.2993\n",
      "Iteration 35130 : Loss 2777.2467\n",
      "Iteration 35140 : Loss 2777.1942\n",
      "Iteration 35150 : Loss 2777.1417\n",
      "Iteration 35160 : Loss 2777.0892\n",
      "Iteration 35170 : Loss 2777.0368\n",
      "Iteration 35180 : Loss 2776.9844\n",
      "Iteration 35190 : Loss 2776.9321\n",
      "Iteration 35200 : Loss 2776.8798\n",
      "Iteration 35210 : Loss 2776.8275\n",
      "Iteration 35220 : Loss 2776.7753\n",
      "Iteration 35230 : Loss 2776.7231\n",
      "Iteration 35240 : Loss 2776.6710\n",
      "Iteration 35250 : Loss 2776.6189\n",
      "Iteration 35260 : Loss 2776.5668\n",
      "Iteration 35270 : Loss 2776.5148\n",
      "Iteration 35280 : Loss 2776.4628\n",
      "Iteration 35290 : Loss 2776.4108\n",
      "Iteration 35300 : Loss 2776.3589\n",
      "Iteration 35310 : Loss 2776.3070\n",
      "Iteration 35320 : Loss 2776.2552\n",
      "Iteration 35330 : Loss 2776.2034\n",
      "Iteration 35340 : Loss 2776.1516\n",
      "Iteration 35350 : Loss 2776.0999\n",
      "Iteration 35360 : Loss 2776.0482\n",
      "Iteration 35370 : Loss 2775.9965\n",
      "Iteration 35380 : Loss 2775.9449\n",
      "Iteration 35390 : Loss 2775.8934\n",
      "Iteration 35400 : Loss 2775.8418\n",
      "Iteration 35410 : Loss 2775.7903\n",
      "Iteration 35420 : Loss 2775.7389\n",
      "Iteration 35430 : Loss 2775.6874\n",
      "Iteration 35440 : Loss 2775.6361\n",
      "Iteration 35450 : Loss 2775.5847\n",
      "Iteration 35460 : Loss 2775.5334\n",
      "Iteration 35470 : Loss 2775.4821\n",
      "Iteration 35480 : Loss 2775.4309\n",
      "Iteration 35490 : Loss 2775.3797\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(1, 35500):\n",
    "    dW, db = gradient(X_train, W, b, y_train)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X_train, W, b, y_train)\n",
    "    losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee47568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8cf1529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.71952597,  480.24856594,  270.31431545,  -49.82868445,\n",
       "        -124.20431738, -208.90705032,  113.33251559,  414.97837954,\n",
       "         101.16307721]),\n",
       " 151.4973319184713)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a05f117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457.8737621196756"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(X_test, W, b)\n",
    "mse = loss(X_test, W, b, y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e92c95be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn90lEQVR4nO3dfZRcdZ3n8fc3SYtBXUKkZWOTmOAwZEUUTAvsya4rQeRBnkYYRgYVXY+simfW0ZMlrK7g0zGjMzp6ZgYXV0fY4UElToyPLJKoO6yg3TxHQSNPoSdCRBIRAnaa7/5Rt8tK5d7uW3Xv7z7V53VOne66VdX1q1u37/d3v78nc3dEREQA5pRdABERqQ4FBRERaVNQEBGRNgUFERFpU1AQEZG2eWUXIIsDDjjAly5dWnYxRERqZXx8/NfuPhz3WK2DwtKlSxkbGyu7GCIitWJmDyQ9pvSRiIi0KSiIiEhbsKBgZs82sx+b2e1mttnMPhRt/5KZ3Wdmt0W3I6LtZmafNbMtZnaHmb0iVNlERCReyDaFp4FV7v47MxsC/sXMvhM9ttrdr+16/knAIdHtaODS6KeIiBQk2JWCt/wuujsU3WaaaOl04IrodTcBC8xsUajyiYjI3oK2KZjZXDO7DXgEuN7db44e+liUIvq0me0TbRsBtna8/KFom1TQ+lsnWLl2I8vWfIuVazey/taJsoskIjkIGhTcfcrdjwAOAo4ys5cCFwHLgVcCC4ELe/mbZna+mY2Z2dj27dvzLrKksP7WCS762p1M7NiFAxM7dnHR1+5UYBBpgEJ6H7n7DmATcKK7b4tSRE8D/wgcFT1tAljc8bKDom3df+sydx9199Hh4dixFxLYJ6+7h12TU3ts2zU5xSevu6ekEolIXkL2Pho2swXR7/OB44G7p9sJzMyAM4C7opdsAN4c9UI6Btjp7ttClU/69687dvW0XUTqI2Tvo0XA5WY2l1bw+Yq7f9PMNprZMGDAbcA7oud/GzgZ2AI8Cbw1YNkkgxcumM9ETAB44YL5JZRGRPIULCi4+x3AkTHbVyU834ELQpVH8rP6hEO56Gt37pFCmj80l9UnHFpiqUQkD7We+0jKccaRrU5hn7zuHv51xy5euGA+q084tL1dROpLQUH6csaRIwoCIg2kuY9ERKRNQUFERNoUFEREpE1BQURE2hQURESkTUFBRETaFBRERKRNQUFERNoUFEREpE1BQURE2hQURESkTXMfSa2sv3VCE/GJBKSgILUxvQzo9JTd08uAAgoMIjlR+khqQ8uAioSnoCC1oWVARcJT+qjGBi2/rmVAizVox5e06Eqhpqbz6xM7duH8Ib++/taJsosWzOoTDmX+0Nw9tmkZ0DAG8fiSFgWFmhrE/PoZR47w8dcfzsiC+RgwsmA+H3/94alrr+tvnWDl2o0sW/MtVq7dqBPcDAbx+JIWpY9qalDz62mXAe1OfRy7fJh14xPquZTSoB5foiuF2krKoyu/Hp/6uPKmB1Xz7YGOr8GloFBTyq8ni0t9eMJzVfONp+NrcCl9lIMyemlM/331DtlbLyd61Xzj6fgaXMGCgpk9G/ghsE/0Pte6+8Vmtgy4Bng+MA68yd1/b2b7AFcAK4BHgT9z9/tDlS8vZY6yTZtfHzRJXVeNPa8YVPOdmY6vwRQyffQ0sMrdXw4cAZxoZscAfwV82t3/CHgMeFv0/LcBj0XbPx09r/LUS6N6klIf5x6zpO+eSyKDItiVgrs78Lvo7lB0c2AV8OfR9suBS4BLgdOj3wGuBf7OzCz6O5WlXhrVo9SHSP+CtimY2VxaKaI/Av4e+CWww913R095CJj+Tx0BtgK4+24z20krxfTrrr95PnA+wJIlS0IWPxWNsq0mpT7CqOso57qWuwxBex+5+5S7HwEcBBwFLM/hb17m7qPuPjo8PJz1z2WmXhoyKOo6yrmu5S5LIV1S3X0HsAn498ACM5u+QjkImP5mJoDFANHj+9FqcK60rKNsReqiru1ndS13WUL2PhoGJt19h5nNB46n1Xi8CTiLVg+k84CvRy/ZEN3/UfT4xqq3J0xTqkIGQV3bz+pa7rKEvFJYBGwyszuAnwDXu/s3gQuB95rZFlptBl+Inv8F4PnR9vcCawKWTUR6VNdRznUtd1lC9j66AzgyZvu9tNoXurc/BfxpqPKINF3oxtTVJxy6x5gcqEf7WV3LXRaNaBZpgCIGUda1q29dy10Wq0naPtbo6KiPjY2VXQyR0q1cuzG2a/TIgvncuGZVCSWSKjOzcXcfjXtME+KJNIAaUyUvCgoiDaDGVMmLgoJIAUKv+nbs8viBnEnbRZKooVkksCIagTfdvb2n7SJJFBREuuTdtTNpRO0lGzbn9j5qUxgcobseKyiIdAhRq086Me/YNcmOXZO5vE8VJ2bUJHT5K+KqU20KIh1CzJOT9sSc5X2yTsyYd5uHJqELo4h5nBQURDok1eonduzq+6QZd8Lu9f1nk2VixhAncE1CF0YRaUKlj0Q6zLSU5/T2zkt2mH2kbNyI2id/v5vHnpyMff9+pZ2YsTut8+TvdyeewNXGUS1FpAkVFEQ6xM2T0722M7ROmh/6xmaemnwmVX63+4TdnRuGYubjictJJ8lyAq9iG0cTFDGPk9JHIh3i0jBJE8E89uRkYq+i2VJNZxw5wpkrRphrBsBcM85cEX4K9ri0TpIsJ3AtPhVGEeu36EpBpEt3rT5pXqEkaXoVrb91gnXjE0xFc49NubNufILRFy0MGhjS1v6znsA1CV04oddvUVAQmUXSJfs+8+a0T/4zicvPz9QQG/IfPimts2D+EM/ZZ16uJ3AtPlVPCgois0iq9QJ7BYsk3TX0ohpiuxuVj10+zLrxib0C3CWnHaYTuAAKCiKpzFTr7adXURENsXGNyuvGJzhzxQib7t6utI7EUlAQyaDfXkVJKaljlw+zcu3GXE7YSSmqTXdv1xoLkkhBQSRHaRtY457XndrJOoWBxgpIPxQURHKWtoE1rpdTno3PGisg/dA4BZGKyLtmr7EC0g9dKYhURN41+xBjBTTzafMpKEjtNeVEFWIKgzzHChQxbbOUL1j6yMwWm9kmM/upmW02s/8abb/EzCbM7LbodnLHay4ysy1mdo+ZnRCqbNIcTZqiuYgpDLLQzKeDIeSVwm7gfe5+i5k9Dxg3s+ujxz7t7n/d+WQzewnwBuAw4IXA98zsj9093UQtMpDKGhkcShGjgPu9slJvpsEQ7ErB3be5+y3R748DPwNmOvJOB65x96fd/T5gC3BUqPJJM+hE1ZssV1ZJbRvqzdQshfQ+MrOlwJHAzdGmd5vZHWb2RTPbP9o2AmzteNlDxAQRMzvfzMbMbGz79notSp736laiE1WvsqSAknozTQ+403HdDMGDgpk9F1gHvMfdfwtcCrwYOALYBvxNL3/P3S9z91F3Hx0eHs67uME0KfddJep22ZssV1ZxbR5nrhhh3fiEjusGCdr7yMyGaAWEK939awDu/nDH458HvhndnQAWd7z8oGhbIzQt910VTet2meW907w2a7fX0APupHzBgoKZGfAF4Gfu/qmO7YvcfVt090+Au6LfNwBXmdmnaDU0HwL8OFT5iqbcdzhN6XaZ5b3Tvjbvbq91Oa6b0m25CCHTRyuBNwGrurqffsLM7jSzO4Bjgb8EcPfNwFeAnwLfBS5oUs8j5b7rocxul1neO+1r8+72WofjWqnb3gS7UnD3f6G1vG23b8/wmo8BHwtVpjIVsbaqZFdmzTfLe/fy2jyvrOpwXCt12xvNfVSQqg9MkpYya75Z3rusctfhuK5LiqsqNM1FgbQ8YfWVWfPN8t5FlTspN1/l41qzxfZGQaGC6tooVtdydypzwfks711Eues691EdUlxVYu5edhn6Njo66mNjY2UXI1dJK3dV7ZK8W13LLemtXLsxtsY9smB+5Vdya0KFJU9mNu7uo3GP6UqhYuraKFbXckt6dcnN1zHFVSWpg4KZvQB49vR9d38wSIkGXF3+8brVtdySXh1y83VNcVXJrL2PzOw0M/sFcB/wA+B+4DuByzWw6tDvO05dyy3p1WFKEU3vnV2aLqkfAY4Bfu7uy4DjgJuClmqA1eEfL05dyy3pFdn9tN/JI3XFml2a9NGkuz9qZnPMbI67bzKzvw1dsEFVZu+XLOpabulNUes99JsCqkOKq+rSBIUd0UynPwSuNLNHgCfCFmuw1bVRrK7llmrJ0mlB3U+zS5M+Oh14ktYcRd8FfgmcErJQIjK48p7eW92ie5MmKHzQ3Z9x993ufrm7fxa4MHTBRGQwqdNCudIEheNjtp2Ud0FERCBbpwXNiJpdYpuCmb0TeBdwcDTN9bTnATeGLpjUT9VHjVa9fNKSpdOCBlFmN1ND81W0xiN8HFjTsf1xd/9N0FJJ7VR90FDVyyd76rfTgrqkZpeYPnL3ne5+v7uf4+4PALsAB55rZksKK6HUQtUHDVW9fJIPtUdkl2ZE86ka0SyzqXoNrerlq6J+B5CVSYMos0vT0PxRNKJZZlH1GlrVy1c1dW2wVZfU7DSiWXJR9UFDvZSv6Q3SaT5fnRtsNYgyG41ollxUfZqLtOVreoN02s+ndNvgmnWRHTN7DvAUYMC5wH7Ale7+aPjizazKi+w0vbbZVHVeSCaNtJ+v6fth0M20yM6sbQru/oS7T3WOaK5CQKiyuuZjpfk15LSfTw22gysxKJjZ42b226RbkYWsG3V/rK+mN0in/XxqsB1ciW0K7v48ADP7CLAN+N/8IYW0aLY/bGaLgSuAA2mNb7jM3T9jZguBLwNLaXVvPdvdHzMzAz4DnExrAr63uPstfX+yEjW9ttlkVW8wz6qXz6cG28GUpqH5NHd/ecf9S83sduCDs7xuN/A+d7/FzJ4HjJvZ9cBbgBvcfa2ZraE1WvpCWvMpHRLdjgYujX7mKmuuP83rNad7fVW9wTyrXj6f2sUGU5qg8ISZnQtcQ6vGfw4peh+5+zZaVxi4++Nm9jNghNZU3K+OnnY58H1aQeF04ApvtXzfZGYLzGxR9HdykbVnSdrXN7222XRNryGn+XyhemHlHWgUuPKXZvDanwNnAw9Htz+NtqVmZkuBI4GbgQM7TvS/opVeglbA2NrxsoeibbnJmutP+3rlY6XuQrSL5d0BQx06wpj1SsHd76dVi+9LNMZhHfAed/9tq+mg/bfdzGbuE7v33zsfOB9gyZLepmDKmuvv5fVNr21Ks4VoF8t7QFydB9hVWZorhb6Z2RCtgHClu38t2vywmS2KHl8EPBJtnwAWd7z8oGjbHtz9MncfdffR4eHhnsqTtWdJ03umiEwLcaznHWjUoSOMYEEh6k30BeBn7v6pjoc2AOdFv58HfL1j+5ut5RhgZ57tCZC977X6bku3siaNC/2+IY71vAONKmlhpJkldVmabTFWAm8CVpnZbdHtZGAtcHw08+provsA3wbuBbYAn6e1wE+usub61VYgncrKaRfxviGO9bwDjSppYaSZ5uIWd39F17Zxd18RtGQpVHmaC2m+sqaCqPMUFOp9VA0zTXMx03Kcy4HDgP3M7PUdD/0b4Nn5FlGkfsrKadc5l553Bwx16MjfTL2PDgVOARYAp3Zsfxx4e8AyidRCL4MU86zRanCkhDTTcpxfd/e3Aqe4+1s7bn/h7v+vwDKKVFLanHbebQDKpUtIaXofPWpmN5jZXQBm9jIz+0DgcknF1XGpxrylbYzNeyCYOjxISGkamn8ArAb+p7sfGW27y91fWkD5ZqSG5mJ0pz6OXT7MuvGJvabx0Ikp3rI13yLuv8yA+9a+rujiiPTX0NxhX3f/cedIZFqT3UnDxOW9gb3mwLnypgf3OslpJGmyrG0A6mEjRUoTFH5tZi+mNRkeZnYW0UR30hxJE6DtM2/OXqmPpGvLvHu/NOVkmGWCxPW3TrD6q7cz+Uxrr0/s2MXqr94ONGN5UGjO99wUaYLCBcBlwHIzmwDuA94YtFRSuKS8d/e2meTZ+6VJayVnmY77kg2b2wFh2uQzziUbNtduP8Rp0vfcFGkmxLsXeE20VvMcd388fLGkaL3W8o09rxjy7v3Sy2Rndahp9tuffseuyZ62140mtaueWYOCmb236z7ATmDc3W8LUywpWlLee/99h3hq8pm9Uh9nrhhh093bg52I0w7QqnNNsw7BLLQ6D8RrqjTpo9Ho9o3o/inAHcA7zOyr7v6JUIWT4iTlvS8+9TDGHvgNV9+8lSl35ppx5ooRPnrG4UHLk7Zxtq41zbTBbP99h3jsyb2vCvbfd6iYggamgXjVk2acwkHAK9z9fe7+PmAF8ALgVbSW1pQGSOr7DrBufIKpqOvylDvrxieCj0tIO0CrrjXNtGMXLj71MIbm7tHzj6G5xsWnHha8jHHyHp+igXjVk+ZK4QXA0x33J2mtnrbLzJ5OeI3UUFzee+XajaXUxNM2zta1ppk2mFVpzegQqboqfT5pSRMUrgRuNrPpdQ9OBa6KGp5/GqxkUgll1sTTNM6GWA+7iFx/L8GsKpO+hUrVVeXzScuM6aNooZwv0Vr+ckd0e4e7f9jdn3D3c0MXUMpV9YVM8p7yoag1EuqYNqlrqk56M+OVQrSG8rfd/XBA80kMoF5q4mX1psmzpllUw3VRaRPNziq9SpM+usXMXunuPwleGqmctCevOncN7VRkbTh02iTv7yREqk6qJ03vo6OBH5nZL83sDjO708zuCF0wqZe8ZwItS9XTZb3Q7KzSjzRXCicEL4VUVtraZlPyzU2qDYf4TtQo3HyzXim4+wPu/gCwi9bMBtM3GQBpa5tNqWE3qTZcl+9Ea3NUS5ppLk4D/gZ4IfAI8CLgZ7TWb5aGS1vbbFINuym14Tp0121KW1STpGlT+AhwDPBzd18GHAfcFLRUUhlpa5tNqmE3RR266zalLapJ0rQpTLr7o2Y2x8zmuPsmM/vb0AWTauilttmUGnZWVZrorurddZvSFtUkaYLCDjN7LvBD4EozewR4ImyxpCo0DcHMZluqNI90SFlBpvt948YoQLYTuMY+VE+aNZqfQ6uReQ5wLrAf8E/u/ptZXvdFWjOqPjK9nrOZXQK8HdgePe2/u/u3o8cuAt4GTAF/4e7XzVb40Gs0V6nGJ8VJ+71358Nh73Umpo0smM+Na1b1VZa4K7XQqbkiPlvS+2i97/BmWqM5TZvCB939GXff7e6Xu/tngQtTvO5LwIkx2z/t7kdEt+mA8BLgDbQar08E/sHM5sa8tjBFTXcg1dLL9x6XTsl7qdKycu5Jn826npe14VptUdWTJn10PHsHgZNitu3B3X9oZktTluN04Bp3fxq4z8y2AEcBP0r5+tzVdZ5+yaaX772XE32/6ZCycu5Jf99pnbjzvHpWW1S1JAYFM3sn8C7g4K4RzM8Dbszwnu82szfTmkvpfe7+GDDCnj2aHoq2xZXrfFoT9LFkyZIMxZiZGsAGUy/fe1I+PM+lSovKuXenzBYkLO6TJVUk9TBT+ugqWtNkb4h+Tt9WuPsb+3y/S4EXA0cA22iNf+iJu1/m7qPuPjo8PNxnMWZXl4E/3TQQKJtevvekmU7PPWZJbumQImZTjUuZ/e6p3Xst7lPXcSfSm8QrBXffSWst5nPyejN3f3j6dzP7PPDN6O4EsLjjqQdF20pTx8FYoQYCDVKDe69dcCFsz6wi3iMuZTb5jLNg/hDP2WfeQHzv8gdp2hRyY2aL3H1bdPdPgLui3zfQWrjnU7RGTh8C/LjIsnWrY1fMEO0ggzbitNfvPW0+PEtgzZJzT/O+SSmznbsmue3i1+byHlIfwYKCmV0NvBo4wMweAi4GXm1mR9BKud4P/BcAd99sZl+htZLbbuACd5+K+bOFqlsDWIh2kEFscM/7e19/6wSrr72dyalWS8PEjl2svvb29nuFkjagZ2m3GLRKwyBI0yW1L+5+jrsvcvchdz/I3b/g7m9y98Pd/WXuflrHVQPu/jF3f7G7H+ru3wlVribn3EO0g/QSaJq8b7P40Dc2twPCtMkp50Pf2Bz0fdN2Z83SbqFpKponWFCooqaPPQjRKJk20DR932YR14tnpu15SRvQs4wVUC+95im0TaFseaRCqpw/DdEOkrbhdRDTTFXXS1qo35SZpqlonoEKCllrNXXIn+adD08baFRjTLbv0ByenHwmdntIRfSgq2MvPZnZQAWFrLWaQa0Npwk0qjEme9a8ubFB4Vnz0s3k0u/VaVO6zBapypmAogxUUMhaq1FtOJlqjMl27opvO0ja3inr1WkRPejq1ksvSR0yAUUYqIbmrJNv1XWUc1pZeg9pYrNkWY4b9e4pjvZ1y0BdKUC2Wk2Ta8O91pKSLrMVBPaW5bhJWsMgafugyTPdo0xAy0BdKWTV5NpwL7UkdT/tTZbjZq51T1Y98/ZBkvdx2PRMQFoDd6WQVVNrw73Ukga1wT2Lfo+bqYRFsJK2D5K8j8MmZwJ6oaAgQG+9h3SZXZyRhO9lJGXttcm9afI+DpvWk6pfCgoC9FZLUvfT4mSpvTa9N02I47CpmYBeqE1BgN7y3kXM8S8tWdojmt6bRsdhGLpSkLa0taReLrObnL4oSr+11xBpvip9n0r3hKGgIH1Jc6Jqevqi6vJOrxT5faYNPkr35E/pIwmm6emLqss7vVLU96kuz+XSlQLVuiSuon73j3oplSvv9EpR36e6PJdr4IOCUhwzy7J/BrWXUpUqGXmmV4r6PlWZKNfAp4+U4phZlv3TpN4haeeFanLqo6jvUyOLyzXwQUG1kpll2T9NmRaklxN9kysZRX2fvQQfLQGbv4FPHw1qiiOtrPunCb1DeslxD0I30CKm4obZ20KU+g1j4IOC5juZmfZPbyf6OncDrZI0wUcN0mEMfFDQAJiZDeL+6a6Z7zd/iB0xC+LEnejzDqI68SVT6jeMgQ8K0IwUR0iDtH/iauZz58RPU33s8uG9ttW1G2gdKfUbRrCgYGZfBE4BHnH3l0bbFgJfBpYC9wNnu/tjZmbAZ4CTgSeBt7j7LaHKVkdZ8spVyklXXVzNfOqZ+GmqN929PXZ7HbuB1pFSm2GEvFL4EvB3wBUd29YAN7j7WjNbE92/EDgJOCS6HQ1cGv2srTxPxFnyyoOak+5XLzXwELX17uPm2OXDrBuf0IkvxiCmNosQLCi4+w/NbGnX5tOBV0e/Xw58n1ZQOB24wt0duMnMFpjZInffFqp8IeV9Is6SV65iTrrKVy5JNfOk5+Yp7rhZNz7BmStG2HT39krur7INUmqzKEW3KRzYcaL/FXBg9PsIsLXjeQ9F2/YKCmZ2PnA+wJIlS8KVNIO8T8RZ8spVy0lX/colLiUxNNfAYbIjjRSitp503Gy6ezs3rlnV19+scgCWaipt8Fp0VdDzmoLufpm7j7r76PDw3g19VZD3iTjLCM+qjQ6t+uCuuAFanzzr5fzZUYvb6yLPNePMFfnXUPM+bpo8ulrCKfpK4eHptJCZLQIeibZPAIs7nndQtK2W8m4czNKgVmRjXJpaadWuXOJ0pyTW3zrBuvGJ9rrIU+6sG59g9EULcw0MScfNgn2HWLl24x77FWbPpVcxdSjVV3RQ2ACcB6yNfn69Y/u7zewaWg3MO+vangD5n4izNKgV1RiXNi1Ux940oU6uaRqVh+Yav3tqN4892RonMbFjF6uvvZ2pZ5zpbNb0NthzX9chAINSXFUTskvq1bQalQ8ws4eAi2kFg6+Y2duAB4Czo6d/m1Z31C20uqS+NVS5ihDiRJylQa2Ixri0J86irlzyPNGEmroiTaPyE0/v3mvg3OTU3lnXySnnQ9/YXLsAnLWN6QPr7+Tqm7cy5c5cM845ejEfPePwoGVuupC9j85JeOi4mOc6cEGospRh0HpFpD1xFnHlkndjdq8n1zQBKW2j8rI130pdzumriWl16Mef5SrsA+vv5J9uerB9f8q9fV+BoX8a0dwwZV2K93LiDB0w80739HJyTRuQ0gbRXrrIdqtDP/4sV2FX37w1cbuCQv8UFBqkzO6eZdZKuwNh0km033TPTCfX7vd+4undqQJS0nxK+80f2uN+3H5NsqDrtdNlr1IQ6JYlxTXd8J92u6SjoNAgZfY2STpxAnv1nAmdKjLi+zpnyaXHnVzj3jtJd0CanHom9nnd2+P267HLh/nyj7fuMW5iaI5xyWmHpf9AKRRx1ZmlMjHXLDYATHcdlv4oKDRI2b1N4rpyhr5yiQuEDnsFhqIGmyXpDkhP/D7+dXHb4wLS6IsW1qpdJkmWFNc5Ry/eo02hc7v0T0GhQarW26SIK5ekgOe0Bp6FrOWmDbYhAlLd2mVm0u9nmW43UO+jfCkoNEjVepsknTQnduzKLaWUFAhHFszve2qIrO+9/75D7PuseTN+vgUJbQpx7QJlKOK7y8NHzzhcQSBnA79Gc5NUbU3kpCsUg9ymXihqMfle3vviUw/jxjWruG/t67hxzarY/X/JaYcx1LVOQ4h2gX4V8d1JNZnXuKV+dHTUx8bGyi6GJOjOS8Peuf5pWWr2ZY6Ibeo6F0V9d1lVeR9WmZmNu/to7GMKChJS2u6iBty39nXFFk5mVPXvLi5wzR+aW+rVcV3MFBTUpjCgiqphdTcirly7MVNjuGqGxcn7u8ubJvwLQ20KA6jMKZWztAFoKuhyldl+E6fsLthNpSuFAZRUw7pkw+bgtfAs/dJVMwwnzRVY1abNqFoX7KZQUKiJImb93LFrst1NcrbBSlnK02+/dNUMw+hloFqVps2oWhfsplBQqIGiZv3sllQLL2uOpUGtGYZuR6nrFVhZU6s0ndoUaiDvJSzjcsNJ4mrhZS2pWbWcdhGKaEep8xXYGUeO7DEmBFC7U0YKCjWQ9z9t3CC3/feNH0kbVwsv6yRyxpEjnLliJPhayVVSRACu2jreWVR9DfA6UFCogSL+aV/3skWpa+FlnUSS1kpuci2wiADcpCuwOl/1VIWCQg3k/U8bl5KYXgoyzRQZWcuz/tYJVq7dyLI132Ll2o2pT+qDWAssIgBXbXqULJp01VMWNTTXQN5dAdMuBRmiPFkaqQexFlhUD5sq9SrKQj2SslNQqIk8/2nzOLn2W54sPV0GsfdR1cYGVJ32V3YKCgMoxEL0aWUJSINaC2xKLb4o2l/ZqE1hAPXSJpB3l8gsOd8m5b5FqkpXCgOol0vsrAObuq8yjl0+zLrxib5r+2MP/IZf7XwKB3618ynGHvhN7lNVV23SvaqVR5qtlKBgZvcDjwNTwG53HzWzhcCXgaXA/cDZ7v5YGeUbBGkvsbOke+Ialad7OW26e3vPJ7kPrL9zjzV5p9zb92dbfSttA3dZo7WTVK080nxlXikc6+6/7ri/BrjB3dea2Zro/oXlFC2MOtb4sjTuZu3l1O3qm7cmbp8tKKS94sljyoc8v+e6TkEh9VWlNoXTgcuj3y8HziivKPmr67TPWcYk5N2FdCphQaik7f2UJWuZ8/6eB7EbrpSrrKDgwP8xs3EzOz/adqC7b4t+/xVwYNwLzex8Mxszs7Ht27cXUdZc1HXgVZbG3bwHEk1Pb5F2ez9lyVrmvL9nDcaSopUVFP6Du78COAm4wMxe1fmgt9YIja3+uftl7j7q7qPDw8MFFDUfda7xdU86ljZtkfdI7HOOXtzT9n7KkrXMeX/PTZqCQuqhlDYFd5+Ifj5iZv8MHAU8bGaL3H2bmS0CHimjbKFo4FX2/Pp0u8HVN29lyp25Zpxz9OJZ2xN6KUvWMuf9PWswlhTNPEU+Ntc3NHsOMMfdH49+vx74MHAc8GhHQ/NCd/9vM/2t0dFRHxsbC1/oHHT3nJn2xmOWpDqplamODeRl0WLyUgdmNu7uo3GPlXGlcCDwz9bKA88DrnL375rZT4CvmNnbgAeAs0soWzCb7o5v/0jaXhXqEjmzuID58dcfriAqtVV4UHD3e4GXx2x/lNbVQiPVtU1BXSKTJQXMj7/+8L663IpUQZW6pDZaXXuR1DWYFaGuPcpEZqKgUJC69iKpazArggKmNJGCQkHqOplbXYNZERQwpYk0IV6B6jilr7pEJhvUqbyl2RQUZFZ1DGZFUMCUJlJQEMlAAVOaRm0KIiLSpqAgIiJtCgoiItKmoCAiIm0KCiIi0lb4LKl5MrPttCbPC+0A4NezPmuwaJ/E036Jp/0Sr6z98iJ3j12QptZBoShmNpY0zeyg0j6Jp/0ST/slXhX3i9JHIiLSpqAgIiJtCgrpXFZ2ASpI+ySe9ks87Zd4ldsvalMQEZE2XSmIiEibgoKIiLQpKABmttDMrjezX0Q/90943nfNbIeZfbNr+zIzu9nMtpjZl83sWcWUPKwe9st50XN+YWbndWz/vpndY2a3RbcXFFf6/JnZidHn2WJma2Ie3yf6/rdEx8PSjscuirbfY2YnFFrwwPrdL2a21Mx2dRwfnyu88IGk2CevMrNbzGy3mZ3V9Vjs/1Nh3H3gb8AngDXR72uAv0p43nHAqcA3u7Z/BXhD9PvngHeW/ZmK2i/AQuDe6Of+0e/7R499Hxgt+3PktC/mAr8EDgaeBdwOvKTrOe8CPhf9/gbgy9HvL4mevw+wLPo7c8v+TBXYL0uBu8r+DCXtk6XAy4ArgLM6tif+PxV105VCy+nA5dHvlwNnxD3J3W8AHu/cZmYGrAKune31NZRmv5wAXO/uv3H3x4DrgROLKV6hjgK2uPu97v574Bpa+6dT5/66FjguOj5OB65x96fd/T5gS/T3miDLfmmqWfeJu9/v7ncAz3S9tvT/JwWFlgPdfVv0+6+AA3t47fOBHe6+O7r/ENCUVVfS7JcRYGvH/e7P/49RauB/1PxEMNvn3OM50fGwk9bxkea1dZVlvwAsM7NbzewHZvYfQxe2IFm+79KPlYFZec3Mvgf825iH3t95x93dzAamn27g/XKuu0+Y2fOAdcCbaF0uiwBsA5a4+6NmtgJYb2aHuftvyy7YIBuYoODur0l6zMweNrNF7r7NzBYBj/Twpx8FFpjZvKgWdBAwkbG4hclhv0wAr+64fxCttgTcfSL6+biZXUXrsrquQWECWNxxP+57nn7OQ2Y2D9iP1vGR5rV11fd+8VYS/WkAdx83s18CfwyMBS91WFm+78T/p6IofdSyAZhu5T8P+HraF0YH9iZgugdBT6+vuDT75TrgtWa2f9Q76bXAdWY2z8wOADCzIeAU4K4CyhzKT4BDop5mz6LVYLqh6zmd++ssYGN0fGwA3hD1wlkGHAL8uKByh9b3fjGzYTObC2BmB9PaL/cWVO6Q0uyTJLH/T4HKGa/slvoq3GjlN28AfgF8D1gYbR8F/lfH8/4vsB3YRSvXd0K0/WBa/+RbgK8C+5T9mQreL/85+uxbgLdG254DjAN3AJuBz1DzHjfAycDPafUseX+07cPAadHvz46+/y3R8XBwx2vfH73uHuCksj9LFfYLcGZ0bNwG3AKcWvZnKXCfvDI6hzxB62pyc8dr9/p/KvKmaS5ERKRN6SMREWlTUBARkTYFBRERaVNQEBGRNgUFERFpU1AQyYmZLTaz+8xsYXR//+j+0pKLJpKagoJITtx9K3ApsDbatBa4zN3vL61QIj3SOAWRHEWjt8eBLwJvB45w98lySyWS3sDMfSRSBHefNLPVwHeB1yogSN0ofSSSv5NozQD60rILItIrBQWRHJnZEcDxwDHAX0azy4rUhoKCSE6iRYQuBd7j7g8CnwT+utxSifRGQUEkP28HHnT366P7/wD8OzP7TyWWSaQn6n0kIiJtulIQEZE2BQUREWlTUBARkTYFBRERaVNQEBGRNgUFERFpU1AQEZG2/w+R9PjfHO0rbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x축에는 X 데이터의 첫 번째 컬럼을, y축에는 정답인 target 데이터\n",
    "plt.scatter(X_test[:,0], y_test)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('target data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd961e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
